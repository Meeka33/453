 It is a traditional assumption among realists about mental representations that representational states come in two basic varieties (cf. Boghossian 1995). There are those, such as thoughts, that are composed of concepts and have no phenomenal (“what-it’s-like”) features (“qualia”), and those, such as sensations, which have phenomenal features but no conceptual constituents. (Nonconceptual content is usually defined as a kind of content that states of a creature lacking concepts might nonetheless  have.[1])  On this taxonomy, mental states can represent either in a way analogous to expressions of natural languages or in a way analogous to drawings, paintings, maps, photographs or movies. Perceptual states such as seeing that something is blue, are sometimes thought of as hybrid states, consisting of, for example, a non-conceptual sensory experience and a belief, or some more integrated compound of conceptual and non-conceptual elements. (There is an extensive literature on the representational content of perceptual experience. See the entry on the  contents of perception.) Disagreement over non-conceptual representation concerns the existence and nature of phenomenal properties, the role they play in determining the contents of sensory representations, and which kinds of properties can be represented by non-conceptual states. Dennett (1988), for example, denies that there are such things as qualia at all (as they are standardly construed); while Brandom (2002), McDowell (1994), Rey (1991) and Sellars (1956) deny that they are needed to explain the content of sensory experience. Among those who accept that experiences have phenomenal content, some (Dretske, Lycan, Tye) argue that it is reducible to a kind of intentional content, while others (Block, Loar, Peacocke) argue that it is irreducible. (See the discussion in the next section.) A further debate concerns the non-conceptual representability of high-level properties such as kind properties and moral properties. (See, e.g., Dretske 1995 and Siegel 2010, and the entry on the contents of perception.) Some historical discussions of the representational properties of mind (e.g., Aristotle De Anima, Locke 1689/1975, Hume 1739/1978) seem to assume that nonconceptual representations – percepts (“impressions”), images (“ideas”) and the like – are the only (or at least the main) kinds of mental representations, and that the mind represents the world in virtue of being in states that resemble things in it. On such a view, all representational states have their content in virtue of their sensory phenomenal features. Powerful arguments, however, focusing on the lack of generality (Berkeley Principles of Human Knowledge), ambiguity (Wittgenstein 1953) and non-compositionality (Fodor 1981d) of sensory and imagistic representations, as well as their unsuitability to function as logical (Frege 1918/1997, Geach 1957) or mathematical (Frege 1884/1953) concepts, and the symmetry of resemblance (Goodman 1976), convinced philosophers that no theory of mind can get by with only nonconceptual representations construed in this way. (For more discussion, see the entry on  nonconceputal mental content.) There has also been dissent from the traditional claim that conceptual representations (thoughts, beliefs) lack phenomenology. Chalmers (1996), Flanagan (1992), Goldman (1993), Horgan and Tienson (2002), Jackendoff (1987), Levine (1993, 1995, 2001), McGinn (1991a), Pitt (2004, 2009, 2011, 2013), Searle (1992), Siewert (1998, 2011) and Strawson (1994, 2010), claim that purely conceptual (conscious) representational states themselves have a proprietary kind of phenomenology. This view – bread and butter, it should be said, among historical and contemporary Phenomenologists – has been gaining momentum of late among analytic philosophers of mind. (See, e.g., the essays in Bayne and Montague 2011 and Kriegel 2013, and Chudnoff 2015, Farkas 2008a, Kriegel 2011, Mendelovici 2018, Montague 2016.) If this claim is correct, the question of what role phenomenology plays in the determination of representational content re-arises for conceptual representation; and the eliminativist ambitions of Sellars, Brandom, Rey, et al. would meet a new obstacle. It would also raise prima facie problems for reductive representationalism, as well as for reductive naturalistic theories of intentional content, and externalism in general. The view that there is a proprietary phenomenology of conscious thought – a cognitive (conceptual, propositional) phenomenology – claims that there is something it’s like to occurrently, consciously think a thought (entertain a propositional content), which is as different from other kinds of phenomenology (visual, auditory, etc.) as they are from each other. Opinions diverge, however, with respect to the role such phenomenology plays in determining the contents of conceptual/propositional representations. Some (e.g., Siewert) claim that it plays no such role. Others (e.g., Horgan and Tienson, Strawson) hold that it determines only “narrow” contents, further, “broad” contents being determined by extrinsic relations to represented objects and properties. Still others (e.g., Farkas 2008b, Pitt) argue that it is the only kind of conceptual content, insisting on a sharp distinction between content (sense) and reference. There is also disagreement about whether or not cognitive phenomenology determines but is distinct from conceptual/propositional content (e.g., Pitt 2004) or is identical to it (e.g., Pitt 2009). Outstanding challenges for this thesis include unconscious thought (which seems to entail the existence of unconscious phenomenology, on this view), indexical concepts (whose content is standardly taken to be referentially individuated; see Pitt 2013 for an attempt to address this challenge), and nominal concepts (concepts expressed by utterances of names, likewise standardly referentially individuated). See the entries on  consciousness and intentionality  and  phenomenal intentionality  for further discussion.