<!DOCTYPE html>
<!--[if lt IE 7]> <html class="ie6 ie"> <![endif]-->
<!--[if IE 7]>    <html class="ie7 ie"> <![endif]-->
<!--[if IE 8]>    <html class="ie8 ie"> <![endif]-->
<!--[if IE 9]>    <html class="ie9 ie"> <![endif]-->
<!--[if !IE]> --> <html> <!-- <![endif]-->
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>
Semantic Conceptions of Information (Stanford Encyclopedia of Philosophy)
</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="robots" content="noarchive, noodp" />
<meta property="citation_title" content="Semantic Conceptions of Information" />
<meta property="citation_author" content="Floridi, Luciano" />
<meta property="citation_publication_date" content="2005/10/05" />
<meta name="DC.title" content="Semantic Conceptions of Information" />
<meta name="DC.creator" content="Floridi, Luciano" />
<meta name="DCTERMS.issued" content="2005-10-05" />
<meta name="DCTERMS.modified" content="2015-01-07" />

<!-- NOTE: Import webfonts using this link: -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300,600,200&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css" />

<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap.min.css" />
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap-responsive.min.css" />
<link rel="stylesheet" type="text/css" href="../../css/font-awesome.min.css" />
<!--[if IE 7]> <link rel="stylesheet" type="text/css" href="../../css/font-awesome-ie7.min.css"> <![endif]-->
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/style.css" />
<link rel="stylesheet" type="text/css" media="print" href="../../css/print.css" />
<link rel="stylesheet" type="text/css" href="../../css/entry.css" />
<!--[if IE]> <link rel="stylesheet" type="text/css" href="../../css/ie.css" /> <![endif]-->
<script type="text/javascript" src="../../js/jquery-1.9.1.min.js"></script>
<script type="text/javascript" src="../../js/bootstrap.min.js"></script>

<!-- NOTE: Javascript for sticky behavior needed on article and ToC pages -->
<script type="text/javascript" src="../../js/jquery-scrolltofixed-min.js"></script>
<script type="text/javascript" src="../../js/entry.js"></script>

<!-- SEP custom script -->
<script type="text/javascript" src="../../js/sep.js"></script>
</head>

<!-- NOTE: The nojs class is removed from the page if javascript is enabled. Otherwise, it drives the display when there is no javascript. -->
<body class="nojs article" id="pagetopright">
<div id="container">
<div id="header-wrapper">
  <div id="header">
    <div id="branding">
      <div id="site-logo"><a href="../../index.html"><img src="../../symbols/sep-man-red.png" alt="SEP logo" /></a></div>
      <div id="site-title"><a href="../../index.html">Stanford Encyclopedia of Philosophy</a></div>
    </div>
    <div id="navigation">
      <div class="navbar">
        <div class="navbar-inner">
          <div class="container">
            <button class="btn btn-navbar collapsed" data-target=".collapse-main-menu" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Menu </button>
            <div class="nav-collapse collapse-main-menu in collapse">
              <ul class="nav">
                <li class="dropdown open"><a id="drop1" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-book"></i> Browse</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop1">
                    <li><a href="../../contents.html">Table of Contents</a></li>
                    <li><a href="../../new.html">What's New</a></li>
                    <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
                    <li><a href="../../published.html">Chronological</a></li>
                    <li><a href="../../archives/">Archives</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop2" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-info-sign"></i> About</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop2">
                    <li><a href="../../info.html">Editorial Information</a></li>
                    <li><a href="../../about.html">About the SEP</a></li>
                    <li><a href="../../board.html">Editorial Board</a></li>
                    <li><a href="../../cite.html">How to Cite the SEP</a></li>
                    <li><a href="../../special-characters.html">Special Characters</a></li>
                    <li><a href="../../tools/">Advanced Tools</a></li>
                    <li><a href="../../contact.html">Contact</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop3" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-leaf"></i> Support SEP</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop3">
                    <li><a href="../../support/">Support the SEP</a></li>
                    <li><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
                    <li><a href="../../support/donate.html">Make a Donation</a></li>
                    <li><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
                  </ul>
                </li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!-- End navigation -->
    
    <div id="search">
      <form id="search-form" method="get" action="../../search/searcher.py">
        <input type="search" name="query" placeholder="Search SEP" />
        <div class="search-btn-wrapper"><button class="btn search-btn" type="submit"><i class="icon-search"></i></button></div>
      </form>
    </div>
    <!-- End search --> 
    
  </div>
  <!-- End header --> 
</div>
<!-- End header wrapper -->

<div id="content">

<!-- Begin article sidebar -->
<div id="article-sidebar" class="sticky">
  <div class="navbar">
    <div class="navbar-inner">
      <div class="container">
        <button class="btn btn-navbar" data-target=".collapse-sidebar" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Entry Navigation </button>
        <div id="article-nav" class="nav-collapse collapse-sidebar in collapse">
          <ul class="nav">
            <li><a href="#toc">Entry Contents</a></li>
            <li><a href="#Bib">Bibliography</a></li>
            <li><a href="#Aca">Academic Tools</a></li>
            <li><a href="https://leibniz.stanford.edu/friends/preview/information-semantic/">Friends PDF Preview <i class="icon-external-link"></i></a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=information-semantic">Author and Citation Info <i class="icon-external-link"></i></a> </li>
            <li><a href="#pagetopright" class="back-to-top">Back to Top <i class="icon-angle-up icon2x"></i></a></li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</div>
<!-- End article sidebar --> 

<!-- NOTE: Article content must have two wrapper divs: id="article" and id="article-content" -->
<div id="article">
<div id="article-content">

<!-- BEGIN ARTICLE HTML -->


<div id="aueditable"><!--DO NOT MODIFY THIS LINE AND ABOVE-->

<h1>Semantic Conceptions of Information</h1><div id="pubinfo"><em>First published Wed Oct 5, 2005; substantive revision Wed Jan 7, 2015</em></div>

<div id="preamble">

<p>

&ldquo;I love information upon all subjects that come in my way, and
especially upon those that are most important.&rdquo; Thus boldly
declares Euphranor, one of the defenders of Christian faith in
Berkeley&rsquo;s <em>Alciphron</em> (Dialogue 1, Section 5, Paragraph 6/10,
see Berkeley [1732]). Evidently, information has been an object of
philosophical desire for some time, well before the computer
revolution, Internet or the dot.com pandemonium (see for example Dunn
[2001] and Adams [2003]). Yet what does Euphranor love, exactly?
<em>What is information</em>? The question has received many answers
in different fields. Unsurprisingly, several surveys do not even
converge on a single, unified definition of information (see for
example Braman [1989], Losee [1997], Machlup and Mansfield [1983],
Debons and Cameron [1975], Larson and Debons [1983]).</p>

<p>

Information is notoriously a polymorphic phenomenon and a polysemantic
concept so, as an <em>explicandum</em>, it can be associated with
several explanations, depending on the level of abstraction adopted
and the cluster of requirements and desiderata orientating a
theory. The reader may wish to keep this in mind while reading this
entry, where some schematic simplifications and interpretative
decisions will be inevitable. Claude E. Shannon, for one, was very
cautious:</p>

<blockquote>
<p>

The word &lsquo;information&rsquo; has been given different meanings
by various writers in the general field of information theory. It is
likely that at least a number of these will prove sufficiently useful
in certain applications to deserve further study and permanent
recognition. <em>It is hardly to be expected that a single concept of
information would satisfactorily account for the numerous possible
applications of this general field</em>. (italics added). (Shannon
[1993], p. 180)
</p>
</blockquote>

<p>Thus, following Shannon, Weaver [1949] supported a tripartite analysis
of information in terms of</p>

<blockquote>
<p>

(1) technical problems concerning the quantification of information
and dealt with by Shannon&rsquo;s theory</p>

<p>

(2) semantic problems relating to meaning and truth; and</p>

<p> 

(3) what he called &ldquo;influential&rdquo; problems concerning
the impact and effectiveness of information on human behaviour, which
he thought had to play an equally important role.</p>
</blockquote>

<p>

And these are only some early examples of the problems raised by any
analysis of information.</p>

<p>

Indeed, the plethora of different analyses can be confusing.
Complaints about misunderstandings and misuses of the very idea of
information are frequently expressed, even if to no apparent avail.
Sayre [1976], for example, criticised the &ldquo;laxity in use of the
term &lsquo;information&rsquo;&rdquo; in Armstrong [1968] (see now
Armstrong [1993]) and in Dennett [1969] (see now Dennett [1986]),
despite appreciating several other aspects of their work. More
recently, Harms [1998] pointed out similar confusions in Chalmers
[1996], who 
</p>

<blockquote>
<p>

seems to think that the information theoretic notion of information
[see section 3, my addition] is a matter of what possible states there
are, and how they are related or structured [&hellip;] rather than of
how probabilities are distributed among them. (p. 480).
</p>
</blockquote>

<p>

In order to try to avoid similar pitfalls, this entry has been
organised into four sections. Section 1 attempts to draw a map of the
main senses in which one may speak of <em>semantic information</em>,
and does so by relying on the analysis of the concept of <em>data</em>
(depicted in Figure 1 below). Sometimes the several concepts of
information organised in the map can be variously coupled
together. This should not be taken as necessarily a sign of confusion,
for in some philosophers it may be the result of an intentional
bridging. The map is not exhaustive and it is there mainly in order to
avoid some obvious pitfalls and to narrow the scope of this article,
which otherwise could easily turn into a short version of the
Encyclopedia Britannica. Its schematism is only a starting point for
further research and the reader interested in knowing more may wish to
consult Floridi [2011] and Adriaans and van Benthem [2008].
</p>

<p>

After this initial orientation, Section 2 provides a brief
introduction to information theory, that is, to the mathematical
theory of communication (MTC). MTC deserves a space of its own because
it is the quantitative approach to the analysis of information that
has been most influential among several philosophers. It provides the
necessary background to understand several contemporary theories of
semantic information, especially Bar-Hillel and Carnap [1953], Dretske
[1981].</p>

<p>

Section 3 analyses information as semantic content. Section 4 focuses
entirely on the philosophical understanding of semantic information,
what Euphranor really loves.</p>

<p>

The reader must also be warned that an initial account of semantic
information as <em>meaningful data</em> will be used as yardstick to
outline other approaches. Unfortunately, even such a minimalist account
is open to disagreement. In favour of this approach one may say that at
least it is less controversial than others. Of course, a conceptual
analysis must start somewhere. This often means adopting some working
definition of the object under scrutiny. But it is not this commonplace
that one needs to emphasize here. The difficulty is rather more
daunting. Philosophical work on the concept of (semantic) information
is still at that lamentable stage when disagreement affects even the
way in which the problems themselves are provisionally phrased and
framed. Nothing comparable to the well-polished nature of the Gettier
problem is yet available, for example. So the &ldquo;you are
here&rdquo; signal provided in this article might be placed elsewhere
by other philosophers. The whole purpose is to put the concept of
semantic information firmly on the philosophical map. Further
adjustments will then become possible.</p>

</div>

<div id="toc">
<!--Entry Contents-->
<ul>

<li><a href="#1">1. An informational map</a>

 <ul>
 <li><a href="#1.1">1.1 An everyday example of information</a></li>
 <li><a href="#1.2">1.2 The data-based definition of information</a></li>
 <li><a href="#1.3">1.3 A definition of data</a></li>
 <li><a href="#1.4">1.4 Taxonomic neutrality</a></li>
 <li><a href="#1.5">1.5 Typological neutrality</a></li>
 <li><a href="#1.6">1.6 Ontological neutrality</a></li>
 <li><a href="#1.7">1.7 Genetic neutrality</a>

 <ul>
 <li><a href="#1.7.1">1.7.1 Environmental information</a></li>
 </ul>
 </li>

 <li><a href="#1.8">1.8 Summary of the first part</a></li>
 </ul>
 </li>

<li><a href="#2">2. Information as data communication</a>

 <ul>
 <li><a href="#2.1">2.1 The mathematical theory of communication</a></li>
 <li><a href="#2.2">2.2 Conceptual implications of the mathematical theory of communication</a></li>
 </ul>
 </li>

 <li><a href="#3">3. Information as semantic content</a>
 
 <ul>
 <li><a href="#3.1">3.1 Instructional information</a></li>
 <li><a href="#3.2">3.2 Factual information</a>

 <ul>
 <li><a href="#3.2.1">3.2.1 Constraining affordances</a></li>
 <li><a href="#3.2.2">3.2.2 Levels of abstraction</a></li>
 <li><a href="#3.2.3">3.2.3 Information and truth</a></li>
 </ul>
 </li>
 </ul>
 </li>

 <li><a href="#4">4. Philosophical approaches to semantic information</a>
 <ul>
 <li><a href="#4.1">4.1 The Bar-Hillel-Carnap Paradox</a></li>
 <li><a href="#4.2">4.2 The strongly semantic approach to information</a></li>
 </ul> 
 </li>

 <li><a href="#5">5. Conclusion</a></li>

<li><a href="#Bib">Bibliography</a></li>

<li><a href="#Aca">Academic Tools</a></li>

<li><a href="#Oth">Other Internet Resources</a></li>

<li><a href="#Rel">Related Entries</a></li>

</ul>
<!--Entry Contents-->

<hr />

</div>

<div id="main-text">

<h2><a name="1">1. An informational map</a></h2>

<p>

Information is a conceptual labyrinth, and in this section we shall
begin to have a look at a general map of one of its regions, with the
purpose of placing ourselves squarely in the semantic area. Figure 1
summarises the main distinctions that are going to be introduced.</p>

<div class="figure">
 <img alt="Figure 1" src="figure1.jpg" />
<p class="center"><span class="figlabel">Figure 1.</span>
An informational map
</p></div>

<p>

Clearly, percolating through the various points in the map will not
make for a linear journey. Using a few basic examples, to illustrate
the less obvious steps, will also help to keep our orientation. So let
us introduce immediately the one to which we shall return more
often.</p>

<h3><a name="1.1">1.1 An everyday example of information</a></h3>

<p>

Monday morning. You turn on the ignition key of your car, but
nothing happens: the engine does not even cough. The silence of the
engine worries you. Unsurprisingly, you also notice that the red light
of the low battery indicator is flashing. After a few more attempts,
you give up and ring the garage. You explain that your husband forgot
to switch off the lights of the car last night&mdash;it is a lie, you
did, but you are too ashamed to confess it&mdash;and now the battery
is flat. The mechanic tells you that the instruction manual of your car
explains how to use jump leads to start the engine. Luckily, your
neighbour has everything you need. You read the manual, look at the
illustrations, follow the instructions, solve the problem and finally
drive to the office.</p>

<p>

This everyday episode will be our &ldquo;fruit fly&rdquo;. Although
it is simple and intuitive, it provides enough details to illustrate
the many ways in which we understand one of our most important
resources: <em>information</em>.</p>

<h3><a name="1.2">1.2 The data-based definition of information</a></h3>

<p>

It is common to think of information as consisting of <em>data</em>.
It certainly helps, if only to a limited extent. For, unfortunately,
the nature of data is not well-understood philosophically either,
despite the fact that some important past debates&mdash;such as the
one on the given and the one on sense data&mdash;have provided at
least some initial insights. There still remains the advantage,
however, that the concept of data is less rich, obscure and slippery
than that of information, and hence easier to handle. So a data-based
definition of information seems to be a good starting point.</p>

<p>

Over the last three decades, several analyses in Information
Science, in Information Systems Theory, Methodology, Analysis and
Design, in Information (Systems) Management, in Database Design and in
Decision Theory have adopted a <em>General Definition of
Information</em> (GDI) in terms of <em>data + meaning</em>.

GDI has become an operational
standard, especially in fields that treat data and information as
reified entities (consider, for example, the now common expressions
&ldquo;data mining&rdquo; and &ldquo;information management&rdquo;).
Recently, GDI has begun to influence the philosophy of computing and
information (Floridi [1999] and Mingers [1997]).</p>

<p>
A clear way of formulating GDI is as a tripartite defintion:</p>

<blockquote>
 <strong>The General Definition of Information (GDI):</strong> <br />
 \(\sigma\) is an instance of information, understood as semantic
content, if and only if:
 
 <blockquote>
 <p>
 (GDI.1) \(\sigma\) consists of one or more <em>data</em>;</p>

 <p>
 (GDI.2) the data in \(\sigma\) are <em>well-formed</em>;</p>

 <p>
 (GDI.3) the well-formed data in \(\sigma\) are <em>meaningful</em>.</p>
 </blockquote>
</blockquote>

<p>

GDI requires a definition of data. This will be provided in the next
section. Before, a brief comment on each clause is in order. </p>

<p>
 According to (GDI.1), data are the stuff of which information is
made. We shall see that things can soon get more complicated. </p>

<p>
 In (GDI.2), &ldquo;well-formed&rdquo; means that the data are
clustered together correctly, according to the rules (<em>syntax</em>)
that govern the chosen system, code or language being analysed. Syntax
here must be understood broadly (not just linguistically), as what
determines the form, construction, composition or structuring of
something (engineers, film directors, painters, chess players and
gardeners speak of syntax in this broad sense). For example, the
manual of your car may show (see Figure 2) a two dimensional picture
of the two cars placed one near the other, not one on top of the
other.</p>

<div class="figure">
 <img alt="Figure 2" src="figure2.jpg" />
<p class="center"><span class="figlabel">Figure 2.</span>
How to jump start your car (Copyright &copy; Bosch UK)
</p></div>

<p>

This pictorial syntax (including the linear perspective that
represents space by converging parallel lines) makes the illustrations
potentially meaningful to the user. Using the same example, the actual
battery needs to be connected to the engine in a correct way to
function: this is still syntax, in terms of correct physical
architecture of the system (thus a disconnected battery is a syntactic
problem). And of course the conversation you carry on with your
neighbour follows the grammatical rules of English: this is syntax in
the ordinary linguistic sense.</p>

<p>

Regarding (GDI.3), this is where semantics finally occurs.
&ldquo;Meaningful&rdquo; means that the data must comply with the
meanings (<em>semantics</em>) of the chosen system, code or language
in question. However, let us not forget that semantic information is
not necessarily linguistic. For example, in the case of the manual of
the car, the illustrations are such as to be visually meaningful to
the reader.</p>

<h3><a name="1.3">1.3 A definition of data</a></h3>

<p>

According to GDI, information cannot be dataless but, in the simplest
case, it can consist of a single datum. Now a datum is reducible to
just a lack of uniformity (<em>diaphora</em> is the Greek word for
&ldquo;difference&rdquo;), so a general definition of a datum is:</p>

<blockquote>
 <strong>The Diaphoric Definition of Data (DDD):</strong><br />
 A datum is a putative fact regarding some difference or lack
 of uniformity within some context.
</blockquote>

<p>

Depending on philosophical inclinations, DDD can be applied at three
levels:</p>

<ol>

<li>data as diaphora <em>de re</em>, that is, as lacks of uniformity
in the real world out there. There is no specific name for such
&ldquo;data in the wild&rdquo;. A possible suggestion is to refer to
them as <em>dedomena</em> (&ldquo;data&rdquo; in Greek; note that our
word &ldquo;data&rdquo; comes from the Latin translation of a work by
Euclid entitled <em>Dedomena</em>). Dedomena are not to be confused
with environmental data (see section 1.7.1). They are pure data or
proto-epistemic data, that is, data before they are epistemically
interpreted. As &ldquo;fractures in the fabric of being&rdquo; they
can only be posited as an external anchor of our information, for
dedomena are never accessed or elaborated independently of a <em>level
of abstraction</em> (more on this in section 3.2.2). They can be
reconstructed as ontological requirements, like Kant&rsquo;s
<em>noumena</em> or Locke&rsquo;s <em>substance</em>: they are not
epistemically experienced but their presence is empirically inferred
from (and required by) experience. Of course, no example can be
provided, but dedomena are whatever lack of uniformity in the world is
the source of (what looks to information systems like us as) data,
e.g., a red light against a dark background. Note that the point here
is not to argue for the existence of such pure data in the wild, but
to provide a distinction that (in section 1.6) will help to clarify
why some philosophers have been able to accept the thesis that there
can be no information without data representation while rejecting the
thesis that information requires physical implementation;</li>

<li>data as diaphora <em>de signo</em>, that is, lacks of uniformity
between (the perception of) at least two physical states, such as a
higher or lower charge in a battery, a variable electrical signal in a
telephone conversation, or the dot and the line in the Morse alphabet;
and</li>

<li>data as diaphora <em>de dicto</em>, that is, lacks of uniformity
between two symbols, for example the letters A and B in the Latin
alphabet.</li>

</ol>

<p>
 Depending on one&rsquo;s position with respect to the thesis of ontological
neutrality (section 1.6) and the nature of environmental information
(section 1.7.1) dedomena in (1) may be either identical with, or what
makes possible signals in (2), and signals in (2) are what make
possible the coding of symbols in (3).</p>

<p>

The dependence of information on the occurrence of syntactically
well-formed data, and of data on the occurrence of differences
variously implementable physically, explain why information can so
easily be decoupled from its support. The actual <em>format</em>,
<em>medium</em> and <em>language</em> in which semantic information is
encoded is often irrelevant and hence disregardable. In particular,
the same semantic information may be analog or digital, printed on
paper or viewed on a screen, in English or in some other language,
expressed in words or pictures. Interpretations of this
support-independence can vary quite radically. For DDD (above) leaves
underdetermined</p>

<ul>

<li>the classification of the relata (<em>taxonomic
neutrality</em>);</li>

<li>the logical type to which the relata belong (<em>typological
neutrality</em>);</li>

<li>the kind of support required for the implementation of their
inequality (<em>ontological neutrality</em>); and</li>

<li>the dependence of their semantics on a producer (<em>genetic
neutrality</em>).</li>
</ul>

<p>

We shall now look at each form of neutrality in turn.</p>

<h3><a name="1.4">1.4 Taxonomic neutrality</a></h3>

<p>

A datum is usually classified as the entity exhibiting the anomaly,
often because the latter is perceptually more conspicuous or less
redundant than the background conditions. However, the relation of
inequality is binary and symmetric. A white sheet of paper is not just
the necessary background condition for the occurrence of a black dot as
a datum, it is a constitutive part of the [black-dot-on-white-sheet]
datum itself, together with the fundamental relation of inequality that
couples it with the dot. Nothing seems to be a datum <em>per se</em>.
Rather, being a datum is an external property. So GDI endorses the
following thesis of taxonomic neutrality:</p>

<blockquote>
 <strong>Taxonomic Neutrality</strong> <strong>(TaN)</strong>:<br />
 A datum is a relational entity.
</blockquote>

<p>

The slogan is &ldquo;data are relata&rdquo;, but GDI is neutral with
respect to the identification of data with <em>specific</em>
relata. In our example, GDI refrains from identifying either the red
light or the white background as the datum. To understand why there
cannot be &ldquo;dataless information&rdquo;, we shall now look at the
typological neutrality of GDI.</p>

<h3><a name="1.5">1.5 Typological neutrality</a></h3>

<p>

GDI also endorses the thesis of typological neutrality:</p>

<blockquote>
 <strong>Typological Neutrality (TyN)</strong>: <br />
 Information can consist of different types of data as relata.
 </blockquote>

<p>
 Five classifications are quite common, although the
terminology is not yet standard or fixed. 

They are not mutually exclusive, and one should not
understand them as rigid: depending on circumstances, on the sort of
analysis conducted and on the level of abstraction adopted, the same
data may fit different classifications.</p>

<table class="cellpad-small vert-top jfy">
 <tr>
 <td>(D1)</td>
 <td><em>Primary data</em>. These are the principal data stored e.g.
in a database, for example a simple array of numbers. They are the data
an information-management system&mdash;such as the one used in the
car to indicate that the battery needs to be charged&mdash;is
generally designed to convey (in the form of information) to the user
in the first place. Normally, when speaking of data, and of the
corresponding information they constitute, one implicitly assumes that
<em>primary</em> data/information is what is in question. So, by
default, the red light of the low battery indicator flashing is assumed
to be an instance of primary data conveying primary information.</td>
 </tr>

<tr>
 <td>(D2)</td>
 <td><em>Secondary data</em>. These are the converse of primary data,
constituted by their absence (one could call them anti-data). Recall
how you first suspected that the battery was flat: the engine failed
to make any of the usual noise. Likewise, in <em>Silver Blaze</em>,
Sherlock Holmes solves the case by noting something that has escaped
everybody else: the unusual silence of the dog. Clearly, silence may
be very informative. This is a peculiarity of information: its absence
may also be informative. When it is, the point is stressed by speaking
of <em>secondary information</em>.</td>
</tr>

<tr>
 <td>(D3)</td>
 <td><em>Metadata</em>. These are indications about the nature of
some other (usually primary) data. They describe properties such as
location, format, updating, availability, usage restrictions, and so
forth. Correspondingly, <em>metainformation</em> is information about
the nature of information. &ldquo;&lsquo;The battery is flat&rsquo; is
encoded in English&rdquo; is a simple example.</td>
</tr>

<tr>
 <td>(D4)</td>
 <td><em>Operational data</em>. These are data regarding the
operations of the whole data system and the system&rsquo;s performance.
Correspondingly, <em>operational information</em> is information about
the dynamics of an information system. Suppose the car has a yellow
light that, when flashing, indicates that the car checking system is
malfunctioning. The fact that the light is on may indicate that the low
battery indicator is not working properly, thus undermining the
hypothesis that the battery is flat.</td>
</tr>

<tr>
 <td>(D5)</td>
 <td><em>Derivative data</em>. These are data that can be extracted
from some data whenever the latter are used as indirect sources in
search of patterns, clues or inferential evidence about other things
than those directly addressed by the data themselves, e.g., for
comparative and quantitative analyses (<em>ideometry</em>). As it is
difficult to define this category precisely, a familiar example may be
helpful to convey the point. Credit cards notoriously leave a trail of
derivative information. From someone&rsquo;s credit card bill, concerning
e.g., the purchase of petrol in a certain petrol station, one may
derive the information of her whereabouts at a given time. Again,
derivative information is not something new. Hume provides a beautiful
example in these days of global warming. In the <em>Essays Moral,
Political, and Literary</em> (1777, Part II, Essay 11. Of the Populousness
of Ancient Nations, Para. 155/186 mp. 448 gp. 432, see now Hume
[1987]) he reports that &ldquo;It is an observation of L&rsquo;Abbe du Bos
that Italy is warmer at present than it was in ancient
times. &lsquo;<em>The annals of Rome</em> tell us,&rsquo; says he,
&lsquo;that in the year 480 ab U.C. the winter was so severe that it
destroyed the trees. [&hellip;] Many passages of Horace suppose the
streets of Rome full of snow and ice. We should have more certainty
with regard to this point, had the ancients known the use of
thermometers: But their writers, without intending it, give us
information, sufficient to convince us, that the winters are now much
more temperate at Rome than formerly.&rdquo; Hume has just extracted
some derivative information from some primary information provided by
L&rsquo;Abbe du Bos.</td>
</tr>
</table>

<p>

Let us now return to our question: can there be dataless information?
GDI does not specify which types of data constitute information. This
<em>typological neutrality</em> (TyN, see above) is justified by the
fact that, when the apparent absence of data is not reducible to the
occurrence of <em>negative</em> primary data, what becomes available
and qualifies as information is some further non-primary information
\(\mu\) about \(\sigma\) constituted by some non-primary data
(D2)&ndash;(D5). For example, if a database query provides an answer,
it will provide at least a <em>negative</em> answer, e.g., &ldquo;no
documents found&rdquo;. This is primary negative information. However,
if the database provides no answer, either it fails to provide any
data at all, in which case no specific information \(\sigma\) is
available&mdash;so the rule &ldquo;no information without
data&rdquo; still applies&mdash;or it can provide some data to
establish, for example, that it is running in a loop. Likewise,
silence, this time as a reply to a question, could represent negative
primary information, e.g., as implicit assent or denial, or it could
carry some non-primary information, e.g., about the fact that the
person has not heard the question, or about the amount of noise in the
room.</p>

<h3><a name="1.6">1.6 Ontological neutrality</a></h3>

<p>

By rejecting the possibility of dataless information, GDI also
endorses the following modest thesis of ontological neutrality:</p>

<blockquote>
 <strong>Ontological Neutrality (ON)</strong>: <br />
 There can be no information without data representation.
</blockquote>

<p>

Following Landauer and Bennett [1985], and Landauer [1987]; [1991];
[1996], (ON) is often interpreted materialistically, as advocating the
impossibility of physically disembodied information, through the
equation &ldquo;representation = physical implementation&rdquo;, that
is:</p>

<blockquote>

(ON.1) There can be no information without physical implementation.

</blockquote>

<p>

(ON.1) is an inevitable assumption, when working on the physics of
computation, since computer science must necessarily take into account
the physical properties and limits of the data carriers. Thus, the
debate on (ON.1) has flourished especially in the context of the
philosophy of quantum information and computing (see Deutsch [1985];
[1997] and Di Vincenzo and Loss [1998]; Steane [1998] provides a
review). (ON.1) is also the ontological assumption behind the Physical
Symbol System Hypothesis in AI and Cognitive Science (Newell and Simon
[1976]). But (ON), and hence GDI, does not specify whether, ultimately,
the occurrence of every discrete state necessarily requires a
<em>material</em> implementation of the data representations. Arguably,
environments in which all entities, properties and processes are
ultimately noetic (e.g., Berkeley, Spinoza), or in which the material or
extended universe has a noetic or non-extended matrix as its
ontological foundation (e.g., Pythagoras, Plato, Descartes, Leibniz,
Fichte, Hegel), seem perfectly capable of upholding (ON) without
necessarily embracing (ON.1). The relata in DDD (above) could be
<em>dedomena</em>, such as Leibnizian monads, for example. Indeed, the
classic realism debate on the ultimate nature of &ldquo;being&rdquo;
can be reconstructed in terms of the possible interpretations of
(ON).</p>

<p>

All this explains why GDI is also consistent with two other popular
slogans, this time favourable to the proto-physical nature of
information and hence completely antithetic to (ON.1):</p>

<table class="cellpad-small vert-top jfy">
 <tr>
 <td>(ON.2)</td>
 <td><em>It from bit</em>. Otherwise put, every &ldquo;it&rdquo;
&mdash; every particle, every field of force, even the space-time
continuum itself&mdash;derives its function, its meaning, its very
existence (even if in some contexts indirectly) from the
apparatus-elicited answers to yes-or-no questions, binary choices,
<em>bits</em>. &ldquo;It from bit&rdquo; symbolizes the idea that
every item of the physical world has at bottom&mdash;a very deep
bottom, in most instances&mdash;an immaterial source and
explanation; that which we call reality arises in the last analysis
from the posing of yes-no questions and the registering of
equipment-evoked responses; in short, that all things physical are
information-theoretic in origin and that this is a <em>participatory
universe</em>. (Wheeler [1990], 5);</td>
 </tr>
</table>

<p>
 and</p>


<table class="cellpad-small vert-top jfy">
<tr>
 <td>(ON.3)</td>
 <td>[information is] a name for the content of what is exchanged with
the outer world as we adjust to it, and make our adjustment felt upon
it. (Wiener [1954], 17). Information is information, not
matter or energy. No materialism which does not admit this can survive
at the present day (Wiener [1961], 132).</td>
 </tr>
</table>

<p>

(ON.2) endorses an information-theoretic, metaphysical monism: the
universe&rsquo;s essential nature is digital, being fundamentally composed
of information as data/dedomena instead of matter or energy, with
material objects as a complex secondary manifestation (a similar
position has been defended more recently in physics by Frieden [1998],
whose work is based on a loosely Platonist perspective). (ON.2) may
but does not have to endorse a computational view of information
processes. (ON.3) advocates a more pluralistic approach along similar
lines. Both are compatible with GDI.</p>

<p>

A final comment concerning (GDI.3) can be introduced by discussing a
fourth slogan:</p>

<table class="cellpad-small vert-top jfy">
 <tr>
 <td>(ON.4)</td>
 <td>In fact, what we mean by information&mdash;the elementary unit
of information&mdash;is a difference which makes a
difference. (Bateson [1973], 428).</td>
 </tr>
</table>

<p>

(ON.4) is one of the earliest and most popular formulations of GDI
(see for example Franklin [1995], 34 and Chalmers [1996], 281). The
formulation usually attributed to Mackay [1969] (yet not to be found
in that text)&mdash;that is, &ldquo;information is a
<em>distinction</em> that makes a difference&rdquo;&mdash;predates
Bateson&rsquo;s but it is slightly different from it in that, by speaking of
&ldquo;distinction&rdquo; instead of &ldquo;difference&rdquo;, it has
an epistemological rather than an ontological twist. A
&ldquo;difference&rdquo; (a &ldquo;distinction&rdquo;) is just a
discrete state, namely a datum, and &ldquo;making a difference&rdquo;
simply means that the datum is &ldquo;meaningful&rdquo;, at least
potentially.</p>

<h3><a name="1.7">1.7 Genetic neutrality</a></h3>

<p>

Finally, let us consider the semantic nature of the data. How data
can come to have an assigned meaning and function in a semiotic system
in the first place is one of the hardest problems in semantics.
Luckily, the point in question here is not <em>how</em> but
<em>whether</em> data constituting information as semantic content can
be meaningful <em>independently</em> of an informee. The <em>genetic
neutrality</em> (GeN) supported by GDI states that:</p>

<blockquote>
 <strong>Genetic Neutrality (GeN)</strong>: <br />
 Data (as relata) can have a semantics <em>independently</em> of
any informee.
</blockquote>

<p>

Before the discovery of the Rosetta Stone, Egyptian hieroglyphics were
already regarded as information, even if their semantics was beyond
the comprehension of any interpreter. The discovery of an interface
between Greek and Egyptian did not affect the semantics of the
hieroglyphics but only its accessibility. This is the weak,
conditional-counterfactual sense in which (GDI.3) speaks of meaningful
data being embedded in information-carriers
informee-independently. GeN supports the possibility of
<em>information without an informed subject</em>, to adapt a Popperian
phrase. Meaning is not (at least not only) in the mind of the
user. GeN is to be distinguished from the stronger, realist thesis,
supported for example by Dretske [1981], according to which data could
also have their own semantics independently of an intelligent
<em>producer/informer</em>. This is also known as <em>environmental
information</em>, a concept sufficiently important to deserve a brief
presentation before we close this first part.</p>

<h4><a name="1.7.1">1.7.1 Environmental information</a></h4>

<p>

One of the most often cited example of environmental information is
the series of concentric rings visible in the wood of a cut tree trunk,
which may be used to estimate its age. Yet &ldquo;environmental&rdquo;
information does not need to be <em>natural</em>. Going back to our
example, when you turned the ignition key, the red light of the low
battery indicator flashed. This signal too can be interpreted as an
instance of environmental information.</p>

<p>

Environmental information is defined relative to an observer (an
information agent), who is supposed to have no direct access to pure
data in themselves. It requires two systems \(a\) and \(b\)
to be coupled in such a way that \(a\)&rsquo;s being (of type, or
in state) \(F\) is correlated to \(b\) being (of type, or in
state) \(G\), thus carrying for the observer the information that
\(b\) is \(G\) (this analysis is adapted from Barwise and
Seligman [1997], who improve on a similar account by Dretske
[1981]):</p>

<blockquote>
 <strong>Environmental information:</strong> <br />
 Two systems \(a\) and \(b\) are coupled in such a way that
\(a\)&rsquo;s being (of type, or in state) \(F\) is correlated to
\(b\) being (of type, or in state) \(G\), thus carrying for
the information agent the information that \(b\) is
\(G\).
 </blockquote>

<p>

The correlation above is usually <em>nomic</em> (it follows some
law). It may be engineered&mdash;as in the case of the low battery
indicator \((a)\) whose flashing \((F)\) is triggered by,
and hence it is informative about, the battery \((b)\) being flat
\((G)\). Or it may be natural, as when litmus&mdash;a natural
colouring matter from lichens&mdash;is used as an acid-alkali
indicator because it turns red in acid solutions and blue in alkaline
solutions. Other typical examples include the correlation between
fingerprints and personal identification.</p>

<p>

One may be so used to see the low battery indicator flashing as
carrying the information that the battery is flat to find it hard to
distinguish, with sufficient clarity, between environmental and
semantic information. However, it is important to stress that
environmental information may require or involve no semantics at all.
It may consist of (networks or patterns of) correlated data understood
as mere differences or constraining affordances. Plants (e.g., a
sunflower), animals (e.g., an amoeba) and mechanisms (e.g., a
photocell) are certainly capable of making practical use of
environmental information even in the absence of any (semantic
processing of) <em>meaningful</em> data.</p>

<h3><a name="1.8">1.8 Summary of the first part</a></h3>

<p>

To summarise, GDI defines information, broadly understood, as
syntactically well-formed and meaningful data. Its four types of
neutrality (TaN, TyN, ON and GeN) represent an obvious advantage, as
they make GDI perfectly scalable to more complex cases and reasonably
flexible in terms of applicability and compatibility. Indeed,
philosophers have variously interpreted and tuned these four
neutralities according to their theoretical needs.</p>

<p>

Our next step is to check whether GDI is satisfactory when discussing
the most important type of semantic information, namely factual
information. Before addressing this issue, however, we need to pause
and look at the <em>mathematical theory of communication</em>
(MTC).</p>

<p>

MTC is not the only successful mathematical approach to the concept
of information. <em>Fisher information</em> (Frieden [2004]) and the
<em>algorithmic information theory</em> (Chaitin [1987]) provide two
other important examples. However, MTC is certainly the most widely
known among philosophers. As such, it has had a profound impact on
philosophical analyses of semantic information, to which it has
provided both the technical vocabulary and at least the initial
conceptual frame of reference. One needs to grasp its main gist if one
wishes to make sense of the issuing philosophical debate.</p>

<h2><a name="2">2. Information as data communication</a></h2>

<p>

Some features of information are intuitive. We are used to information
being <em>encoded</em>, <em>transmitted</em> and <em>stored</em>. One
also expects it to be <em>additive</em> (information \(a +\)
information \(b =\) information \(a + b)\) and
<em>non-negative</em>, like other things in life, such as
probabilities and interest rates. If you ask a question, the worst
scenario is that you receive no answer or a wrong answer, which will
leave you with zero new information.</p>

<p>

Similar properties of information are quantifiable. They are
investigated by the <em>mathematical theory of communication</em> (MTC)
with the primary aim of devising efficient ways of encoding and
transferring data.</p>

<p>

The name for this branch of probability theory comes from Shannon&rsquo;s
seminal work (Shannon and Weaver [1949]). Shannon pioneered this
field and obtained many of its principal results, but he acknowledged
the importance of previous work done by other researchers and
colleagues at Bell laboratories, most notably Nyquist and Hartley (see
Cherry [1978] and Mabon [1975]). After Shannon, MTC became known as
<em>information theory</em>, an appealing but unfortunate label, which
continues to cause endless misunderstandings. Shannon came to regret
its widespread popularity, and we shall avoid using it in this
context.</p>

<p>

This second part of the article outlines some of the key ideas
behind MTC, with the aim of understanding the relation between MTC and
some philosophical theories of semantic information. The reader with no
taste for mathematical formulae may wish to go directly to section 2.2,
where some conceptual implications of MTC are outlined. The reader
interested in knowing more may start by reading Weaver [1949], Pierce
[1980], Shannon and Weaver [1949 rep. 1998], then Jones [1979], and
finally Cover and Thomas [1991]. The latter two are technical texts.
Floridi [2010] provides a brief and simplified analysis oriented to philosophy
students.
</p>

<h3><a name="2.1">2.1 The mathematical theory of communication</a></h3>

<p>

MTC has its origin in the field of electrical engineering, as the
study of communication limits. It develops a quantitative approach to
information as a means to answer two fundamental problems: the ultimate
level of data compression (how small can a message be, given the same
amount of information to be encoded?) and the ultimate rate of data
transmission (how fast can data be transmitted over a channel?). The
two solutions are the entropy \(H\) in equation [9] (see below)
and the channel capacity \(C\). The rest of this section
illustrates how to get from the problems to the solutions.</p>

<p>

To have an intuitive sense of the approach, let us return to our
example. Recall the telephone conversation with the mechanic. In Figure
2, the wife is the <em>informer</em>, the mechanic is the
<em>informee</em>, &ldquo;the battery is flat&rdquo; is the (semantic)
message (the <em>informant</em>), there is a coding and decoding
procedure through a natural language (English), a channel of
communication (the telephone system) and some possible noise. Informer
and informee share the same background knowledge about the collection
of usable symbols (technically known as the <em>alphabet</em>; in the
example this is English).</p>

<div class="figure">
 <img src="figure3.jpg" alt="Figure 3" width="600" />
<p class="center"><span class="figlabel">Figure 3.</span>
Communication model (adapted from Shannon and Weaver [1949])
</p></div>

<p>

MTC is concerned with the efficient use of the resources indicated in
Figure 3. Now, the conversation with the mechanic is fairly realistic
and hence more difficult to model than a simplified case. We shall
return to it later but, in order to introduce MTC, imagine instead a
very boring device that can produce only one symbol. Edgar Alan Poe
wrote a short story in which a raven can answer only
&ldquo;nevermore&rdquo; to any question. Poe&rsquo;s raven is called a
<em>unary device</em>. Imagine you ring the garage and your call is
answered by Poe&rsquo;s raven. Even at this elementary level, Shannon&rsquo;s
simple model of communication still applies. It is obvious that the
raven (a unary device) produces zero amount of
information. Simplifying, we already know the outcome of the
communication exchange, so our ignorance (expressed by our question)
cannot be decreased. Whatever the informational state of the system
is, asking appropriate questions (e.g., &ldquo;Will I be able to make
the car start?&rdquo;, &ldquo;Can you come to fix the car?&rdquo;) of
the raven does not make any difference. Note that, interestingly
enough, this is the basis of Plato&rsquo;s famous argument in the
<em>Phaedrus</em> against the value of semantic information provided
by written texts: </p>

<blockquote>
<p>
[Socrates]: Writing, Phaedrus, has this
strange quality, and is very like painting; for the creatures of
painting stand like living beings, but if one asks them a question,
they preserve a solemn silence. And so it is with written words; you
might think they spoke as if they had intelligence, but if you
question them, wishing to know about their sayings, they always say
only one and the same thing [they are unary devices, in our
terminology]. And every word, when [275e] once it is written, is
bandied about, alike among those who understand and those who have no
interest in it, and it knows not to whom to speak or not to speak;
when ill-treated or unjustly reviled it always needs its father to
help it; for it has no power to protect or help itself.
</p>
</blockquote>

<p>

As Plato well realises a unary source answers every question all the
time with only one message, not with silence or message, since silence
counts as a message, as we saw in 2.5, when discussing the nature of
secondary information. It follows that a completely silent source also
qualifies as a unary source. And if silencing a source (censorship) may
be a nasty way of making a source uninformative, it is well known that
crying wolf is a classic case in which an informative source degrades
to the role of uninformative unary device.</p>

<p>

Consider now a binary device that can produce two symbols, like a fair
coin \(A\) with its two equiprobable symbols \(\{h, t\}\); or, as
Matthew 5:37 suggests, &ldquo;Let your communication be Yea, yea; Nay,
nay: for whatsoever is more than these cometh of evil&rdquo;. Before
the coin is tossed, the informee (for example a computer) is in a
state of <em>data deficit</em> greater than zero: the informee does
not &ldquo;know&rdquo; which symbol the device will actually
produce. Shannon used the technical term &ldquo;uncertainty&rdquo; to
refer to data deficit. In a non-mathematical context this can be a
very misleading term because of the strong epistemological
connotations of this term. Remember that the informee can be a simple
machine, and psychological, mental or doxastic states are clearly
irrelevant.</p>

<p>

Once the coin has been tossed, the system produces an amount of
information that is a function of the possible outputs, in this case 2
equiprobable symbols, and equal to the data deficit that it
removes.</p>

<p>

Let us now build a slightly more complex system, made of two fair
coins \(A\) and \(B\). The \(AB\) system can produce 4 ordered
outputs: \(\langle h, h\rangle , \langle h, t\rangle , \langle t, h\rangle , \langle t, t\rangle\). It
generates a data deficit of 4 units, each couple counting as a symbol
in the source alphabet. In the \(AB\) system, the occurrence of each
symbol \(\langle \cdot, \cdot \rangle\) removes a higher data deficit than the
occurrence of a symbol in the \(A\) system. In other words, each
symbol provides more information. Adding an extra coin would produce a
8 units of data deficit, further increasing the amount of information
carried by each symbol in the \(ABC\) system, and so on.</p>

<p>

We are now ready to generalise the examples. Call the number of
possible symbols \(N\). For \(N = 1\), the amount of
information produced by a unary device is 0. For \(N = 2\), by
producing an equiprobable symbol, the device delivers 1 unit of
information. And for \(N = 4\), by producing an equiprobable
symbol the device delivers the sum of the amount of information
provided by a device producing one of two equiprobable symbols (coin
\(A\) in the example above) plus the amount of information
provided by another device producing one of two equiprobable symbols
(coin \(B)\), that is, 2 units of information, although the total
number of symbols is obtained by multiplying \(A\)&rsquo;s symbols by
\(B\)&rsquo;s symbols. Now, our information measure should be a
continuous and monotonic function of the probability of the symbols.
The most efficient way of satisfying these requirements is by using
the logarithm to the base 2 of the number of possible symbols (the
logarithm to the base 2 of a number \(n\) is the power to which 2
must be raised to give the number \(n\), for example
\(\log_2 8 = 3\), since \(2^3 = 8)\). Logarithms have the
useful property of turning multiplication of symbols into addition of
information units. By taking the logarithm to the base 2 (henceforth
log simply means \(\log_2)\) we have the further advantage of
expressing the units in bits. The base is partly a matter of
convention, like using centimetres instead of inches, partly a matter
of convenience, since it is useful when dealing with digital devices
that use binary codes to represent data.</p>

<p>

Given an alphabet of \(N\) equiprobable symbols, we can now
use equation [1]:</p>

\[\begin{align}\tag{1}
&amp;\text{average informativeness per symbol (uncertainty)} = \\
&amp;\qquad\log_2(N) \text{ bits of information}
\end{align}\]

<p>
 to rephrase some examples more precisely:</p>

<table class="hrules cellpad-med-dense vert-top centered">
<tr>
<td><strong>Device</strong></td>
<td><strong>Alphabet</strong></td>
<td><strong>Bits of information<br />per symbol</strong></td>
</tr>

<tr>
<td>Poe&rsquo;s raven (unary)</td>
<td>1 symbol</td>
<td>\(\log(1) = 0\)</td>
</tr>

<tr>
<td>1 coin (binary)</td>
<td>2 equiprobable symbols</td>
<td>\(\log(2) = 1\)</td>
</tr>

<tr>
<td>2 coins</td>
<td>4 equiprobable symbols</td>
<td>\(\log(4) = 2\)</td>
</tr>

<tr>
<td>1 die</td>
<td>6 equiprobable symbols</td>
<td>\(\log(6) = 2.58\)</td>
</tr>

<tr>
<td>3 coins</td>
<td>8 equiprobable symbols</td>
<td>\(\log(8) = 3\)</td>
</tr>
</table>

<p>
<strong>Some communication devices and their information power</strong></p>

<p>

The basic idea is all in equation [1]. Information can be quantified
in terms of decrease in data deficit (Shannon&rsquo;s
&ldquo;uncertainty&rdquo;). Unfortunately, real coins are always
biased. To calculate how much information they produce one must rely
on the frequency of the occurrences of symbols in a finite series of
tosses, or on their probabilities, if the tosses are supposed to go on
indefinitely. Compared to a fair coin, a slightly biased coin must
produce less than 1 bit of information, but still more than 0. The
raven produced no information at all because the occurrence of a
string \(S\) of &ldquo;nevermore&rdquo; was not
<em>informative</em> (not <em>surprising</em>, to use Shannon&rsquo;s more
intuitive, but psychologistic vocabulary), and that is because the
<em>probability</em> of the occurrence of &ldquo;nevermore&rdquo; was
maximum, so overly predictable. Likewise, the amount of information
produced by the biased coin depends on the average
<em>informativeness</em> (also known as average <em>surprisal</em>,
another unfortunate term to refer to the average statistical rarity)
of the string \(S\) of \(h\) and \(t\) produced by the
coin. The average informativeness of the resulting string \(S\)
depends on the <em>probability</em> of the occurrence of each symbol.
The higher the frequency of a symbol in \(S\), the less
information is being produced by the coin, up to the point when the
coin is so biased to produce always the same symbol and stops being
informative at all, behaving like the raven or the boy who cries
wolf.</p>

<p>

So, to calculate the average informativeness of \(S\) we need to know
how to calculate \(S\) and the informativeness of the
\(i^{\text{th}}\) symbol in general. This requires understanding what
the probability of the \(i^{\text{th}}\) symbol \((P_i)\) to occur is.</p>

<p>

The probability \(P_i\) of the \(i^{\text{th}}\) symbol can be
&ldquo;extracted&rdquo; from equation [1], where it is embedded in
\(\log(N)\), a special case in which the symbols are
equiprobable. Using some elementary properties of the logarithmic
function, we have:</p>

\[\tag{2}
\log(N) = -\log(N^{-1}) = -\log(1/N) = -\log(P)
\]

<p>

The value of \(1/N = P\) can range from 0 to 1. If Poe&rsquo;s raven
is our source, the probability of it saying &ldquo;good morning&rdquo;
is 0. In the case of the coin, \(P(h) + P(t) = 1\), no matter how
biased the coin is. Probability is like a cake that gets sliced more
and more thinly depending on the number of guests, but never grows
beyond its original size and, in the worst case scenario, can at most
be equal to zero, but never become &ldquo;negative&rdquo;. More
formally, this means:</p>

\[\tag{3}
\sum_{i=1}^N P_i = 1
\]

<p>

The sigma notation in [3] is simply a shortcut that indicates that
if we add all probabilities values from \(i = 1\) to \(i =\)
N their sum is equal to 1.</p>

<p>

We can now be precise about the raven: &ldquo;nevermore&rdquo; is not
informative at all because \(P_{nevermore} = 1\). Clearly, the lower
the probability of occurrence of a symbol, the higher is the
informativeness of its actual occurrence. The informativeness \(u\) of
the \(i^{\text{th}}\) symbol can be expressed by analogy with
\(-\log(P)\) in equation [4]:</p>

\[\tag{4}
u_i = -\log(P_i)
\]

<p>
 Next, we need to calculate the length of a general string
\(S\). Suppose that the biased coin, tossed 10 times, produces the
string: \(\langle h, h, t, h, h, t, t, h, h, t\rangle\). The (length of the)
string \(S\) (in our case equal to 10) is equal to the number of times
the \(h\) type of symbol occurs added to the numbers of times the
\(t\) type of symbol occurs.</p>

<p>

Generalising for \(i\) types of symbols:</p>

\[\tag{5}
S = \sum_{i=1}^N S_i
\]

<p>

Putting together equations [4] and [5] we see that the average
informativeness for a string of \(S\) symbols is the sum of the
informativeness of each symbol divided by the sum of all symbols:</p>

\[\tag{6}
\frac{\sum_{i=1}^N S_i u_i}{\sum_{i=1}^N S_i}
\]

<p>

Term [6] can be simplified thus:</p>

\[\tag{7}
\sum_{i=1}^N \frac{S_i}{S} u_i
\]

<p>

Now \(S_i /S\) is the frequency with which the \(i^{\text{th}}\)
symbol occurs in \(S\) when \(S\) is finite. If the length of \(S\) is
left undetermined (as long as one wishes), then the frequency of the
\(i^{\text{th}}\) symbol becomes its probability \(P_i\). So, further
generalising term [7], we have:</p>

\[\tag{8}
\sum_{i=1}^N P_i u_i
\]

<p>

Finally, by using equation [4] we can substitute for
\(u_i\) and obtain</p>

\[\tag{9}
H = - \sum_{i=1}^N P_i \log P_i \text{ (bits per symbol)}
\]

<p>

Equation [9] is Shannon&rsquo;s formula for \(H =\) uncertainty, which
we have called <em>data deficit</em> (actually, Shannon&rsquo;s original
formula includes a positive constant \(K\) which amounts to a
choice of a unit of measure, bits in our case; apparently, Shannon
used the letter \(H\) because of R.V.L. Hartley&rsquo;s previous
work).</p>

<p>

Equation [9] indicates that the quantity of information produced by
a device corresponds to the amount of data deficit erased. It is a
function of the average informativeness of the (potentially unlimited)
string of symbols produced by the device. It is easy to prove that, if
symbols are equiprobable, [9] reduces to [1] and that the highest
quantity of information is produced by a system whose symbols are
equiprobable (compare the fair coin to the biased one).</p>

<p>

To arrive at [9] we have used some very simple examples: a raven and a
handful of coins. Things in life are far more complex, witness our
Monday morning accident. For example, we have assumed that the strings
of symbols are <em>ergodic</em>: the probability distribution for the
occurrences of each symbol is assumed to be stable through time and
independently of the selection of a certain string. Our raven and
coins are <em>discrete</em> and <em>zero-memory sources</em>. The
successive symbols they produce are statistically independent. But in
real life occurrences of symbols are often interdependent. Sources can
be non-ergodic and have a memory. Symbols can be continuous, and the
occurrence of one symbol may depend upon a finite number \(n\) of
preceding symbols, in which case the string is known as a Markov chain
and the source an \(n^{\text{th}}\) order Markov
source. Consider for example the probability of hearing
&ldquo;n&rdquo; (followed by the string &ldquo;ing&rdquo;) after
having received the string of letters &ldquo;Good mor_&rdquo; over the
phone, when you called the garage. And consider the same example
through time, in the case of a child (the son of the mechanic) who is
learning how to answer the phone instead of his father. In brief, MTC
develops the previous analysis to cover a whole variety of more
complex cases. We shall stop here, however, because in the rest of
this section we need to concentrate on other central aspects of
MTC.</p>

<p>

The quantitative approach just sketched plays a fundamental role in
coding theory (hence in cryptography) and in data storage and
transmission techniques. MTC is primarily a study of the properties of
a channel of communication and of codes that can efficiently encipher
data into recordable and transmittable signals. Since data can be
distributed either in terms of here/there or now/then, diachronic
communication and synchronic analysis of a memory can be based on the
same principles and concepts (our coin becomes a bistable circuit or
flip-flop, for example). Two concepts that play a pivotal role both in
communication analysis and in memory management are so important to
deserve a brief explanation: <em>redundancy</em> and
<em>noise</em>.</p>

<p>

Consider our \(AB\) system. Each symbol occurs with 0.25
probability. A simple way of encoding its symbols is to associate each
of them with two digits, as follows:</p>

<div class="indent">
 <strong>Code 1:</strong> <br />
<table class="cellpad-med notopmargin nocaption">
<tr>
<td>\(\langle h,h\rangle = 00\)</td>
<td>\(\langle h, t\rangle = 01\)</td>
<td>\(\langle t, h\rangle = 10\)</td>
<td>\(\langle t, t\rangle = 11\)</td>
</tr>
</table>
</div>

<p>

In Code 1 a message conveys 2 bits of information, as expected. Do not
confuse <em>bits</em> as <em>bi-</em>nary uni<em>ts</em> of
information (recall that we decided to use log\(_2\) also as a
matter of convenience) with <em>bits</em> as <em>bi-</em>nary
digi<em>ts</em>, which is what a 2-symbols system like a CD-ROM uses
to encode a message. Suppose now that the \(AB\) system is
biased, and that the four symbols occur with the following
probabilities:</p>

<div class="indent">
 <strong>A Biased System:</strong> 
 <table class="cellpad-med notopmargin nocaption">
 <tr>
<td>\(\langle h, h\rangle = 0.5\)</td>
<td>\(\langle h, t\rangle = 0.25\)</td>
<td>\(\langle t, h\rangle = 0.125\)</td>
<td>\(\langle t, t\rangle = 0.125\)</td>
</tr>
</table>
</div>

<p>

This biased system produces less information, so by using Code 1 we
would be wasting resources. A more efficient Code 2 (see below) should
take into account the symbols&rsquo; probabilities, with the following
outcomes:</p>

<div class="indent">
<strong>Code 2 (Fano Code):</strong> <br />
 <table class="cellpad-med-dense notopmargin nocaption">
 <tr>
 <td>\(\langle h, h\rangle = 0\)</td>
 <td>\(0.5 \times 1\) binary digit = .5</td>
 </tr>

<tr>
<td>\(\langle h, t\rangle = 10\)</td>
<td>\(0.25 \times 2\) binary digits = .5</td>
</tr>

<tr>
<td>\(\langle t, h\rangle = 110\)</td>
<td>\(0.125 \times 3\) binary digits = .375</td>
</tr>

<tr>
<td>\(\langle t, t\rangle = 111\)</td>
<td>\(0.125 \times 3\) binary digits = .375</td>
</tr>
</table>
</div>

<p>

In Code 2, known as Fano Code, a message conveys 1.75 bits of
information. One can prove that, given that probability distribution,
no other coding system will do better than Fano Code.</p>

<p>

In real life, a good codification is also modestly redundant.
<em>Redundancy</em> refers to the difference between the physical
representation of a message and the mathematical representation of the
same message that uses no more bits than necessary.
<em>Compression</em> procedures work by reducing data redundancy, but
redundancy is not always a bad thing, for it can help to counteract
<em>equivocation</em> (data sent but never received) and
<em>noise</em> (data received but unwanted). A message + noise
contains more data than the original message by itself, but the aim of
a communication process is <em>fidelity</em>, the accurate transfer of
the original message from sender to receiver, not data increase. We
are more likely to reconstruct a message correctly at the end of the
transmission if some degree of redundancy counterbalances the
inevitable noise and equivocation introduced by the physical process
of communication and the environment. Noise extends the informee&rsquo;s
freedom of choice in selecting a message, but it is an undesirable
freedom and some redundancy can help to limit it. That is why the
manual of your car includes both verbal explanations and pictures to
convey (slightly redundantly) the same information.</p>

<p>

We are now ready to understand Shannon&rsquo;s two fundamental
theorems. Suppose the 2-coins biased system \(AB\) produces the
following message: \(\langle t, h\rangle \langle h, h\rangle \langle t, t\rangle \langle h,
t\rangle \langle h, t\rangle\). Using Fano Code we
obtain: 11001111010. The next step is to send this string through a
channel. Channels have different transmission rates \((C)\),
calculated in terms of bits per second (bps). Shannon&rsquo;s fundamental
theorem of the noiseless channel states that:</p>

<blockquote>
<strong>Shannon&rsquo;s Fundamental Theorem of the Noiseless
 Channel:</strong><br /> Let a source have entropy \(H\) (bits
per symbol) and a channel have a capacity \(C\) (bits per
second). Then it is possible to encode the output of the source in
such a way as to transmit at the average rate of \(C/H - \varepsilon\)
symbols per second over the channel where \(\varepsilon\) is
arbitrarily small. It is not possible to transmit at an average rate
greater than \(C/H\). (Shannon and Weaver [1949], 59)
 </blockquote>

<p>

In other words, if you devise a good code you can transmit symbols
over a noiseless channel at an average rate as close to
\(C/H\) as one may wish but, no matter how clever the
coding is, that average can never exceed \(C/H\). We have
already seen that the task is made more difficult by the inevitable
presence of noise. However, the fundamental theorem for a discrete
channel with noise comes to our rescue:</p>

<blockquote>
<strong>Shannon&rsquo;s Fundamental Theorem for a Discrete
 Channel:</strong><br /> Let a discrete channel have the capacity
\(C\) and a discrete source the entropy per second \(H\). If \(H \le
C\) there exists a coding system such that the output of the source
can be transmitted over the channel with an arbitrarily small
frequency of errors (or an arbitrarily small equivocation). If \(H \rangle
C\) it is possible to encode the source so that the equivocation is
less than \(H - C + \varepsilon\) where \(\varepsilon\) is arbitrarily
small. There is no method of encoding which gives an equivocation less
than \(H - C\). (Shannon and Weaver [1949], 71)
 </blockquote>

<p>

Roughly, if the channel can transmit as much or more information than
the source can produce, then one can devise an efficient way to code
and transmit messages with as small an error probability as
desired. </p>

<p>
 These two fundamental theorems are among Shannon&rsquo;s greatest
achievements. They are limiting results in information theory that
constrain any conceptual analysis of semantic information. They are
thus comparable to G&ouml;del&rsquo;s, Turing&rsquo;s, and Church&rsquo;s theorems in
logic and computation. With our message finally sent, we may close
this section and return to a more philosophical approach.</p>

<h3><a name="2.2">2.2 Conceptual implications of the mathematical theory of communication</a></h3>

<p>

For the mathematical theory of communication (MTC), information is
only a selection of one symbol from a set of possible symbols, so a
simple way of grasping how MTC quantifies information is by
considering the number of yes/no questions required to determine what
the source is communicating. One question is sufficient to determine
the output of a fair coin, which therefore is said to produce 1 bit of
information. A 2-fair-coins system produces 4 ordered outputs: \(\langle
h, h\rangle , \langle h, t\rangle , \langle t, h\rangle , \langle t, t\rangle\) and therefore
requires at least two questions, each output containing 2 bits of
information, and so on. This <em>erotetic</em> (the Greek word for
&ldquo;question&rdquo;) analysis clarifies two important points.</p>

<p>

First, MTC is not a theory of information in the ordinary sense of
the word. In MTC, information has an entirely technical meaning.
Consider some examples. According to MTC, two equiprobable
&ldquo;yes&rdquo;&rsquo;s contain the same quantity of information, no
matter whether their corresponding questions are &ldquo;have the lights
of your car been left switched on for too long, without recharging the
battery?&rdquo; or &ldquo;would you marry me?&rdquo;. If we knew that a
device could send us, with equal probabilities, either this article or
the whole <em>Stanford Encyclopedia of Philosophy</em>, by receiving
one or the other we would receive very different amounts of bytes of
data but actually only one bit of information in the MTC sense of the
word. On June 1 1944, the BBC broadcasted a line from Verlaine&rsquo;s
<em>Song of Autumn</em>: &ldquo;Les sanglots longs des violons de
Autumne&rdquo;. The message contained almost 1 bit of information, an
increasingly likely &ldquo;yes&rdquo; to the question whether the D-Day
invasion was imminent. The BBC then broadcasted the second line
&ldquo;Blessent mon coeur d&rsquo;une longueur monotone&rdquo;. Another
almost meaningless string of letters, but almost another bit of
information, since it was the other long-expected &ldquo;yes&rdquo; to
the question whether the invasion was to take place immediately. German
intelligence knew about the code, intercepted those messages and even
notified Berlin, but the high command failed to alert the Seventh Army
Corps stationed in Normandy. Hitler had all the information in
Shannon&rsquo;s sense of the word, but failed to understand (or believe
in) the crucial importance of those two small bits of data. As for
ourselves, we were not surprised to conclude in the previous section
that the maximum amount of information (again, in the MTC sense of the
word) is produced by a text where each character is equally
distributed, that is by a perfectly random sequence. According to MTC,
the classic monkey randomly pressing typewriter keys is indeed
producing a lot of information.</p>

<p>

Second, since MTC is a theory of information without meaning (not in
the sense of meaningless, but in the sense of not yet meaningful), and
since we have seen that [information \(-\) meaning = data],
&ldquo;mathematical theory of data communication&rdquo; is a far more
appropriate description of this branch of probability theory than
&ldquo;information theory&rdquo;. This is not a mere question of
labels. Information, as semantic content (more on this shortly), can
also be described erotetically as <em>data + queries</em>. Imagine a
piece of (propositional) information such as &ldquo;the earth has only
one moon&rdquo;. It is easy to polarise almost all its semantic
content by transforming it into a [query + binary answer], such as
[does the earth have only one moon? + yes]. Subtract the
&ldquo;yes&rdquo;&mdash;which is at most 1 bit of information, in
the equiprobable case of a yes or no answer&mdash;and you are left
with virtually all the semantic content, fully de-alethicised (from
<em>aletheia</em>, the Greek word for truth; the query is neither true
nor false). To use a Fregean expression, <em>semantic content</em> is
<em>unsaturated information</em>, where the latter is semantic
information that has been &ldquo;eroteticised&rdquo; and from which a
quantity of information has been subtracted equal to
\(-\log P(\text{yes})\), with \(P\) being the
probability of the yes-answer.</p>

<p>

The datum &ldquo;yes&rdquo; works as a key to unlock the information
contained in the query. MTC studies the codification and transmission
of information by treating it as data keys, that is, as the amount of
details in a signal or message or memory space necessary to saturate
the informee&rsquo;s unsaturated information. As Weaver [1949] remarked
&ldquo;the word information relates not so much to what you do say, as
to what you could say. The mathematical theory of communication deals
with the carriers of information, symbols and signals, not with
information itself. That is, information is the measure of your freedom
of choice when you select a message&rdquo; (p. 12).</p>

<p>

Since MTC deals not with semantic information itself but with the
data that constitute it, that is, with messages comprising
uninterpreted symbols encoded in well-formed strings of signals, it is
commonly described as a study of information at the <em>syntactic</em>
level. MTC can be successfully applied in ICT (information and
communication technologies) because computers are syntactical devices.
What remains to be clarified is how \(H\) in equation [9] should
be interpreted.</p>

<p>

\(H\) is also known in MTC as <em>entropy</em>. It seems we owe
this confusing label to John von Neumann, who recommended it to Shannon:</p>

<blockquote>
<p>
&ldquo;You should call it entropy for two reasons: first, the function
is already in use in thermodynamics under the same name; second, and
more importantly, most people don&rsquo;t know what entropy really is,
and if you use the word <em>entropy</em> in an argument you will win
every time&rdquo; (quoted by Golan [2002]). 
</p>
</blockquote>

<p>Von Neumann proved to be right on both accounts, unfortunately.</p>

<p>

Assuming the ideal case of a noiseless channel of communication,
\(H\) is a measure of three equivalent quantities:</p>

<ol type="a">
 <li>the average amount of information per symbol produced by the
informer, or</li>
 <li>the corresponding average amount of data deficit (Shannon&rsquo;s
uncertainty) that the informee has before the inspection of the output
of the informer, or</li>
 <li>the corresponding informational potentiality of the same source,
that is, its <em>informational entropy</em>.</li>
 </ol>

<p>

\(H\) can equally indicate (a) or (b) because, by selecting a
particular alphabet, the informer automatically creates a data deficit
(uncertainty) in the informee, which then can be satisfied (resolved)
in various degrees by the <em>informant</em>. Recall the erotetic game.
If you use a single fair coin, I immediately find myself in a 1 bit
deficit predicament: I do not know whether it is head or tail. Use two
fair coins and my deficit doubles, but use the raven, and my deficit
becomes null. My empty glass (point (b) above) is an exact measure of
your capacity to fill it (point (a) above). Of course, it makes sense
to talk of information as quantified by \(H\) only if one can
specify the probability distribution.</p>

<p>

Regarding (c), MTC treats information like a physical quantity, such
as mass or energy, and the closeness between equation [9] and the
formulation of the concept of entropy in statistical mechanics was
already discussed by Shannon. The informational and the thermodynamic
concept of entropy are related through the concepts of probability and
<em>randomness</em> (&ldquo;randomness&rdquo; is better than
&ldquo;disorder&rdquo; since the former is a syntactical concept
whereas the latter has a strongly semantic value, that is, it is easily
associated to interpretations, as I used to try to explain to my
parents when I was young). Entropy is a measure of the amount of
&ldquo;mixedupness&rdquo; in processes and systems bearing energy or
information. Entropy can also be seen as an indicator of reversibility:
if there is no change of entropy then the process is reversible. A
highly structured, perfectly organised message contains a lower degree
of entropy or randomness, less information in Shannon sense, and hence
it causes a smaller data deficit, which can be close to zero (remember
the raven). By contrast, the higher the potential randomness of the
symbols in the alphabet, the more bits of information can be produced
by the device. Entropy assumes its maximum value in the extreme case of
uniform distribution, which is to say that a glass of water with a cube
of ice contains less entropy than the glass of water once the cube has
melted, and a biased coin has less entropy than a fair coin. In
thermodynamics, we know that the greater the entropy, the less
available the energy. This means that high entropy corresponds to high
energy deficit, but so does entropy in MTC: higher values of \(H\)
correspond to higher quantities of data deficit.</p>

<h2><a name="3">3. Information as semantic content</a></h2>

<p>

We have seen that, when data are well-formed and meaningful, the
result is also known as <em>semantic content</em> (Bar-Hillel and
Carnap [1953]; Bar-Hillel [1964]). Information, understood as semantic
content, comes in two main varieties: factual and instructional. In our
example, one may translate the red light flashing into semantic content
in two senses:</p>

<ol type="a">

<li>as a piece of factual information, representing the fact that the
battery is flat; and</li>

<li>as a piece of instructional information, conveying the need for a
specific action, e.g., the re-charging or replacing of the flat
battery.</li>

</ol>

<p>

In this third part of the article we shall be concerned primarily
with (a), so it is better to clear the ground by considering (b) first.
It is the last detour in our journey.</p>

<h3><a name="3.1">3.1 Instructional information</a></h3>

<p>

Instructional information is a type of semantic content. An
instruction booklet, for example, provides instructional information,
either imperatively&mdash;in the form of a recipe: first do this,
then do that&mdash;or conditionally, in the form of some inferential
procedure: if such and such is the case do this, otherwise do
that.</p>

<p>

Instructional information is not about a situation, a fact, or a
state of affairs \(w\) and does not model, or describe or
represent \(w\). Rather, it is meant to (help to) bring about
\(w\). For example, when the mechanic tells one over the phone to
connect a charged battery to the flat battery of one&rsquo;s car, the
information one receives is not factual, but instructional.</p>

<p>

There are many plausible contexts in which a stipulation (&ldquo;let
the value of \(x = 3\)&rdquo; or &ldquo;suppose we discover the
bones of a unicorn&rdquo;), an invitation (&ldquo;you are cordially
invited to the college party&rdquo;), an order (&ldquo;close the
window!&rdquo;), an instruction (&ldquo;to open the box turn the
key&rdquo;), a game move (&ldquo;1.e2-e4 c7-c5&rdquo; at the beginning
of a chess game) may be correctly qualified as kinds of instructional
information. The printed score of a musical composition or the digital
files of a program may also be counted as typical cases of
instructional information.</p>

<p>

All these instances of information have a semantic side: they have to
be at least potentially meaningful (interpretable) to count as
information. Moreover, instructional information may be related to
factual (descriptive) information in performative contexts, such as
christening (e.g., &ldquo;this ship is now called <em>HMS The
Informer</em>&rdquo;) or programming (e.g., as when deciding the type
of a variable). The two types of semantic information (instructional
and factual) may also come together in magic spells, where semantic
representations of \(x\) may be (wrongly) supposed to provide
some instructional power and control over \(x\). Nevertheless, as
a test, one should remember that instructional information does not
qualify alethically (cannot be correctly qualified as true or false).
In the example, it would be silly to ask whether the information
&ldquo;only use batteries with the same rated voltage&rdquo; is true.
Stipulations, invitations, orders, instructions, game moves, and
software cannot be true or false. As Wittgenstein remarks &ldquo;The
way music speaks. Do not forget that a poem, even though it is
composed in the language of information, is not used in the
language-game of giving information.&rdquo; (<em>Zettel</em>,
&sect;160, see Wittgenstein [1981])</p>

<h3><a name="3.2">3.2 Factual information</a></h3>

<p>

In the language game that Wittgenstein seems to have in mind, the
notion of &ldquo;semantic information&rdquo; is intended in a
declarative or factual mode. Factual information may be true or untrue
(false, in case one adopts a binary logic). <em>True semantic
content</em> is the most common sense in which information seems to be
understood (Floridi [2004]). Quine [1970, pp. 3&ndash;6, 98&ndash;99], for
example, equates &ldquo;likeness of meaning&rdquo; &ldquo;sameness of
proposition&rdquo; and &ldquo;sameness of objective information&rdquo;
by treating propositions as information in the factual sense just
highlighted (having the same meaning means conveying the same
objective information, though according to Quine, this only rephrases
the problem). The factual sense is also one of the most important,
since information as true semantic content is a necessary condition
for knowledge. Some elaboration is in order, and in the following
sub-sections we shall briefly look at the concept of data as
constraining affordances, at the role played by levels of abstraction
in the transformation of constraining affordances into factual
information, and finally at the relation between factual information
and truth.</p>

<h4><a name="3.2.1">3.2.1 Constraining affordances</a></h4>

<p>

The data that constitute factual information allow or invite certain
constructs (they are <em>affordances</em> for the information agent
that can take advantage of them) and resist or impede some others (they
are <em>constraints</em> for the same agent), depending on the
interaction with, and the nature of, the information agent that
processes them. For example, the red light flashing repetitively and
the engine not starting allow you (or any other information agent like
you) to construct the information that (a) the battery is flat, while
making it more difficult to you (or any other information agent like
you) to construct the information that (b) there is a short circuit
affecting the proper functioning of the low battery indicator, where
the engine fails to start because there is no petrol in the tank, a
fact not reported by the relevant indicator which is affected by the
same short circuit. This is the sense in which data are
<em>constraining affordances</em> for (an information agent responsible
for) the elaboration of factual information.</p>

<h4><a name="3.2.2">3.2.2 Levels of abstraction</a></h4>

<p>

In section 1.3, we saw that the concept of pure data in themselves
(<em>dedomena</em>) is an abstraction, like Kant&rsquo;s noumena or Locke&rsquo;s
substance. The point made was that data are never accessed and
elaborated (by an information agent) independently of a <em>level of
abstraction</em> (&lsquo;LoA&rsquo;) (see also the comparable concept
of &ldquo;matrix&rdquo; in Quine [1970]). The time has come to clarify
what a LoA is.</p>

<p>

A LoA is a specific set of typed variables, intuitively representable
as an interface, which establishes the scope and type of data that
will be available as a resource for the generation of
information. This concept of LoA is purely epistemological, and it
should not be confused with other forms of &ldquo;levellism&rdquo;
that are more or less explicitly based on an ontological commitment
concerning the intrinsic architecture, syntax or structure of the
system discussed (Dennett [1971], Marr [1982], Newell [1982], Simon
[1969], see now Simon [1996]; Poli [2001] provides a reconstruction of
ontological levellism; more recently, Craver [2004] has analysed
ontological levellism, especially in biology and cognitive
science). Ontological levellism has come under increasing attack. Heil
[2003] and Schaffer [2003] have seriously and convincingly questioned
its plausibility. However, epistemological levellism is flourishing,
especially in computer science (Roever <em>et al</em>. [1998], Hoare
and Jifeng [1998]), where it is regularly used to satisfy the
requirement that systems constructed in levels (in order to tame their
complexity) function correctly.</p>

<p>

Through a LoA, an information agent (the observer) accesses a physical
or conceptual environment, the system. LoAs are not necessarily
hierarchical and they are comparable. They are interfaces that mediate
the epistemic relation between the observed and the
observer. Consider, for example, a motion detector (Figure 4). In the
past, motion detectors caused an alarm whenever a movement was
registered within the range of the sensor, including the swinging of a
tree branch (object \(a\) in Figure 4). The old LoA\(_1\)
consisted of a single typed variable, which may be labelled
&lsquo;movement&rsquo;. Nowadays, when a PIR (passive infrared)
motion detector registers some movement, it also monitors the presence
of an infrared signal, so the entity detected has to be something that
also emits infrared radiation&mdash;usually perceived as heat
&mdash; before the sensor activates the alarm. The new LoA\(_2\)
consists of two typed variables: &lsquo;movement&rsquo; and
&lsquo;infrared radiation&rsquo;. Clearly, your car (object \(b\)
in Figure 4) leaving your house is present for both LoAs; but for the
new LoA\(_2\), which is more finely grained, the branch of the
tree swinging in the garden is absent. Likewise, a stone in the garden
(object \(c\) in Figure 4) is absent for both the new and the old
LoA, since it satisfies no typed variable of either one.</p>

<div class="figure">
<img src="figure4.jpg" alt="Figure 4" width="550" />
<p class="center"><span class="figlabel">Figure 4.</span>
An example of Levels of Abstraction
</p></div>

<p>

The method of LoA is an efficient way of making explicit and
managing the ontological commitment of a theory. In our case,
&ldquo;the battery is what provides electricity to the car&rdquo; is a
typical example of information elaborated at a driver&rsquo;s LoA. An
engineer&rsquo;s LoA may output something like &ldquo;12-volt lead-acid
battery is made up of six cells, each cell producing approximately 2.1
volts&rdquo;, and an economist&rsquo;s LoA may suggest that &ldquo;a
good quality car battery will cost between $50 and $100 and, if
properly maintained, it should last five years or more&rdquo;.</p>

<p>

Data as constraining affordances&mdash;answers waiting for the
relevant questions&mdash;are transformed into factual information by
being processed semantically at a given LoA (alternatively: the
relevant question is associated to the right answer at a given LoA).
Once data as constraining affordances have been elaborated into factual
information at a given LoA, the next question is whether truth values
supervene on factual information.</p>

<h4><a name="3.2.3">3.2.3 Information and truth</a></h4>

<p>

Does some factual content qualify as information only if it is true?
Defenders of the alethic neutrality of semantic information (Fetzer
[2004] and Dodig-Crnkovic [2005], who criticise Floridi [2004];
Colburn [2000], Fox [1983], among situation theorists Devlin [1991],
and Scarantino and Piccinini [2010]) argue that meaningful and
well-formed data already qualify as information, no matter whether
they represent or convey a truth or a falsehood or indeed have no
alethic value at all. Opponents, on the other hand, object that
&ldquo;[&hellip;] <em>false</em> information
and <em>mis</em>-information are not kinds of information&mdash;any
more than decoy ducks and rubber ducks are kinds of ducks&rdquo;
(Dretske [1981], 45) and that &ldquo;false information is not an
inferior kind of information; it just is not information&rdquo; (Grice
[1989], 371; other philosophers who accept a truth-based definition of
semantic information are Barwise and Seligman [1997] and Graham
[1999]). The result is a definition of factual semantic information as
well-formed, meaningful and truthful data (defended in Floridi
[2005]), where &ldquo;truthful&rdquo; is only a stylistic choice to be
preferred to &ldquo;true&rdquo; because it enables one to say that a
map conveys factual information insofar as it is truthful.</p>

<p>

Once again, the debate is not about a mere definition, but concerns
the possible consequences of the alethic neutrality thesis, three of
which can be outlined here, whereas a fourth requires a longer analysis
and will be discussed in section 4.1.</p>

<p>

If the thesis &ldquo;meaningful and well-formed data already qualify
as information&rdquo; is correct then</p>

<ol type="i">

<li>false information (including contradictions) would count as a
genuine type of semantic information, not as pseudo-information;</li>

<li>all necessary truths (including tautologies) would qualify as
information (on this issue see Bremer [2003]); and</li>

<li>&ldquo;it is true that \(p\)&rdquo;&mdash;where
\(p\) is a variable that can be replaced by any instance of
genuine semantic information&mdash;would not be a redundant
expression; for example, &ldquo;it is true&rdquo; in the conjunction
&ldquo;&lsquo;the earth is round&rsquo; qualifies as information and it
is true&rdquo; could not be eliminated without semantic loss.</li>

</ol>

<p>

All these new issues are grafted to some old branches of the
philosophical tree. </p>

<p>
 Whether false information is a genuine type of information has
important repercussions on any philosophy and pragmatics of
communication.</p>

<p>

The question about the informative nature (or lack thereof) of
necessary truths, tautologies, equations or identity statements is an
old one, as it runs through Hume, Kant, Frege and Wittgenstein. The
latter, for example, interestingly remarked:</p>

<blockquote>
 Another expression akin to those we have just considered is this:
&lsquo;Here it is; take it or leave it!&rsquo; And this again is akin
to a kind of introductory statement which we sometimes make before
remarking on certain alternatives, as when we say: &lsquo;It either
rains or it doesn&rsquo;t rain; if it rains we&rsquo;ll stay in my room, if
it doesn&rsquo;t&hellip;&rsquo;. The first part of this sentence is no piece
of information (just as &lsquo;Take it or leave it&rsquo; is no
order). Instead of, &lsquo;It either rains or it doesn&rsquo;t rain&rsquo;
we could have said, &lsquo;Consider the two cases&hellip;&rsquo;. Our
expression underlines these cases, presents them to your
attention. (<em>The Blue and Brown Books</em>, The Brown Book,
II, p. 161, see Wittgenstein [1960])
 </blockquote>

<p>
 The solution of the problem of hyperintensionality (how one can draw
a semantic distinction between expressions that are supposed to have
the same meaning according to a particular theory of meaning that is
usually model-theoretic or modal in character) depends on how one can
make sense of the relation between truth and informativeness in the
case of logically equivalent expressions.</p>

<p>

Finally, the possibly redundant qualification of information as true
is also linked with the critique of the deflationary theories of truth
(DTT), since one could accept a deflationary T-schema as perfectly
correct, while rejecting the explanatory adequacy of DTT. &ldquo;It is
true that&rdquo; in &ldquo;it is true that \(p\)&rdquo; could be
redundant in view of the fact that there cannot be factual information
that is not true, but DTT could mistake this linguistic or conceptual
redundancy for unqualified dispensability. &ldquo;It is true
that&rdquo; could be redundant because, strictly speaking, information
is not a truth-bearer but already encapsulates truth as truthfulness.
Thus, DTT may be satisfactory as theories of truth-ascriptions while
being inadequate as theories of truthfulness.</p>

<p>

Once information is available, knowledge can be built in terms of
<em>justifiable</em> or <em>explainable</em> <em>semantic
information</em>. An information agent knows that the battery is flat
not by merely guessing rightly, but because e.g., it perceives that the
red light of the low battery indicator flashing and/or that the engine
does not start. In this sense, information provides the basis of any
further scientific investigation. Note, however, that the fact that
data may count as <em>resources</em> for (i.e., inputs an agent can use
to construct) information, and hence for knowledge, rather than
<em>sources</em>, may lead to constructionist arguments against mimetic
theories that interpret information as some sort of picture of the
world. The point requires some elaboration.</p>

<p>

Whether empirical or conceptual, data make possible only a certain
range of information constructs, and not all constructs are made
possible equally easily. An analogy may help here. Suppose one has to
build a shelter. The design and complexity of the shelter may vary, but
there is a limited range of &ldquo;realistic&rdquo; possibilities,
determined by the nature of the available resources and constraints
(size, building materials, location, weather, physical and biological
environment, working force, technical skills, purposes, security, time
constraints, etc.). Not any shelter can be built. And the type of
shelter that will be built more often will be the one that is more
likely to take close-to-optimal advantage of the available resources
and constraints. The same applies to data. Data are at the same time
the resources and constraints that make possible the construction of
information. The best information is that better tuned to the
constraining affordances available. Thus informational coherence and
adequacy do not necessarily entail nor support na&iuml;ve or direct
realism, or a correspondence theory of truth as this is ordinarily
presented. Ultimately, information is the result of a process of data
modelling; it does not have to represent or photograph or portray or
photocopy, or map or show or uncover or monitor or &hellip; the
intrinsic nature of the system analysed, no more than an igloo
describes the intrinsic nature of snow or the Parthenon indicates the
real properties of stones.</p>

<p>

When <em>semantic content</em> is <em>false</em>, this is a case of
<em>misinformation</em> (Fox [1983]). And if the source of
misinformation is aware of its nature, one may speak of
<em>disinformation</em>, as when one says to the mechanic &ldquo;my
husband forgot to turn the lights off&rdquo;. Disinformation and
misinformation are ethically censurable but may be successful in
achieving their purpose: tell the mechanic that your husband left the
lights on last night, and he will still be able to provide you with the
right advice. Likewise, information may still fail to be successful;
just imagine telling the mechanic that your car is out of order.</p>

<h2><a name="4">4. Philosophical approaches to semantic information</a></h2>

<p>

What is the relation between MTC and the sort of semantic
information that we have called factual? The mathematical theory of
communication approaches information as a physical phenomenon. Its
central question is whether and how much uninterpreted data can be
encoded and transmitted efficiently by means of a given alphabet and
through a given channel. MTC is not interested in the meaning,
&ldquo;aboutness&rdquo;, relevance, reliability, usefulness or
interpretation of information, but only in the level of detail and
frequency in the uninterpreted data, being these symbols, signals or
messages. Philosophical approaches differ from MTC in two main
respects.</p>

<p>

First, they seek to give an account of information as
<em>semantic</em> content, investigating questions like &ldquo;how can
something count as information? and why?&rdquo;, &ldquo;how can
something carry information about something else?&rdquo;, &ldquo;how
can semantic information be generated and flow?&rdquo;, &ldquo;how is
information related to error, truth and knowledge?&rdquo;, &ldquo;when
is information useful?&rdquo;. Wittgenstein, for example, remarks
that</p>

<blockquote>

 One is inclined to say: &lsquo;Either it is raining, or it isn&rsquo;t
&mdash; how I know, how the information has reached me, is another
matter.&rsquo; But then let us put the question like this: What do I
call &lsquo;information that it is raining&rsquo;? (Or have I only
information of this information too?) And what gives this
&lsquo;information&rsquo; the character of information about
something? Doesn&rsquo;t the form of our expression mislead us here? For
isn&rsquo;t it a misleading metaphor to say: &lsquo;My eyes give me the
information that there is a chair over there&rsquo;?
(<em>Philosophical Investigations</em>, I. &sect; 356, see now
Wittgenstein [2001])
 </blockquote>

<p>

Second, philosophical theories of semantic information also seek to
connect it to other relevant concepts of information and more complex
forms of epistemic, mental and doxastic phenomena. For instance,
Dretske [1981] and Barwise and Seligman [1997] attempt to ground
information, understood as factual semantic contents, on environmental
information. The approach is also known as the <em>naturalization of
information</em>. A similar point can be made about Putnam&rsquo;s twin
earths argument, the externalization of semantics and
teleosemantics.</p>

<p>

Philosophical analyses usually adopt a propositional orientation and
an epistemic outlook, endorsing, often implicitly, the prevalence or
centrality of factual information within the map outlined in Figure 1.
They tend to base their analyses on cases such as &ldquo;Paris is the
capital of France&rdquo; or &ldquo;The Bodleian Library is in
Oxford&rdquo;. How relevant is MTC to similar researches?</p>

<p>

In the past, some research programs tried to elaborate information
theories <em>alternative</em> to MTC, with the aim of incorporating the
semantic dimension. Donald M. Mackay [1969] proposed a quantitative
theory of qualitative information that has interesting connections with
<em>situation logic</em> (see below). According to MacKay, information
is linked to an increase in knowledge on the receiver&rsquo;s side:
&ldquo;Suppose we begin by asking ourselves what we mean by
information. Roughly speaking, we say that we have gained information
when we know something now that we didn&rsquo;t know before; when
&lsquo;what we know&rsquo; has changed.&rdquo; (Mackay [1969], p. 10).
Around the same years, Doede Nauta [1972] developed a
semiotic-cybernetic approach. Nowadays, few philosophers follow these
lines of research. The majority agrees that MTC provides a rigorous
constraint to any further theorising on all the semantic and pragmatic
aspects of information. The disagreement concerns the crucial issue of
the <em>strength</em> of the constraint.</p>

<p>

At one extreme of the spectrum, any philosophical theory of
semantic-factual information is supposed to be <em>very strongly</em>
constrained, perhaps even overdetermined, by MTC, somewhat as
mechanical engineering is by Newtonian physics. Weaver&rsquo;s
optimistic interpretation of Shannon&rsquo;s work is a typical
example.</p>

<p>

At the other extreme, any philosophical theory of semantic-factual
information is supposed to be <em>only weakly</em> constrained, perhaps
even completely underdetermined, by MTC, somewhat as tennis is
constrained by Newtonian physics, that is in the most uninteresting,
inconsequential and hence disregardable sense (see for example Sloman
[1978] and Thagard [1990]).</p>

<p>

The emergence of MTC in the 1950s generated earlier philosophical
enthusiasm that has gradually cooled down through the decades.
Historically, philosophical theories of semantic-factual information
have moved from &ldquo;very strongly constrained&rdquo; to &ldquo;only
weakly constrained&rdquo;. Recently, we find positions that carefully
appreciate MTC for what it can provide in terms of a robust and
well-developed statistical theory of correlations between states of
different systems (the sender and the receiver) according to their
probabilities. This can have important consequences in
mathematically-friendly contexts, such as some approaches to
naturalised epistemology (Harms [1998]) or scientific explanation
(Badino [2004]).</p>

<p>

Although the philosophy of semantic information has become
increasingly autonomous from MTC, two important connections have
remained stable between MTC and even the most recent philosophical
accounts:</p>

<ol>

<li>the communication model, explained in section 2.1 (see Figure 2);
and</li>

<li>what Barwise labelled the &ldquo;Inverse Relationship
Principle&rdquo; (IRP).</li>

</ol>

<p>

The communication model has remained virtually unchallenged, even if
nowadays theoretical accounts are more likely to consider as basic
cases multiagent and distributed systems interacting in parallel,
rather than individual agents related by simple, sequential channels
of communication. In this respect, the philosophy of information
(Floridi [2011]; Allo [2010]) is less Cartesian than
&ldquo;social&rdquo;.</p>

<p>

IRP refers to the inverse relation between the probability of
\(p\)&mdash;which may range over sentences of a given language
(as in Bar-Hillel and Carnap) or events, situations or possible worlds
(as in Dretske)&mdash;and the amount of semantic information carried
by \(p\) (recall that Poe&rsquo;s raven, as a unary source provides no
information because its answers are entirely predictable). It states
that information goes hand in hand with unpredictability. Popper
[1935] is often credited as the first philosopher to have advocated
IRP explicitly. However, systematic attempts to develop a formal
calculus involving it were made only after Shannon&rsquo;s breakthrough.</p>

<p>

We have seen that MTC defines information in terms of probability
space distribution. Along similar lines, the <em>probabilistic
approach</em> to semantic information defines the semantic information
in \(p\) in terms of logical probability space and the inverse
relation between information and the probability of \(p\). This
approach was initially suggested by Bar-Hillel and Carnap [1953] (see
also Bar-Hillel [1964]) and further developed by Kemeny [1953],
Smokler [1966], Hintikka and Suppes [1970] and Dretske [1981]. The
details are complex but the original idea is simple. The semantic
content (\(\CONT\)) in \(p\) is measured as the complement of
the <em>a priori</em> probability of \(p\):</p>

\[\tag{10}
\CONT(p) = 1 - P(p)
\]

<p>

\(\CONT\) does not satisfy the two requirements of
additivity and conditionalization, which are satisfied by another
measure, the informativeness (\(\INF\)) of \(p\), which
is calculated, following equations [9] and [10], as the reciprocal of
\(P(p)\), expressed in bits, where
\(P(p) = 1 - \CONT(p)\):</p>

\[\tag{11}
\INF(p) = \log \frac{1}{1 - \CONT(p)} = -\log P(p)
\]

<p>

Things are complicated by the fact that the concept of probability
employed in equations [10] and [11] is subject to different
interpretations. In Bar-Hillel and Carnap [1953], the probability
distribution is the outcome of a logical construction of atomic
statements according to a chosen formal language. This introduces a
problematic reliance on a strict correspondence between observational
and formal language. In Dretske, the solution is to make probability
values refer to the observed states of affairs \((s)\), that
is:</p>

\[\tag{12}
I(s) = -\log P(s)
\]

<p>
 where \(I(s)\) is Dretske&rsquo;s notation to refer to the
information contained in \(s\).</p>

<p>

The <em>modal approach</em> further modifies the probabilistic
approach by defining semantic information in terms of modal space and
in/consistency. The information conveyed by \(p\) becomes the set
of all possible worlds, or (more cautiously) the set of all the
descriptions of the relevant possible states of the universe, that are
excluded by \(p\).</p>

<p>

The <em>systemic approach</em>, developed especially in situation
logic (Barwise and Perry 1983, Israel and Perry 1990, Devlin 1991;
Barwise and Seligman 1997 provide a foundation for a general theory of
information flow) also defines information in terms of states space and
consistency. However, it is less ontologically demanding than the modal
approach, since it assumes a clearly limited domain of application. It
is also compatible with Dretske&rsquo;s probabilistic approach,
although it does not require a probability measure on sets of states.
The informational content of \(p\) is not determined a priori,
through a calculus of possible states allowed by a representational
language, but in terms of factual content that \(p\) carries with
respect to a given situation. Information tracks possible transitions
in a system&rsquo;s states space under normal conditions. Both Dretske
and situation theorists require some presence of information already
immanent in the environment (<em>environmental information</em>), as
nomic regularities or constraints. This &ldquo;semantic
externalism&rdquo; can be controversial.</p>

<p>

The <em>inferential approach</em> defines information in terms of
entailment space: information depends on valid inference relative to an
information agent&rsquo;s theory or epistemic state.</p>

<p>

Each of the previous extensionalist approaches can be given an
intentionalist interpretation by considering the relevant space as a
doxastic space, in which information is seen as a reduction in the
degree of personal uncertainty, given a state of knowledge of the
informee. Wittgenstein addressed this distinction in his <em>Remarks
on the Philosophy of Psychology</em>:</p>

<blockquote>
 The important insight is that there is a language-game in which I
produce information automatically, information which can be treated by
other people quite as they treat non-automatic information &mdash;
only here there will be no question of any &lsquo;lying&rsquo; &mdash;
information which I myself may receive like that of a third
person. The &lsquo;automatic&rsquo; statement, report etc. might also
be called an &lsquo;oracle&rsquo;. &hellip; But of course that means
that the oracle must not avail itself of the words &lsquo;I
believe&hellip;&rsquo;. ((Wittgenstein [1980], &sect;817)
</blockquote>

<p>
 In using the notion of a language game, Wittgenstein seem to have in
mind here the information game we have already encountered above.</p>

<h3><a name="4.1">4.1 The Bar-Hillel-Carnap Paradox</a></h3>

<p>

Insofar as they subscribe to the Inverse Relationship Principle, the
extensionalist approaches outlined in the previous section can be
affected by what has been defined, with a little hyperbole, as the
<em>Bar-Hillel-Carnap Paradox</em> (Floridi [2004]).</p>

<p>

In a nutshell, we have seen that, following IRP, the less probable
or possible \(p\) is the more semantic information \(p\) is
assumed to be carrying. This explains why most philosophers agree that
tautologies convey no information at all, for their probability or
possibility is 1. But it also leads one to consider contradictions
&mdash; which describe impossible states, or whose probability is 0
&mdash; as the sort of messages that contain the highest amount of
semantic information. It is a slippery slope. Make a statement less and
less likely and you gradually increase its informational content, but
at certain point the statement &ldquo;implodes&rdquo; (in the quotation
below, it becomes &ldquo;too informative to be true&rdquo;).</p>

<p>

Bar-Hillel and Carnap [1953] were among the first to make explicit
this prima facie counterintuitive inequality. Note how their careful
wording betrays the desire to defuse the problem:</p>

<blockquote>
 <strong>Bar-Hillel-Carnap Paradox (BCP):</strong> <br />
 It might perhaps, at first, seem strange that a self-contradictory
sentence, hence one which no ideal receiver would accept, is regarded
as carrying with it the most inclusive information. It should,
however, be emphasized that semantic information is here not meant as
implying truth. A false sentence which happens to say much is thereby
highly informative in our sense. Whether the information it carries is
true or false, scientifically valuable or not, and so forth, does not
concern us. A self-contradictory sentence asserts too much; it is too
informative to be true. (229)
 </blockquote>

<p>

Since its formulation, BCP has been recognised as an unfortunate, yet
perfectly correct and logically inevitable consequence of any
quantitative <em>theory of weakly semantic information</em>. It is
&ldquo;weakly&rdquo; semantic because truth values play no role in
it. As a consequence, the problem has often been either ignored or
tolerated (Bar-Hillel and Carnap [1953]) as the price of an otherwise
valuable approach. Sometimes, however, attempts have been made to
circumscribe its counterintuitive consequences. This has happen
especially in Information Systems Theory (Winder [1997])&mdash;where
consistency is an essential constraint that must remain satisfied for
a database to preserve data integrity&mdash;and in Decision Theory,
where inconsistent information is obviously of no use to a decision
maker.</p>

<p>

In these cases, whenever there are no possible models that satisfy a
statement or a theory, instead of assigning to it the maximum quantity
of semantic information, three strategies have been suggested:</p>

<ol>

<li>assigning to all inconsistent cases the same, infinite
information value (Lozinskii [1994]). This is in line with an economic
approach, which defines x as impossible if and only if x has an
infinite price;</li>

<li>eliminating all inconsistent cases a priori from consideration,
as impossible outcomes in decision-making (Jeffrey [1990]). This is in
line with the syntactic approach developed by MTC;</li>

<li>assigning to all inconsistent cases the same zero information
value (Mingers [1997], Aisbett and Gibbon [1999]).</li>

</ol>

<p>

The latter approach is close to the <em>strongly semantic
approach</em>, to which we shall now turn.</p>

<h3><a name="4.2">4.2 The strongly semantic approach to information</a></h3>

<p>

The general hypothesis is that BCP indicates that something has gone
essentially amiss with the theory of weakly semantic information. It
is based on a semantic principle that is too weak, namely that
truth-values are independent of semantic information. A semantically
stronger approach, according to which information encapsulates truth,
can avoid the paradox and is more in line with the ordinary conception
of what generally counts as factual information, as we have seen in
section 3.2.3. MTC already provides some initial reassurance. MTC
identifies the quantity of information associated with, or generated
by, the occurrence of a signal (an event or the realisation of a state
of affairs) with the elimination of possibilities (reduction in
uncertainty) represented by that signal (event or state of
affairs). In MTC, no counterintuitive inequality comparable to BCP
occurs, and the line of argument is that, as in the case of MTC, a
<em>theory of strongly semantic information</em>, based on alethic and
discrepancy values rather than probabilities, can also successfully
avoid BCP (Floridi [2005]; see Bremer and Cohnitz
[2004] chap. 2 for an overview; Sequoiah-Grayson [2007] defends the
theory of strongly semantic information against recent independent
objections from Fetzer [2004] and Dodig-Crnkovic [2005]). 
</p>

<p>
Before describing this approach, note that some have proposed a
different alethic approach, one that uses truthlikeness, or
verisimilitude, to explicate the notion of semantic information
(Frick&eacute; 1997; Cevolani 2011, 2014; D&rsquo;Alfonso 2011). Typically
these seek to identify factual information with likeness to the
complete truth about all empirical matters or about some restricted
relevant domain of factual interest. These also avoid the BCP, and
also do not use probabilities. However, truthlikeness is different
from truth itself in as much as a truth bearer can be like the truth
without actually being true, i.e. while being false, so that
verisimilitude accounts of information can permit false views or
theories to possess information. (Indeed false statements can
sometimes carry more information than than their true negations on
this account; Frick&eacute; 1997).</p>

<p>

By contrast, on Floridi&rsquo;s conception semantic-factual information is
defined, in terms of data space, as well-formed, meaningful and
truthful data. This constrains the probabilistic approach introduced
above, by requiring first a qualification of the content as
truthful. Once the content is so qualified, the quantity of semantic
information in \(p\) is calculated in terms of distance
of \(p\) from the situation/resource \(w\) that \(p\)
is supposed to model. Total distance is equivalent to a \(p\)
true in all cases (all possible worlds or probability 1), including
\(w\) and hence minimally informative, whereas maximum closeness
is equivalent to the precise modelling of \(w\) at the agreed
level of abstraction.</p>

<p>

Suppose there will be exactly three guests for dinner tonight. This
is our situation \(w\). Imagine we are told that</p>

<table class="cellpad-med-dense vert-top">
 <tr>
 <td>(T)</td>
 <td>there may or may not be some guests for dinner tonight; or</td>
 </tr>
 
 <tr>
 <td>(V)</td>
 <td>there will be some guests tonight; or</td>
 </tr>

 <tr>
 <td>(P)</td>
 <td>there will be three guests tonight.</td>
 </tr>
</table>

<p>

The <em>degree of informativeness</em> of (T) is zero because, as a
tautology, (T) applies both to \(w\) and to \(\neg w\). (V)
performs better, and (P) has the maximum degree of informativeness
because, as a fully accurate, precise and contingent truth, it
&ldquo;zeros in&rdquo; on its target \(w\). Generalising, the
more distant some semantic-factual information \(\sigma\) is from its
target \(w\), the larger is the number of situations to which it
applies, the lower its degree of informativeness becomes. A tautology
is a true \(\sigma\) that is most &ldquo;distant&rdquo; from the world.</p>

<p>

Let us now use &lsquo;\(\theta\)&rsquo; to refer to the distance
between a true \(\sigma\) and \(w\). Using the more precise vocabulary
of situation logic, \(\theta\) indicates the degree of support offered
by \(w\) to \(\sigma\). We can now map on the \(x\)-axis of a
Cartesian diagram the values of \(\theta\) given a specific \(\sigma\)
and a corresponding target \(w\). In our example, we know that
\(\theta(\T) = 1\) and \(\theta(\P) = 0\). For the sake of simplicity,
let us assume that \(\theta(\V) = 0.25\). We now need a formula to
calculate the
<em>degree of informativeness</em> \(\iota\) of \(\sigma\) in relation to
\(\theta(s)\). Floridi (2004, 210&ndash;11) mathematically derives
and motivates the use of the complement of the square value of
\(\theta(\sigma)\), that is, [13]:</p>

\[\tag{13}
\iota(\sigma) = 1 - \theta(\sigma)^2
\]

<p>

Figure 5 shows the graph generated by equation [13] when we include
also negative values of distance for false \(\sigma\); \(\theta\) ranges
from \(-1 (=\) contradiction) to \(1 (=\) tautology):</p>

<div class="figure">
<img src="figure5.jpg" alt="Figure 5" />
<p class="center"><span class="figlabel">Figure 5.</span>
Degree of informativeness
</p></div>

<p>

If \(\sigma\) has a very high degree of informativeness \(\iota\) (very low
\(\theta)\) we want to be able to say that it contains a large quantity
of semantic information and, vice versa, the lower the degree of
informativeness of \(\sigma\) is, the smaller the quantity of semantic
information conveyed by \(\sigma\) should be. To calculate the quantity
of semantic information contained in \(\sigma\) relative to
\(\iota(\sigma)\) we need to calculate the area delimited by equation
[13], that is, the definite integral of the function \(\iota(\sigma)\)
on the interval \([0, 1]\). As we know, the maximum quantity of semantic
information (call it \(\alpha)\) is carried by (P), whose \(\theta =
0\). This is equivalent to the whole area delimited by the
curve. Generalising to \(\sigma\) we have:</p>

\[\tag{14}
\int_0^1 \iota(\sigma)dx = \alpha = 2/3
\]

<p>

Figure 6 shows the graph generated by equation [14]. The shaded area
is the maximum amount of semantic information \(\alpha\) carried by
\(\sigma\):</p>

<div class="figure">
<img src="figure6.jpg" alt="Figure 6" />
<p class="center"><span class="figlabel">Figure 6.</span>
Maximum amount of semantic information \(\alpha\) carried by \(\sigma\)
</p></div>

<p>

Consider now (V), &ldquo;there will be some guests tonight&rdquo;. (V)
can be analysed as a (reasonably finite) string of disjunctions, that
is (V) = [&ldquo;there will be one guest tonight&rdquo; or &ldquo;there
will be two guests tonight&rdquo; or &hellip; &ldquo;there will be
\(n\) guests tonight&rdquo;], where \(n\) is the reasonable
limit we wish to consider (things are more complex than this, but here
we only need to grasp the general principle). Only one of the
descriptions in (V) will be fully accurate. This means that (V) also
contains some (perhaps much) information that is simply irrelevant or
redundant. We shall refer to this &ldquo;informational waste&rdquo; in
(V) as vacuous information in (V). The amount of vacuous information
(call it \(\beta)\) in (V) is also a function of the distance \(\theta\) of
(V) from \(w\), or more generally:</p>

\[\tag{15}
\int_0^{\theta} \iota(\sigma)dx = \beta
\]

<p>
 Since \(\theta(\V) = 0.25\), we have</p>

\[\tag{16}
\int_0^{0.25} \iota(V)dx = 0.24479
\]

<p>

Figure 7 shows the graph generated by equation [16]:</p>

<div class="figure">
 <img src="figure7.jpg" alt="Figure 7" />
<p class="center"><span class="figlabel">Figure 7.</span>
Amount of semantic information \(\gamma\) carried by \(\sigma\)
</p></div>

<p>
 The shaded area is the amount of vacuous information \(\beta\) in
(V). Clearly, the amount of semantic information in (V) is simply the
difference between \(\alpha\) (the maximum amount of information that can
be carried in principle by \(\sigma)\) and \(\beta\) (the amount of vacuous
information actually carried by \(\sigma)\), that is, the clear area in
the graph of Figure 7. So, the amount of semantic information \(\gamma\)
in \(\sigma\) is:</p>


\[\tag{17}
\gamma(\sigma) = \alpha - \beta
\]

<p>

Note the similarity between [14] and [15]. When \(\theta(\sigma) = 1\),
that is, when the distance between \(\sigma\) and \(w\) is maximum,
then \(\alpha = \beta\) and \(\gamma(\sigma) = 0\). This is what happens
when we consider (T). (T) is so distant from \(w\) as to contain only
vacuous information. In other words, (T) contains as much vacuous
information as (P) contains relevant information.</p>

<h2><a name="5">5. Conclusion</a></h2>

<p>

Philosophical theories of semantic information have recently
contributed to a new area of research in itself, the philosophy of
information (Adams [2003], Floridi [2011]).

<em>The Routledge Handbook of Philosophy of Information</em> (Floridi
(ed.) 2016) provides an overview of the scope and depth of current
work in the field. Information seems to have become a key concept to
unlock several philosophical problems. &ldquo;The most valuable
commodity I know of is information&rdquo;, boldly declares Gordon
Gekko in Oliver Stone&rsquo;s <em>Wall Street</em> (1987). Euphranor would
probably have concurred. The problem is that we still have to agree
about what information is exactly.</p>

</div>

<div id="bibliography">

<h2><a name="Bib">Bibliography</a></h2>

<ul class="hanging">

<li>Adams, F., 2003, &ldquo;The Informational Turn in
Philosophy&rdquo;, <em>Minds and Machines</em>, 13(4):
471&ndash;501.</li>

<li>Adriaans, P. and van Benthem, J. (ed.), 2008, <em>Handbook of
Philosophy of Information</em>, Amsterdam, Oxford: Elsevier.</li>

<li>Allo, P. (ed.), 2010, <em>Putting Information First: Luciano
Floridi and the Philosophy of Information</em>, special issue of
<em>Metaphilosophy</em>, Volume 41, No. 3.</li>

<li>Armstrong, D. M., 1968, <em>A Materialist Theory of the Mind</em>,
London: Routledge &amp; Kegan Paul.</li>

<li>&ndash;&ndash;&ndash;, 1993, <em>A Materialist Theory of the
Mind</em>, 2nd edition, London: Routledge.</li>

<li>Badino, M., 2004, &ldquo;An Application of Information Theory to the
Problem of the Scientific Experiment&rdquo;, <em>Synthese</em>, 140:
355&ndash;389.</li>

<li>Bar-Hillel, Y., 1964, <em>Language and Information: Selected Essays
on Their Theory and Application</em>, Reading, Mass; London:
Addison-Wesley.</li>

<li>Bar-Hillel, Y. and Carnap, R., 1953, &ldquo;An Outline of a Theory
of Semantic Information&rdquo;; reprinted in Bar-Hillel [1964],
pp. 221&ndash;74.</li>

<li>Barwise, J. and Seligman, J., 1997, <em>Information Flow: The Logic
of Distributed Systems</em>, Cambridge: Cambridge University
Press.</li>

<li>Bateson, G., 1973, <em>Steps to an Ecology of Mind</em>, Frogmore,
St. Albans: Paladin.</li>

<li>Berkeley, G., 1732, <em>Alciphron: Or the Minute Philosopher</em>,
Edinburgh: Thomas Nelson, 1948&ndash;57.</li>

<li>Braman, S., 1989, &ldquo;Defining Information&rdquo;,
<em>Telecommunications Policy</em>, 13: 233&ndash;242.</li>

<li>Bremer, M. and Cohnitz, D., 2004, <em>Information and Information
Flow &ndash; an Introduction</em>, Frankfurt, Lancaster: Ontos
Verlag.</li>

<li>Bremer, M. E., 2003, &ldquo;Do Logical Truths Carry
Information?&rdquo;, <em>Minds and Machines</em>, 13(4):
567&ndash;575.</li>

<li>Cevolani, G., 2011, &ldquo;Verisimilitude and strongly semantic
information&rdquo;, <em>Ethics &amp; Politics</em>, XIII(2):
159&ndash;179.</li>

<li>&ndash;&ndash;&ndash;, 2014, &ldquo;Strongly Semantic Information
as Information About the Truth&rdquo;, in R. Ciuni, H. Wansing and
C. Willkommen (eds.), <em>Recent Trends in Philosophical Logic</em>
(Trends in Logic, Volume 41), Dordrecht: Springer, 59&ndash;74.</li>

<li>Chaitin, G. J., 1987, <em>Algorithmic Information Theory</em>,
Cambridge: Cambridge University Press.</li>

<li>Chalmers, D. J., 1996, <em>The Conscious Mind: In Search of a
Fundamental Theory</em>, New York: Oxford University Press.</li>

<li>Cherry, C., 1978, <em>On Human Communication: A Review, a Survey, and
a Criticism</em>, 3rd edition, Cambridge, Mass; London: MIT Press.</li>

<li>Colburn, T. R., 2000, <em>Philosophy and Computer Science</em>,
Armonk, NY: M.E. Sharpe.</li>

<li>Cover, T. M. and Thomas, J. A., 1991, <em>Elements of Information
Theory</em>, New York; Chichester: Wiley.</li>

<li>Craver, C. F., 2004, &ldquo;A Field Guide to Levels&rdquo;, 
<em>Proceedings and Addresses of the American Philosophical
Association</em>, 77(3): 121
 [<a href="http://folk.uio.no/anderstr/Craver.pdf" target="other">Preprint available online</a>].</li>

<li>D&rsquo;Alfonso, S., 2011, &ldquo;On Quantifying Semantic
Information&rdquo;, <em>Information</em>, 2(1): 61&ndash;101.</li>

<li>Debons, A. and Cameron, W. J. (ed.), 1975, <em>Perspectives in
Information Science</em> (Proceedings of the Nato Advanced Study Institute
on Perspectives in Information Science, Held in Aberystwyth, Wales, Uk,
August 13&ndash;24, 1973), Leiden: Noordhoff.</li>

<li>Dennett, D. C., 1969, <em>Content and Consciousness</em>, London:
Routledge &amp; Kegan Paul.</li>

<li>&ndash;&ndash;&ndash;, 1971, &ldquo;Intentional
Systems&rdquo;, <em>The Journal of Philosophy</em>, 68:
87&ndash;106.</li>

<li>&ndash;&ndash;&ndash;, 1986, <em>Content and Consciousness</em>,
2nd edition, London: Routledge &amp; Kegan Paul.</li>

<li>Deutsch, D. 1985, &ldquo;Quantum Theory, the Church-Turing
Principle and the Universal Quantum Computer&rdquo;, <em>Proceedings
of the Royal Society</em>, 400: 97&ndash;117.</li>

<li>&ndash;&ndash;&ndash;, 1997, <em>The Fabric of Reality</em>, London:
Penguin.</li>

<li>Devlin, K. J., 1991, <em>Logic and Information</em>, Cambridge:
Cambridge University Press.</li>

<li>Di Vincenzo, D. P. and Loss, D., 1998, &ldquo;Quantum Information Is
Physical&rdquo;, <em>Superlattices and Microstructures</em> (Special issue
on the occasion of Rolf Landauer&rsquo;s 70th birthday), 23: 419&ndash;432.</li>

<li>Dodig-Crnkovic, G., 2005, &ldquo;System Modeling and Information
Semantics&rdquo;, in <em>Proceedings of the Fifth Promote IT
Conference</em> (Borl&auml;nge, Sweden), Janis Bubenko, Owen Eriksson,
Hans Fernlund, and Mikael Lind (eds.), Lund: Studentlitteratur.</li>

<li>Dretske, F. I., 1981, <em>Knowledge and the Flow of
Information</em>, Oxford: Blackwell; reprinted, Stanford, CA: CSLI
Publications, 1999.</li>

<li>Dunn, J. M., 2001, &ldquo;The Concept of Information and the
Development of Non-Classical Logics&rdquo; in <em>Non-Classical
Approaches in the Transition from Traditional to Modern Logic</em>,
W. Stelzner (ed.), Berlin, New York: de Gruyter, 423&ndash;448.</li>

<li>Fetzer, J. H., 2004, &ldquo;Information: Does It Have to Be
True?&rdquo;, <em>Minds and Machines</em>, 14(2): 223&ndash;229.</li>

<li>Floridi, L., 1999, <em>Philosophy and Computing: An Introduction</em>,
London; New York: Routledge.</li>

<li>&ndash;&ndash;&ndash;, 2003, &ldquo;Information&rdquo; in <em>The
Blackwell Guide to the Philosophy of Computing and Information</em>,
L. Floridi (ed.), Oxford, New York: Blackwell, 40&ndash;61.</li>

<li>&ndash;&ndash;&ndash;, 2004, &ldquo;Outline of a Theory of
Strongly Semantic Information&rdquo;, <em>Minds and Machines</em>,
14(2): 197&ndash;222.</li>

<li>&ndash;&ndash;&ndash;, 2005, &ldquo;Is Information Meaningful
Data?&rdquo; <em>Philosophy and Phenomenological Research</em>, 70(2):
351&ndash;370.</li>

<li>&ndash;&ndash;&ndash;, 2010, <em>Information &ndash; A Very Short
Introduction</em>, Oxford; Oxford University Press.</li>

<li>&ndash;&ndash;&ndash;, 2011, <em>The Philosophy of Information</em>,
Oxford; Oxford University Press.</li>

<li>&ndash;&ndash;&ndash; (ed.), 2016, <em>The Routledge Handbook of
Philosophy of Information</em>, London; Routledge.</li>

<li>Fox, C. J., 1983, <em>Information and Misinformation: An
Investigation of the Notions of Information, Misinformation, Informing,
and Misinforming</em>, Westport, CT: Greenwood Press.</li>

<li>Franklin, S., 1995, <em>Artificial Minds</em>, Cambridge, Mass.:
MIT Press.</li>

<li>Frick&eacute;, M., 1997, &ldquo;Information using likeness
measures&rdquo;, <em>Journal of the American Society for Information
Science</em>, 48(10): 882&ndash;892.</li>

<li>Frieden, B. R., 1998, <em>Physics from Fisher Information: A
Unification</em>, Cambridge: Cambridge University Press.</li>

<li>&ndash;&ndash;&ndash;, 2004, <em>Science from Fisher Information: A
Unification</em>, 2nd edition, Cambridge: Cambridge University Press.</li>

<li>Golan, A., 2002, &ldquo;Information and Entropy Econometrics
&ndash; Editor&rsquo;s View&rdquo;, <em>Journal of Econometrics</em>,
107(1&ndash;2): 1&ndash;15.</li>

<li>Graham, G., 1999, <em>The Internet: A Philosophical Inquiry</em>,
London: Routledge.</li>

<li>Grice, H. P., 1989, <em>Studies in the Way of Words</em>, Cambridge,
Mass.: Harvard University Press.</li>

<li>Harms, W. F., 1998, &ldquo;The Use of Information Theory in Epistemology&rdquo;,
<em>Philosophy of Science</em>, 65(3): 472&ndash;501.</li>

<li>Heil, J., 2003, &ldquo;Levels of Reality&rdquo;, <em>Ratio</em>, 16(3):
205&ndash;221.</li>

<li>Hintikka, J. and Suppes, P. (ed.), 1970, <em>Information and
Inference</em>, Dordrecht: D. Reidel.</li>

<li>Hoare, C. A. R. and Jifeng, H., 1998, <em>Unifying Theories of
Programming</em>, London: Prentice Hall.</li>

<li>Hume, D., 1777 [1987], <em>Essays, Moral, Political, and
Literary</em>, Indianapolis: Liberty Classics, 1987, edited and with a
foreword, notes, and glossary by Eugene F. Miller; with an apparatus
of variant readings from the 1889 edition by T.H. Green and
T.H. Grose; based on the 1777 edition originally published as v. 1 of
Essays and treatises on several subjects.</li>

<li>Jones, D. S., 1979, <em>Elementary Information Theory</em>, Oxford:
Clarendon Press.</li>

<li>Kemeny, J., 1953, &ldquo;A Logical Measure Function&rdquo;, <em>Journal of
Symbolic Logic</em>, 18: 289&ndash;308.</li>

<li>Landauer, R., 1987, &ldquo;Computation: A Fundamental Physical View&rdquo;,
<em>Physica Scripta</em>, 35: 88&ndash;95.</li>

<li>&ndash;&ndash;&ndash;, 1991, &ldquo;Information Is
Physical&rdquo;, <em>Physics Today</em>, 44: 23&ndash;29.</li>

<li>&ndash;&ndash;&ndash;, 1996, &ldquo;The Physical Nature of
Information&rdquo;, <em>Physics Letters A</em>, 217: 188.</li>

<li>Landauer, R. and Bennett, C. H., 1985, &ldquo;The Fundamental Physical
Limits of Computation&rdquo;, <em>Scientific American</em>, July: 48&ndash;56.</li>

<li>Larson, A. G. and Debons, A. (ed.), 1983, <em>Information Science in
Action: System Design</em> (Proceedings of the Nato Advanced Study Institute
on Information Science, Crete, Greece, August 1&ndash;11, 1978), The
Hague: M. Nijhoff.</li>

<li>Losee, R. M., 1997, &ldquo;A Discipline Independent Definition of
Information&rdquo;, <em>Journal of the American Society for Information
Science</em>, 48(3): 254&ndash;269.</li>

<li>Mabon, P. C., 1975, <em>Mission Communications: The Story of Bell
Laboratories</em>, Murray Hill, N.J.: Bell Telephone Laboratories.</li>

<li>Machlup, F. and Mansfield, U. (ed.), 1983, <em>The Study of
Information: Interdisciplinary Messages</em>, New York: Wiley.</li>

<li>MacKay, D. M., 1969, <em>Information, Mechanism and Meaning</em>,
Cambridge: MIT Press.</li>

<li>Marr, D., 1982, <em>Vision: A Computational Investigation into the
Human Representation and Processing of Visual Information</em>, San
Francisco: W.H. Freeman.</li>

<li>Mingers, J., 1997, &ldquo;The Nature of Information and Its Relationship to
Meaning&rdquo; in <em>Philosophical Aspects of Information Systems</em>,
R. L. Winder <em>et al</em>. (eds.), London: Taylor and Francis,
73&ndash;84.</li>

<li>Nauta, D., 1972, <em>The Meaning of Information</em>, The Hague:
Mouton.</li>

<li>Newell, A., 1982, &ldquo;The Knowledge Level&rdquo;, <em>Artificial
Intelligence</em>, 18: 87&ndash;127.</li>

<li>Newell, A. and Simon, H. A., 1976, &ldquo;Computer Science as Empirical
Inquiry: Symbols and Search&rdquo;, <em>Communications of the ACM</em>, 19:
113&ndash;126.</li>

<li>Pierce, J. R., 1980, <em>An Introduction to Information Theory:
Symbols, Signals &amp; Noise</em>, 2nd edition, New York: Dover
Publications.</li>

<li>Poli, R., 2001, &ldquo;The Basic Problem of the Theory of Levels of
Reality&rdquo;, <em>Axiomathes</em>, 12: 261&ndash;283.</li>

<li>Popper, K. R., 1935, <em>Logik Der Forschung: Zur
Erkenntnistheorie Der Modernen Naturwissenschaft</em>, Wien:
J. Springer; English translation, <em>The Logic of Scientific
Discovery</em>, London: Hutchinson, 1959.</li>

<li>Quine, W.V.O., 1970, <em>Philosophy of Logic</em>,
Englewood Cliffs, NJ: Prentice Hall. </li>

<li>Roever, W. P. d., Engelhardt, K. and Buth, K.-H., 1998, <em>Data
Refinement: Model-Oriented Proof Methods and Their Comparison</em>,
Cambridge: Cambridge University Press.</li>

<li>Sayre, K. M., 1976, <em>Cybernetics and the Philosophy of Mind</em>,
London: Routledge &amp; Kegan Paul.</li>

<li>Scarantino, A., Piccinini, G., 2010, &ldquo;Information Without
Truth&rdquo;, <em>Metaphilosophy</em>, 41(3): 313&ndash;330.</li>

<li>Sequoiah-Grayson, S., 2007, &ldquo;The Metaphilosophy of
Information&rdquo;, <em>Minds and Machines</em>, 17: 331&ndash;344.</li>

<li>Schaffer, J., 2003, &ldquo;Is There a Fundamental Level?&rdquo;,
<em>No&ucirc;s</em>, 37(3): 498&ndash;517.</li>

<li>Shannon, C. E., 1993, <em>Collected Papers</em>, edited by N. J. A.
Sloane and A. D. Wyner, New York: IEEE Press.</li>

<li>Shannon, C. E. and Weaver, W., 1949, <em>The Mathematical Theory
of Communication</em>, Urbana: University of Illinois Press; reprinted
in 1998.</li>

<li>Simon, H. A., 1969, <em>The Sciences of the Artificial</em>,
Cambridge, Mass., London: MIT Press.</li>

<li>&ndash;&ndash;&ndash;, 1996, <em>The Sciences of the
Artificial</em>, 3rd edition, Cambridge, Mass., London: MIT
Press.</li>

<li>Sloman, A., 1978, <em>The Computer Revolution in Philosophy:
Philosophy, Science and Models of Mind</em>, Hassocks: Harvester.</li>

<li>Smokler, H., 1966, &ldquo;Informational Content: A Problem of Definition&rdquo;,
<em>The Journal of Philosophy</em>, 63(8): 201&ndash;211.</li>

<li>Steane, A. M., 1998, &ldquo;Quantum Computing&rdquo;, <em>Reports
on Progress in Physics</em>, 61: 117&ndash;173.</li>

<li>Thagard, P. R., 1990, &ldquo;Comment: Concepts of
Information&rdquo;, in Hanson [1990].</li>

<li>Weaver, W., 1949, &ldquo;The Mathematics of
Communication&rdquo;, <em>Scientific American</em>, 181(1):
11&ndash;15.</li>

<li>Wheeler, J. A., 1990, &ldquo;Information, Physics, Quantum: The
Search for Links&rdquo;, in <em>Complexity, Entropy, and the Physics
of Information</em>, W. H. Zureck (ed.), Redwood City, CA: Addison
Wesley,</li>

<li>Wiener, N., 1954, <em>The Human Use of Human Beings: Cybernetics and
Society</em>, Boston: Houghton Mifflin; reissued in 1989 with a new
introduction by Steve J. Heims, London: Free Association.</li>

<li>&ndash;&ndash;&ndash;, 1961, <em>Cybernetics or Control and
Communication in the Animal and the Machine</em>, 2nd edition,
Cambridge, Mass.: MIT Press.</li>

<li>Wittgenstein, L. 1960, <em>Preliminary Studies for the
Philosophical Investigations: Generally Known as the Blue and Brown
Books</em>, 2nd edition, Oxford: Basil Blackwell.</li>

<li>&ndash;&ndash;&ndash;, 1980, <em>Remarks on the Philosophy of
Psychology</em>, 2 volumes, Chicago: University of Chicago Press and
Oxford: Basil Blackwell; edited by G. E. M. Anscombe and G. H. von
Wright; translated by G. E. M. Anscombe; Volume edited by G.H. von
Wright and H. Nyman; translated by C.G. Luckhardt and A.E. Aue.</li>

<li>&ndash;&ndash;&ndash;, 1981, <em>Zettel</em>, 2nd edition, edited by
G.E.M. Anscombe and G.H. von Wright; translated by G.E.M. Anscombe,
Oxford: Blackwell.</li>

<li>&ndash;&ndash;&ndash;, 2001, <em>Philosophical Investigations: The
German Text with a Revised English Translation</em>, 3rd edition,
Oxford: Blackwell. Translated by G.E.M. Anscombe. [Incorporates final
revisions made by Elizabeth Anscombe to her English edition. Some
typesetting errors have been corrected, and the text has been
repaginated.]</li>

</ul>

</div>

<div id="academic-tools">

<h2 id="Aca">Academic Tools</h2>

<blockquote>
<table class="vert-top">
<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=information-semantic" target="other">How to cite this entry</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://leibniz.stanford.edu/friends/preview/information-semantic/" target="other">Preview the PDF version of this entry</a> at the
 <a href="https://leibniz.stanford.edu/friends/" target="other">Friends of the SEP Society</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/inpho.png" alt="inpho icon" /></td>
<td><a href="https://www.inphoproject.org/entity?sep=information-semantic&amp;redirect=True" target="other">Look up this entry topic</a>
 at the <a href="https://www.inphoproject.org/" target="other">Internet Philosophy Ontology Project</a>
 (InPhO).</td>
</tr>

<tr>
<td><img src="../../symbols/pp.gif" alt="phil papers icon" /></td>
<td><a href="https://philpapers.org/sep/information-semantic/" target="other">Enhanced bibliography for this entry</a>
at <a href="https://philpapers.org/" target="other">PhilPapers</a>, with links to its database.</td>
</tr>

</table>
</blockquote>


</div>

<div id="other-internet-resources">

<h2><a name="Oth">Other Internet Resources</a></h2>

<ul>

<li><a href="http://media.wiley.com/product_ancillary/91/06312291/DOWNLOAD/introduction.zip" target="other">Introduction</a> (zip file), to the <em>The Blackwell Guide to 
Philosophy of Computing and Information</em>. See also the 
 <a href="http://media.wiley.com/product_ancillary/91/06312291/DOWNLOAD/Glossary.zip" target="other">Glossary of
Technical Terms</a> (zip file), and the 
 <a href="http://media.wiley.com/product_ancillary/91/06312291/DOWNLOAD/futherreading.zip" target="other">Further Reading</a> (zip file).</li>

<li><a href="http://www.iacap.org/" target="other">IACAP &ndash; The International Association for Computing and Philosophy</a></li>

<li><a href="http://www.comlab.ox.ac.uk/activities/ieg/" target="other">Information Ethics Group</a>,
 the Oxford research group on the philosophy of information</li>

<li><a href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?reload=true&amp;arnumber=6773024" target="other">A Mathematical Theory of Communication</a>,
 paper by Claude E. Shannon.</li>

<li><a href="http://www.alcatel-lucent.com/wps/portal/!ut/p/kcxml/04_Sj9SPykssy0xPLMnMz0vM0Y_QjzKLd4w3CTDXL8h2VAQAAWWnZg!!?LMSG_CABINET=Bell_Labs_Research&amp;LMSG_CONTENT_FILE=Research_Centers/Research_Centers_000004.xml&amp;LMSG_PARENT=ROOT" target="other">A basic introduction and history of information theory</a>
 from Bell Labs</li>


<li><a href="https://schneider.ncifcrf.gov/paper/primer/primer.pdf" target="other">Information Theory Primer</a>,
 with an Appendix on Logarithms, by Tom Schneider</li>


<li><a href="http://www.inference.phy.cam.ac.uk/mackay/info-theory/course.html" target="other">A Short Course in Information Theory</a>
 8 lectures, by David J.C. MacKay</li>

</ul>

</div>

<div id="related-entries">

<h2><a name="Rel">Related Entries</a></h2>

<p>

 <a href="../ethics-computer/">computer and information ethics</a> |
 <a href="../computer-science/">computer science, philosophy of</a> |
 <a href="../epistemology-naturalized/">epistemology: naturalism in</a> |
 <a href="../knowledge-analysis/">knowledge: analysis of</a> |
 <a href="../meaning/">meaning, theories of</a> |
 <a href="../probability-interpret/">probability, interpretations of</a> |
 <a href="../propositions/">propositions</a>

</p>

</div>

<div id="acknowledgments">

<h3>Acknowledgments</h3>

<p>
This article is based on Floridi [2003] and [2010]. I am grateful to
Blackwell for permission to reproduce parts of the original text and
to Bosch UK for having allowed me to reproduce the picture in Figure
2. I benefited enormously from many insightful editorial comments by
Fred Kroon and Jerry Seligman on previous drafts. I am also very
grateful to several colleagues and friends for their helpful
suggestions and conversations on previous drafts and past papers on
which this entry is based. They are responsible only for the
improvements not for any remaining mistake: Frederick R. Adams, Mark
Bedau, John Collier, Ian C. Dengler, Michael Dunn, Roger Brownsword,
Timothy Colburn, James Fetzer, Phil Fraundorf, Gian Maria Greco, Ken
Herold, Bernard Katz, Philipp Keller, Gianluca Paronitti, Jeff
Sanders, Sebastian Sequoiah-Grayson, Janet D. Sisson, Ernest Sosa,
J. L. Speranza, Matteo Turilli, and Edward N. Zalta.</p>

</div>

<script type="text/javascript" src="local.js"></script>
<script type="text/javascript" src="../../MathJax/MathJax.js?config=TeX-MML-AM_CHTML"></script>

</div><!-- #aueditable --><!--DO NOT MODIFY THIS LINE AND BELOW-->

<!-- END ARTICLE HTML -->

</div> <!-- End article-content -->

  <div id="article-copyright">
    <p>
 <a href="../../info.html#c">Copyright &copy; 2015</a> by

<br />
<a href="http://www.philosophyofinformation.net/" target="other">Luciano Floridi</a>
&lt;<a href="m&#97;ilto:luciano&#37;2efloridi&#37;40philosophy&#37;2eox&#37;2eac&#37;2euk"><em>luciano<abbr title=" dot ">&#46;</abbr>floridi<abbr title=" at ">&#64;</abbr>philosophy<abbr title=" dot ">&#46;</abbr>ox<abbr title=" dot ">&#46;</abbr>ac<abbr title=" dot ">&#46;</abbr>uk</em></a>&gt;
    </p>
  </div>

</div> <!-- End article -->

<!-- NOTE: article banner is outside of the id="article" div. -->
<div id="article-banner" class="scroll-block">
  <div id="article-banner-content">
    <a href="../../fundraising/">
    Open access to the SEP is made possible by a world-wide funding initiative.<br />
    The Encyclopedia Now Needs Your Support<br />
    Please Read How You Can Help Keep the Encyclopedia Free</a>
  </div>
</div> <!-- End article-banner -->

    </div> <!-- End content -->

    <div id="footer">

      <div id="footer-menu">
        <div class="menu-block">
          <h4><i class="icon-book"></i> Browse</h4>
          <ul role="menu">
            <li><a href="../../contents.html">Table of Contents</a></li>
            <li><a href="../../new.html">What's New</a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
            <li><a href="../../published.html">Chronological</a></li>
            <li><a href="../../archives/">Archives</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-info-sign"></i> About</h4>
          <ul role="menu">
            <li><a href="../../info.html">Editorial Information</a></li>
            <li><a href="../../about.html">About the SEP</a></li>
            <li><a href="../../board.html">Editorial Board</a></li>
            <li><a href="../../cite.html">How to Cite the SEP</a></li>
            <li><a href="../../special-characters.html">Special Characters</a></li>
            <li><a href="../../tools/">Advanced Tools</a></li>
            <li><a href="../../contact.html">Contact</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-leaf"></i> Support SEP</h4>
          <ul role="menu">
            <li><a href="../../support/">Support the SEP</a></li>
            <li><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
            <li><a href="../../support/donate.html">Make a Donation</a></li>
            <li><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
          </ul>
        </div>
      </div> <!-- End footer menu -->

      <div id="mirrors">
        <div id="mirror-info">
          <h4><i class="icon-globe"></i> Mirror Sites</h4>
          <p>View this site from another server:</p>
        </div>
        <div class="btn-group open">
          <a class="btn dropdown-toggle" data-toggle="dropdown" href="https://plato.stanford.edu/">
            <span class="flag flag-usa"></span> USA (Main Site) <span class="caret"></span>
            <span class="mirror-source">CSLI, Stanford University</span>
          </a>
          <ul class="dropdown-menu">
            <li><a href="../../mirrors.html">Info about mirror sites</a></li>
          </ul>
        </div>
      </div> <!-- End mirrors -->
      
      <div id="site-credits">
        <p class="csli-logo"><a href="https://www-csli.stanford.edu/"><img src="../../symbols/SU_csli.png" width="355" alt="Stanford Center for the Study of Language and Information" /></a></p>
        <p>The Stanford Encyclopedia of Philosophy is <a href="../../info.html#c">copyright &copy; 2016</a> by <a href="http://mally.stanford.edu/">The Metaphysics Research Lab</a>, Center for the Study of Language and Information (CSLI), Stanford University</p>
        <p>Library of Congress Catalog Data: ISSN 1095-5054</p>
      </div> <!-- End site credits -->

    </div> <!-- End footer -->

  </div> <!-- End container -->

   <!-- NOTE: Script required for drop-down button to work (mirrors). -->
  <script>
    $('.dropdown-toggle').dropdown();
  </script>



</body>
</html>
