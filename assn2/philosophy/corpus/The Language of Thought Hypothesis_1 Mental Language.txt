 What does it mean to posit a mental language? Or to say that thinking occurs in this language? Just how “language-like” is Mentalese supposed to be? To address these questions, we will isolate some core commitments that are widely shared among LOT theorists. Folk psychology routinely explains and predicts behavior by citing mental states, including beliefs, desires, intentions, fears, hopes, and so on. To explain why Mary walked to the refrigerator, we might note that she believed there was orange juice in the refrigerator and wanted to drink orange juice. Mental states such as belief and desire are called propositional attitudes. They can be specified using locutions of the form X believes that p. X desires that p. X intends that p. X fears that p. etc. By replacing “p” with a sentence, we specify the content of X’s mental state. Propositional attitudes have  intentionality  or aboutness: they are about a subject matter. For that reason, they are often called intentional states. The term “propositional attitude” originates with Russell (1918–1919 [1985]) and reflects his own preferred analysis: that propositional attitudes are relations to   propositions.   A proposition is an abstract entity that determines a truth-condition. To illustrate, suppose John believes that Paris is north of London. Then John’s belief is a relation to the proposition that Paris is north of London, and this proposition is true iff Paris is north of London. Beyond the thesis that propositions determine truth-conditions, there is little agreement about what propositions are like. The literature offers many options, mainly derived from theories of Frege (1892 [1997]), Russell (1918–1919 [1985]), and Wittgenstein (1921 [1922]). Fodor (1981: 177–203; 1987: 16–26) proposes a theory of propositional attitudes that assigns a central role to mental representations. A    mental representation  is a mental item with semantic properties (such as a denotation, or a meaning, or a truth-condition, etc.). To believe that p, or hope that p, or intend that p, is to bear an appropriate relation to a mental representation whose meaning is that p. For example, there is a relation belief* between thinkers and mental representations, where the following biconditional is true no matter what English sentence one substitutes for “p”: X believes that p iff there is a mental representation S such that X believes* S and S means that p. More generally: On this analysis, mental representations are the most direct objects of propositional attitudes. A propositional attitude inherits its semantic properties, including its truth-condition, from the mental representation that is its object. Proponents of (1) typically invoke   functionalism to analyze A*. Each psychological relation A* is associated with a distinctive functional role: a role that S plays within your mental activity just in case you bear A* to S. When specifying what it is to believe* S, for example, we might mention how S serves as a basis for inferential reasoning, how it interacts with desires to produce actions, and so on. Precise functional roles are to be discovered by scientific psychology. Following Schiffer (1981), it is common to use the term “belief-box” as a placeholder for the functional role corresponding to belief*: to believe* S is to place S in your belief box. Similarly for “desire-box”, etc. (1) is compatible with the view that propositional attitudes are relations to propositions. One might analyze the locution “S means that p” as involving a relation between S and a proposition expressed by S. It would then follow that someone who believes* S stands in a psychologically important relation to the proposition expressed by S. Fodor (1987: 17) adopts this approach. He combines a commitment to mental representations with a commitment to propositions. In contrast, Field (2001: 30–82) declines to postulate propositions when analyzing “S means that p”. He posits mental representations with semantic properties, but he does not posit propositions expressed by the mental representations. The distinction between    types and tokens is crucial for understanding (1). A mental representation is a repeatable type that can be instantiated on different occasions. In the current literature, it is generally assumed that a mental representation’s tokens are neurological. For present purposes, the key point is that mental representations are instantiated by mental events. Here we construe the category of   events broadly so as to include both occurrences (e.g., I form an intention to drink orange juice) and enduring states (e.g., my longstanding belief that Abraham Lincoln was president of the United States). When mental event e instantiates representation S, we say that S is tokened and that e is a tokening of S. For example, if I believe that whales are mammals, then my belief (a mental event) is a tokening of a mental representation whose meaning is that whales are mammals. According to Fodor (1987: 17), thinking consists in chains of mental events that instantiate mental representations: A paradigm example is deductive inference: I transition from believing* the premises to believing* the conclusion. The first mental event (my belief* in the premises) causes the second (my belief* in the conclusion). (1) and (2) fit together naturally as a package that one might call the representational theory of thought (RTT). RTT postulates mental representations that serve as the objects of propositional attitudes and that constitute the domain of thought  processes.[1] RTT as stated requires qualification. There is a clear sense in which you believe that there are no elephants on Jupiter. However, you probably never considered the question until now. It is not plausible that your belief box previously contained a mental representation with the meaning that there are no elephants on Jupiter. Fodor (1987: 20–26) responds to this sort of example by restricting (1) to core cases. Core cases are those where the propositional attitude figures as a causally efficacious episode in a mental process. Your tacit belief that there are no elephants on Jupiter does not figure in your reasoning or decision-making, although it can come to do so if the question becomes salient and you consciously judge that there are no elephants on Jupiter. So long as the belief remains tacit, (1) need not apply. In general, Fodor says, an intentional mental state that is causally efficacious must involve explicit tokening of an appropriate mental representation. In a slogan: “No Intentional Causation without Explicit Representation” (Fodor 1987: 25). Thus, we should not construe (1) as an attempt at faithfully analyzing informal discourse about propositional attitudes. Fodor does not seek to replicate folk psychological categories. He aims to identify mental states that resemble the propositional attitudes adduced within folk psychology, that play roughly similar roles in mental activity, and that can support systematic theorizing. Dennett’s (1977 [1981]) review of The Language of Thought raises a widely cited objection to RTT: In a recent conversation with the designer of a chess-playing program I heard the following criticism of a rival program: “it thinks it should get its queen out early”. This ascribes a propositional attitude to the program in a very useful and predictive way, for as the designer went on to say, one can usefully count on chasing that queen around the board. But for all the many levels of explicit representation to be found in that program, nowhere is anything roughly synonymous with “I should get my queen out early” explicitly tokened. The level of analysis to which the designer’s remark belongs describes features of the program that are, in an entirely innocent way, emergent properties of the computational processes that have “engineering reality”. I see no reason to believe that the relation between belief-talk and psychological talk will be any more direct. In Dennett’s example, the chess-playing machine does not explicitly represent that it should get the queen out early, yet in some sense it acts upon a belief that it should do so. Analogous examples arise for human cognition. For example, we often follow rules of deductive inference without explicitly representing the rules. To assess Dennett’s objection, we must distinguish sharply between mental representations and rules governing the manipulation of mental representations (Fodor 1987: 25). RTT does not require that every such rule be explicitly represented. Some rules may be explicitly represented—we can imagine a reasoning system that explicitly represents deductive inference rules to which it conforms. But the rules need not be explicitly represented. They may merely be implicit in the system’s operations. Only when consultation of a rule figures as a causally efficacious episode in mental activity does RTT require that the rule be explicitly represented. Dennett’s chess machine explicitly represents chess board configurations and perhaps some rules for manipulating chess pieces. It never consults any rule akin to Get the Queen out early. For that reason, we should not expect that the machine explicitly represents this rule even if the rule is in some sense built into the machine’s programming. Similarly, typical thinkers do not consult inference rules when engaging in deductive inference. So RTT does not demand that a typical thinker explicitly represent inference rules, even if she conforms to them and in some sense tacitly believes that she should conform to them. Natural language is   compositional: complex  linguistic expressions are built from simpler linguistic expressions, and the meaning of a complex expression is a function of the meanings of its constituents together with the way those constituents are combined. Compositional semantics describes in a systematic way how semantic properties of a complex expression depend upon semantic properties of its constituents and the way those constituents are combined. For example, the truth-condition of a conjunction is determined as follows: the conjunction is true iff both conjuncts are true. Historical and contemporary LOT theorists universally agree that Mentalese is compositional: Compositionality of mental representations (COMP): Mental representations have a compositional semantics: complex representations are composed of simple constituents, and the meaning of a complex representation depends upon the meanings of its constituents together with the constituency structure into which those constituents are arranged. Clearly, mental language and natural language must differ in many important respects. For example, Mentalese surely does not have a phonology. It may not have a morphology either. Nevertheless, COMP articulates a fundamental point of similarity. Just like natural language, Mentalese contains complex symbols amenable to semantic analysis. What is it for one representation to be a “constituent” of another? According to Fodor (2008: 108), “constituent structure is a species of the part/whole relation”. Not all parts of a linguistic expression are constituents: “John ran” is a constituent of “John ran and Mary jumped”, but “ran and Mary” is not a constituent because it is not semantically interpretable. The important point for our purposes is that all constituents are parts. When a complex representation is tokened, so are its parts. For example, intending that \(P \amp Q\) requires having a sentence in your intention box… one of whose parts is a token of the very same type that’s in the intention box when you intend that \(P\), and another of whose parts is a token of the very same type that’s in the intention box when you intend that \(Q\). (Fodor 1987: 139) More generally: mental event \(e\) instantiates a complex mental representation only if \(e\) instantiates all of the representation’s constituent parts. In that sense, \(e\) itself has internal complexity. The complexity of mental events figures crucially here, as highlighted by Fodor in the following passage (1987: 136): Practically everybody thinks that the objects of intentional states are in some way complex… [For example], what you believe when you believe that \(P \amp Q\) is… something composite, whose elements are—as it might be—the proposition that P and the proposition that Q. But the (putative) complexity of the intentional object of a mental state does not, of course, entail the complexity of the mental state itself… LOT claims that mental states—and not just their propositional objects—typically have constituent structure. Many philosophers, including Frege and Russell, regard propositions as structured entities. These philosophers apply a part/whole model to propositions but not necessarily to mental events during which thinkers entertain propositions. LOTH as developed by Fodor applies the part/whole model to the mental events themselves: what’s at issue here is the complexity of mental events and not merely the complexity of the propositions that are their intentional objects. (Fodor 1987: 142) On this approach, a key element of LOTH is the thesis that mental events have semantically relevant complexity. Contemporary proponents of LOTH endorse RTT+COMP. Historical proponents also believed something in the vicinity (Normore 1990, 2009; Panaccio 1999 [2017]), although of course they did not use modern terminology to formulate their views. We may regard RTT+COMP as a minimalist formulation of LOTH, bearing in mind that many philosophers have used the phrase “language of thought hypothesis” to denote one of the stronger theses discussed below. As befits a minimalist formulation, RTT+COMP leaves unresolved numerous questions about the nature, structure, and psychological role of Mentalese expressions. In practice, LOT theorists usually adopt a more specific view of the compositional semantics for Mentalese. They claim that Mentalese expressions have    logical form (Fodor 2008: 21). More specifically, they claim that Mentalese contains analogues to the familiar logical connectives (and, or, not, if-then, some, all, the). Iterative application of logical connectives generates complex expressions from simpler expressions. The meaning of a logically complex expression depends upon the meanings of its parts and upon its logical structure. Thus, LOT theorists usually endorse a doctrine along the following lines: Logically structured mental representations (LOGIC): Some mental representations have logical structure. The compositional semantics for these mental representations resembles the compositional semantics for logically structured natural language expressions. Medieval LOT theorists used syllogistic and propositional logic to analyze the semantics of Mentalese (King 2005; Normore 1990). Contemporary proponents instead use the predicate calculus, which was discovered by Frege (1879 [1967]) and whose semantics was first systematically articulated by Tarski (1933 [1983]). The view is that Mentalese contains primitive words—including predicates, singular terms, and logical connectives—and that these words combine to form complex sentences governed by something like the semantics of the predicate calculus. The notion of a Mentalese word corresponds roughly to the intuitive notion of a concept. In fact, Fodor (1998: 70) construes a concept as a Mentalese word together with its denotation. For example, a thinker has the concept of a cat only if she has in her repertoire a Mentalese word that denotes cats. Logical structure is just one possible paradigm for the structure of mental representations. Human society employs a wide range of non-sentential representations, including pictures, maps, diagrams, and graphs. Non-sentential representations typically contain parts arranged into a compositionally significant structure. In many cases, it is not obvious that the resulting complex representations have logical structure. For example, maps do not seem to contain logical connectives (Fodor 1991: 295; Millikan 1993: 302; Pylyshyn 2003: 424–5). Nor is it evident that they contain predicates (Camp 2018; Rescorla 2009c), although some philosophers contend that they do (Blumson 2012; Casati & Varzi 1999; Kulvicki 2015). Theorists often posit mental representations that conform to COMP but that lack logical structure. The British empiricists postulated ideas, which they characterized in broadly imagistic terms. They emphasized that simple ideas can combine to form complex ideas. They held that the representational import of a complex idea depends upon the representational import of its parts and the way those parts are combined. So they accepted COMP or something close to it (depending on what exactly “constituency” amounts  to).[2]  They did not say in much detail how compounding of ideas was supposed to work, but imagistic structure seems to be the paradigm in at least some passages. LOGIC plays no significant role in their  writings.[3]  Partly inspired by the British empiricists, Prinz (2002) and Barsalou (1999) analyze cognition in terms of image-like representations derived from perception. Armstrong (1973) and Braddon-Mitchell and Jackson (2007) propose that propositional attitudes are relations not to mental sentences but to mental maps analogous in important respects to ordinary concrete maps. One problem facing imagistic and cartographic theories of thought is that propositional attitudes are often logically complex (e.g., John believes that if Plácido Domingo does not sing then either Gustavo Dudamel will conduct or the concert will be cancelled). Images and maps do not seem to support logical operations: the negation of a map is not a map; the disjunction of two maps is not a map; similarly for other logical operations; and similarly for images. Given that images and maps do not support logical operations, theories that analyze thought in exclusively imagistic or cartographic terms will struggle to explain logically complex propositional  attitudes.[4] There is room here for a pluralist position that allows mental representations of different kinds: some with logical structure, some more analogous to pictures, or maps, or diagrams, and so on. The pluralist position is widespread within cognitive science, which posits a range of formats for mental representation (Block 1983; Camp 2009; Johnson-Laird 2004: 187; Kosslyn 1980; McDermott 2001: 69; Pinker 2005: 7; Sloman 1978: 144–76). Fodor himself (1975: 184–195) suggests a view on which imagistic mental representations co-exist alongside, and interact with, logically structured Mentalese expressions. Given the prominent role played by logical structure within historical and contemporary discussion of Mentalese, one might take LOGIC to be definitive of LOTH. One might insist that mental representations comprise a mental language only if they have logical structure. We need not evaluate the merits of this terminological choice.