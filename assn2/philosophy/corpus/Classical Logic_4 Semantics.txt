 Let \(K\) be a set of non-logical terminology. An interpretation for the language \(\LKe\) is a structure \(M = \langle d,I\rangle\), where \(d\) is a non-empty set, called the domain-of-discourse, or simply the domain, of the interpretation, and \(I\) is an interpretation function. Informally, the domain is what we interpret the language  \(\LKe\) to be about. It is what the variables range over. The interpretation function assigns appropriate extensions to the non-logical terms. In particular, If \(c\) is a constant in \(K\), then \(I(c)\) is a member of the domain \(d\). Thus we assume that every constant denotes something. Systems where  this is not assumed are called free logics (see the entry  on free logic). Continuing, If \(P^0\) is a zero-place predicate letter in \(K\), then \(I(P)\) is a truth value, either truth or falsehood. If \(Q^1\) is a one-place predicate letter in \(K\), then \(I(Q)\) is a subset of \(d\). Intuitively, \(I(Q)\) is the set of members of the domain that the predicate \(Q\) holds of. For example,  \(I(Q)\) might be the set of red members of the domain. If \(R^2\) is a two-place predicate letter in \(K\), then \(I(R)\) is a set of ordered pairs of members of \(d\). Intuitively, \(I(R)\) is the set of pairs of members of the domain that the relation \(R\) holds between. For example, (I(R)\) might be the set of pairs \(\langle a,b\rangle\) such that \(a\) and \(b\) are the members of the domain for which \(a\) loves \(b\). In general, if S\(^n\) is an \(n\)-place predicate letter in \(K\), then \(I(S)\) is a set of ordered \(n\)-tuples of members of \(d\). Define \(s\) to be a variable-assignment, or simply an assignment, on an interpretation \(M\), if \(s\) is a function from the variables to the domain \(d\) of \(M\). The role of variable-assignments is to assign denotations to the free variables of open formulas. (In a sense, the quantifiers determine the “meaning” of the bound variables.) Let \(t\) be a term of \(\LKe\).  We define the denotation of \(t\) in \(M\) under \(s\), in terms of the interpretation function and variable-assignment: If \(t\) is a constant, then \(D_{M,s}(t)\) is \(I(t)\), and if \(t\) is a variable, then \(D_{M,s}(t)\) is \(s(t)\). That is, the interpretation \(M\) assigns denotations to the constants, while the variable-assignment assigns denotations to the (free) variables. If the language contained function symbols, the denotation function would be defined by recursion. We now define a relation of satisfaction between interpretations, variable-assignments, and formulas of \(\LKe\). If \(\phi\) is a formula of \(\LKe, M\) is an interpretation for \(\LKe\), and \(s\) is a variable-assignment on \(M\), then we write \(M,s\vDash \phi\) for \(M\) satisfies \(\phi\) under the assignment \(s\). The idea is that \(M,s\vDash \phi\) is an analogue of “\(\phi\) comes out true when interpreted as in \(M\) via \(s\)”. We proceed by recursion on the complexity of the formulas of  \(\LKe\). If \(t_1\) and \(t_2\) are terms, then \(M,s\vDash t_1 =t_2\) if and only if \(D_{M,s}(t_1)\) is the same as \(D_{M,s}(t_2)\). This is about as straightforward as it gets. An identity \(t_1 =t_2\) comes out true if and only if the terms \(t_1\) and \(t_2\) denote the same thing. If \(P^0\) is a zero-place predicate letter in \(K\), then \(M,s\vDash P\) if and only if \(I(P)\) is truth. If S\(^n\) is an \(n\)-place predicate letter in \(K\) and \(t_1, \ldots,t_n\) are terms, then \(M,s\vDash St_1 \ldots t_n\) if and only if the \(n\)-tuple \(\langle D_{M,s}(t_1), \ldots,D_{M,s}(t_n)\rangle\) is in \(I(S)\). This takes care of the atomic formulas. We now proceed to the compound formulas of the language, more or less following the meanings of the English counterparts of the logical terminology. \(M,s\vDash \neg \theta\) if and only if it is not the case that \(M,s\vDash \theta\). \(M,s\vDash(\theta \amp \psi)\) if and only if both \(M,s\vDash \theta\) and \(M,s\vDash \psi\). \(M,s\vDash(\theta \vee \psi)\) if and only if either \(M,s\vDash \theta\) or \(M,s\vDash \psi\). \(M,s\vDash(\theta \rightarrow \psi)\) if and only if either it is not the case that \(M,s\vDash \theta\), or \(M,s\vDash \psi\). \(M,s\vDash \forall v\theta\) if and only if \(M,s'\vDash \theta\), for every assignment \(s'\) that agrees with \(s\) except possibly at the variable \(v\). The idea here is that \(\forall v\theta\) comes out true if and only if \(\theta\) comes out true no matter what is assigned to the variable \(v\). The final clause is similar. \(M,s\vDash \exists v\theta\) if and only if \(M,s'\vDash \theta\), for some assignment \(s'\) that agrees with \(s\) except possibly at the variable \(v\). So \(\exists v\theta\) comes out true if there is an assignment to \(v\) that makes \(\theta\) true. Theorem 6, unique readability, assures us that this definition is coherent. At each stage in breaking down a formula, there is exactly one clause to be applied, and so we never get contradictory verdicts concerning satisfaction. As indicated, the role of variable-assignments is to give denotations to the free variables. We now show that variable-assignments play no other role. Theorem 14. For any formula \(\theta\), if \(s_1\) and \(s_2\) agree on the free variables in \(\theta\), then \(M,s_1 \vDash \theta\) if and only if \(M,s_2 \vDash \theta\). Proof: We proceed by induction on the complexity of the formula \(\theta\). The theorem clearly holds if \(\theta\) is atomic, since in those cases only the values of the variable-assignments at the variables in \(\theta\) figure in the definition. Assume, then, that the theorem holds for all formulas less complex than \(\theta\). And suppose that \(s_1\) and \(s_2\) agree on the free variables of \(\theta\). Assume, first, that \(\theta\) is a negation, \(\neg \psi\). Then, by the induction hypothesis, \(M,s_1 \vDash \psi\) if and only if \(M,s_2 \vDash \psi\).  So, by the clause for negation, \(M,s_1 \vDash \neg \psi\) if and only if \(M,s_2 \vDash \neg \psi\). The cases where the main connective in \(\theta\) is binary are also straightforward. Suppose that \(\theta\) is \(\exists v\psi\), and that \(M,s_1 \vDash \exists v\psi\).  Then there is an assignment \(s_1'\) that agrees with \(s_1\) except possibly at \(v\) such that \(M,s_1'\vDash \psi\).  Let \(s_2'\) be the assignment that agrees with \(s_2\) on the free variables not in \(\psi\) and agrees with \(s_1'\) on the others. Then, by the induction hypothesis, \(M,s_2'\vDash \psi\).  Notice that \(s_2'\) agrees with \(s_2\) on every variable except possibly \(v\). So \(M,s_2 \vDash \exists v\psi\).  The converse is the same, and the case where \(\theta\) begins with a universal quantifier is similar. By Theorem 14, if \(\theta\) is a sentence, and \(s_1, s_2\), are any two variable-assignments, then \(M,s_1 \vDash \theta\) if and only if \(M,s_2 \vDash \theta\).  So we can just write \(M\vDash \theta\) if \(M,s\vDash \theta\) for some, or all, variable-assignments \(s\). So we define \(M\vDash \theta\) where \(\theta\) is a sentence just in case \(M,s\vDash\theta\) for all variable assignments \(s\). In this case, we call \(M\) a  model  of \(\theta\). Suppose that \(K'\subseteq K\) are two sets of non-logical terms. If \(M = \langle d,I\rangle\) is an interpretation of \(\LKe\), then we define the restriction of \(M\) to \(\mathcal{L}1K'{=}\) to be the interpretation \(M'=\langle d,I'\rangle\) such that \(I'\) is the restriction of \(I\) to \(K'\). That is, \(M\) and \(M'\) have the same domain and agree on the non-logical terminology in \(K'\). A straightforward induction establishes the following: Theorem 15. If \(M'\) is the restriction of \(M\) to \(\mathcal{L}1K'{=}\), then for every sentence \(\theta\) of \(\mathcal{L}1K'\), \(M\vDash\theta\) if and only if \(M'\vDash \theta\). Theorem 16. If two interpretations \(M_1\) and \(M_2\) have the same domain and agree on all of the non-logical terminology of a sentence \(\theta\), then \(M_1\vDash\theta\) if and only if \(M_2\vDash \theta\). In short, the satisfaction of a sentence \(\theta\) only depends on the domain of discourse and the interpretation of the non-logical terminology in \(\theta\). We say that an argument \(\langle \Gamma,\theta \rangle\) is semantically valid, or just valid, written \(\Gamma \vDash \theta\), if for every interpretation \(M\) of the language, if \(M\vDash\psi\), for every member \(\psi\) of \(\Gamma\), then \(M\vDash\theta\). If \(\Gamma \vDash \theta\), we also say that \(\theta\) is a logical consequence, or semantic consequence, or model-theoretic consequence of \(\Gamma\). The definition corresponds to the informal idea that an argument is valid if it is not possible for its premises to all be true and its conclusion false. Our definition of logical consequence also sanctions the common thesis that a valid argument is truth-preserving--to the extent that satisfaction represents truth. Officially, an argument in \(\LKe\) is valid if its conclusion comes out true under every interpretation of the language in which the premises are true. Validity is the model-theoretic counterpart to deducibility. A sentence \(\theta\) is logically true, or valid, if \(M\vDash \theta\), for every interpretation \(M\). A sentence is logically true if and only if it is a consequence of the empty set. If \(\theta\) is logically true, then for any set \(\Gamma\) of sentences, \(\Gamma \vDash \theta\). Logical truth is the model-theoretic counterpart of theoremhood. A sentence \(\theta\) is satisfiable if there is an interpretation \(M\) such that \(M\vDash \theta\).  That is, \(\theta\) is satisfiable if there is an interpretation that satisfies it. A set \(\Gamma\) of sentences is satisfiable if there is an interpretation \(M\) such that \(M\vDash\theta\), for every sentence \(\theta\) in \(\Gamma\). If \(\Gamma\) is a set of sentences and if \(M\vDash \theta\) for each sentence \(\theta\) in \(\Gamma\), then we say that \(M\) is a model of  \(\Gamma\). So a set of sentences is satisfiable if it has a model. Satisfiability is the model-theoretic counterpart to consistency. Notice that \(\Gamma \vDash \theta\) if and only if the set \(\Gamma,\neg \theta\) is not satisfiable. It follows that if a set \(\Gamma\) is not satisfiable, then if \(\theta\) is any sentence, \(\Gamma \vDash \theta\).  This is a model-theoretic counterpart to ex falso quodlibet (see Theorem 10). We have the following, as an analogue to Theorem 12: Theorem 17. Let \(\Gamma\) be a set of sentences. The following are equivalent: (a) \(\Gamma\) is satisfiable; (b) there is no sentence \(\theta\) such that both \(\Gamma \vDash \theta\) and \(\Gamma \vDash \neg \theta\); (c) there is some sentence \(\psi\) such that it is not the case that \(\Gamma \vDash \psi\). Proof: (a)\(\Rightarrow\)(b): Suppose that \(\Gamma\) is satisfiable and let \(\theta\) be any sentence. There is an interpretation \(M\) such that \(M\vDash \psi\) for every member \(\psi\) of \(\Gamma\). By the clause for negations, we cannot have both \(M\vDash \theta\) and \(M\vDash \neg \theta\).  So either \(\langle \Gamma,\theta \rangle\) is not valid or else \(\langle \Gamma,\neg \theta \rangle\) is not valid. (b)\(\Rightarrow\)(c): This is immediate.  (c)\(\Rightarrow\)(a): Suppose that it is not the case that \(\Gamma \vDash \psi\). Then there is an interpretation \(M\) such that \(M\vDash \theta\), for every sentence \(\theta\) in \(\Gamma\) and it is not the case that \(M\vDash \psi\).  A fortiori, \(M\) satisfies every member of \(\Gamma\), and so \(\Gamma\) is satisfiable.