 A sentence \(S\) defines its class \(\Mod(S)\) of models. Given two languages \(L\) and \(L'\), we can compare them by asking whether every class \(\Mod(S)\), with \(S\) a sentence of \(L\), is also a class of the form \(\Mod(S')\) where \(S'\) is a sentence of \(L'\). If the answer is Yes, we say that \(L\) is reducible to \(L'\), or that \(L'\) is at least as expressive as \(L\). For example if \(L\) is a first-order language with identity, whose signature consists of 1-ary predicate symbols, and \(L'\) is the language whose sentences consist of the four syllogistic forms (All \(A\) are \(B\), Some \(A\) are \(B\), No \(A\) are \(B\), Some \(A\) are not \(B)\) using the same predicate symbols, then \(L'\) is reducible to \(L\), because the syllogistic forms are expressible in first-order logic. (There are some quarrels about which is the right way to express them; see the entry on the traditional  square of opposition.)  But the first-order language \(L\) is certainly not reducible to the language \(L'\) of syllogisms, since in \(L\) we can write down a sentence saying that exactly three elements satisfy \(Px\), and there is no way of saying this using just the syllogistic forms. Or moving the other way, if we form a third language \(L''\) by adding to \(L\) the quantifier \(Qx\) with the meaning “There are uncountably many elements \(x\) such that …”, then trivially \(L\) is reducible to \(L''\), but the downward Loewenheim-Skolem theorem shows at once that \(L''\) is not reducible to \(L\). These notions are useful for analysing the strength of database query languages. We can think of the possible states of a database as structures, and a simple Yes/No query becomes a sentence that elicits the answer Yes if the database is a model of it and No otherwise. If one database query language is not reducible to another, then the first can express some query that can’t be expressed in the second. So we need techniques for comparing the expressive strengths of languages. One of the most powerful techniques available consists of the back-and-forth games of Ehrenfeucht and Fraïssé between the two players Spoiler and Duplicator; see the entry on  logic and games  for details. Imagine for example that we play the usual first-order back-and-forth game \(G\) between two structures \(A\) and \(B\). The theory of these games establishes that if some first-order sentence \(\phi\) is true in exactly one of \(A\) and \(B\), then there is a number \(n\), calculable from \(\phi\), with the property that Spoiler has a strategy for \(G\) that will guarantee that he wins in at most \(n\) steps. So conversely, to show that first-order logic can’t distinguish between \(A\) and \(B\), it suffices to show that for every finite \(n\), Duplicator has a strategy that will guarantee she doesn’t lose \(G\) in the first \(n\) steps. If we succeed in showing this, it follows that any language which does distinguish between \(A\) and \(B\) is not reducible to the first-order language of the structures \(A\) and \(B\). These back-and-forth games are immensely flexible. For a start, they make just as much sense on finite structures as they do on infinite; many other techniques of classical model theory assume that the structures are infinite. They can also be adapted smoothly to many non-first-order languages. In 1969 Per Lindström used back-and-forth games to give some abstract characterisations of first-order logic in terms of its expressive power. One of his theorems says that if \(L\) is a language with a signature \(K, L\) is closed under all the first-order syntactic operations, and \(L\) obeys the downward Loewenheim-Skolem theorem for single sentences, and the compactness theorem, then \(L\) is reducible to the first-order language of signature \(K\). These theorems are very attractive; see Chapter XII of Ebbinghaus, Flum and Thomas for a good account. But they have never quite lived up to their promise. It has been hard to find any similar characterisations of other logics. Even for first-order logic it is a little hard to see exactly what the characterisations tell us. But very roughly speaking, they tell us that first-order logic is the unique logic with two properties: (1) we can use it to express arbitrarily complicated things about finite patterns, and (2) it is hopeless for discriminating between one infinite cardinal and another. These two properties (1) and (2) are just the properties of first-order logic that allowed Abraham Robinson to build his nonstandard analysis. The background is that Leibniz, when he invented differential and integral calculus, used infinitesimals, i.e. numbers that are greater than 0 and smaller than all of 1/2, 1/3, 1/4 etc. Unfortunately there are no such real numbers. During the nineteenth century all definitions and proofs in the Leibniz style were rewritten to talk of limits instead of infinitesimals. Now let \(\mathbb{R}\) be the structure consisting of the field of real numbers together with any structural features we care to give names to: certainly plus and times, maybe the ordering, the set of integers, the functions sin and log, etc. Let \(L\) be the first-order language whose signature is that of \(\mathbb{R}\). Because of the expressive strength of \(L\), we can write down any number of theorems of calculus as sentences of \(L\). Because of the expressive weakness of \(L\), there is no way that we can express in \(L\) that \(\mathbb{R}\) has no infinitesimals. In fact Robinson used the compactness theorem to build a structure \(\mathbb{R}'\) that is a model of exactly the same sentences of \(L\) as \(\mathbb{R}\), but which has infinitesimals. As Robinson showed, we can copy Leibniz’s arguments using the infinitesimals in \(\mathbb{R}'\), and so prove that various theorems of calculus are true in \(\mathbb{R}'\). But these theorems are expressible in \(L\), so they must also be true in \(\mathbb{R}\). Since arguments using infinitesimals are usually easier to visualise than arguments using limits, nonstandard analysis is a helpful tool for mathematical analysts. Jacques Fleuriot in his Ph.D. thesis (2001) automated the proof theory of nonstandard analysis and used it to mechanise some of the proofs in Newton’s Principia.