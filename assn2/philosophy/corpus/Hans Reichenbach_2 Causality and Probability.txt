 Reichenbach's doctoral thesis, The Concept of Probability in the Mathematical Representation of Reality (1915b), contains many of the themes that concerned him throughout his life, and anticipated in some detail 21st century philosophical discussions of probability relations between microscopic and macroscopic systems. Indeed, the development of his ideas about causality and probability from 1915 until the end of his life can be seen as a series of reexaminations and reformulations of issues the thesis implicitly posed and the solutions it explicitly offered. The thesis develops an account of probability appropriate for scientific inference. It presents an argument to supplement what Reichenbach understands to be Kant's transcendental principle of causality with a transcendental principle of probability. In Reichenbach's reading of Kant, the “principle of causality” asserts that every event is preceded by a cause that determines it according to some universal law (see the discussion of Kant's principle in Section 2 of the entry on  Kant and Hume on Causality).  The principle is “transcendental” because it cannot be empirically established, but is instead a precondition for the very possibility of empirical knowledge. Reichenbach's claim is that there is a principle of probability that has an equal status: it cannot be empirically established, but it is a precondition of empirical knowledge. It states that events are governed by a probability distribution. Reichenbach considers, and rejects, the subjective interpretation of probability advocated by the then prominent philosopher and psychologist Carl Stumpf (1892a, b), and, less emphatically, the attempt at an objective interpretation advocated by Johannes von Kries (1886), a physiologist who had studied with Hermann von Helmholtz. According to Reichenbach, von Kries's account of probability needs to be freed from the principle of insufficient reason—that mutually exclusive events of which we have no knowledge that would determine differential probability are equally probable. As a subjective principle, Reichenbach claimed, it had no place in science. Reichenbach insists on an “objective” interpretation of probability—in the Kantian sense as about the world of experience—for which probability statements are synthetic, but not verifiable, claims about the empirical world. His task, as he sees it, is to demonstrate that probabilistic statements are supported by a claim—the “existence of a probability function”—which is a transcendental principle that is necessary, and in combination with causal principles sufficient, for empirical knowledge. Reichenbach's technical argument is an adaptation of Henri Poincaré's results on probability functions and what have since come to be called “strike ratios” (Poincaré, 1912, pp. 148–150). By considering events collected in a histogram, in which alternate equally narrow columns are black and white, Reichenbach argues that as the number of (independent) events increases (and the width of the columns decreases) the ratio of black to white events within any interval of the abscissa will approximate 1. Reichenbach's general idea is that if a variable X is divided into two or more classes of very small intervals of equal width (in X units) juxtaposed in a definite order and proportion, then there will be a probability for the occurrence of a value of X within any particular class that is invariant over all Riemann integrable probability distributions for X. (The Riemann integral of a function describing a curve is defined as the limit of the sum of rectangles touching the curve as their width approaches 0.) Reichenbach extends the analysis to error probabilities for physical measurements. He then argues that since all physical measurements are subject to error, knowledge of natural laws is possible only if errors occur subject to a probability distribution, a proposition that is synthetic but cannot be established empirically. Empirical knowledge thus requires both an a priori principle of causality for individual events and an a priori principle of probability to ensure that individual events can be aggregated into general laws. No explicit interpretation of probability is forwarded, although Reichenbach implies that probability claims are about frequencies of causally independent events—a notion for which probability theorists would later substitute the idea of independent, identically distributed events (see the entry on  probabilistic causation)—  in observed and unobserved collections of cases. Further Reading. The thesis with an introduction to the arguments can be found in Reichenbach (2008). Re-statements and slight variations of the arguments in the thesis can also be found in Reichenbach (1920c), Reichenbach (1920e) and to a lesser extent in Reichenbach (1930g) and chapter 9 of Reichenbach (1949f). A synopsis is also given in Padovani (2011), while Eberhardt (2011) provides a critical assessment of the thesis. Reichenbach's allegiance to Kantian formulations waxed and waned and transformed over time, but while the terminology changed, Reichenbach long retained the essential claim of his doctoral thesis that the establishment of any empirical law requires a superempirical presupposition about probability. In 1920, the argument and conclusions of the thesis were repeated with little qualification or variation in two essays, “The Physical Presuppositions of the Calculus of Probability”, and “A Philosophical Critique of the Probability Calculus”. Again in “Causality and Probability”, in 1930, Reichenbach reprises the claims of his doctoral thesis, but substitutes the “principle of induction”—that observed frequencies will continue to hold in new cases—for the “principle of probability.” The principle of induction is not given an explicitly a priori basis, the possibility of which Reichenbach had come to doubt when studying with Einstein (see Reichenbach, 1920f). Instead, it is justified by an uneasy mixture of loose convergence arguments (foreshadowing the straight rule, see below) and psychological habit. Without attribution, he dismisses a “conventionalist” account of the principle of induction, expressed in nearly Kantian terms, as “the principle of induction is not a statement about the physical world, but merely constitutes an ordering principle of science.” He argues that such an account does not “justify” scientific preferences for simpler hypotheses (1930g, see Reichenbach 1978, vol. II, p. 340–341). Arbitrary convention could choose any scientific hypothesis that captures the phenomena, but a descriptively accurate account of theory selection in science must explain why simpler theories should be preferred. The justification of the preference for simpler hypotheses remains unexplained in “Causality and Probability”, and Reichenbach's own conclusion seems to be essentially the Kantian principle he rejects, supplemented with an attempt to prove that the principle of induction is unchallengeable because, in his view, probability claims are generalizations over as yet unobserved cases and therefore presuppose the principle of induction: In a further break with the Kantian tradition, the role of causation as conceptually primitive is reconsidered. It is difficult to pinpoint Reichenbach's position between 1915 and 1935 since his writings mix epistemic and metaphysical issues. In his thesis (1915b) and in “Stetige Wahrscheinlichkeitsfolgen” (1929L) Reichenbach is committed to individual deterministic causal events. In “The Causal Structure of the World” (1925d) probability is regarded as the more fundamental concept. In later years Reichenbach often cited this paper as an anticipation of the indeterminism of quantum theory, because his account allows the possibility that finer and finer measures will not converge to deterministic laws (see Gerner, 1997, p. 153). In “Causality and Probability” (1930g) causality explicitly refers to regularities in populations rather than to particular events, a view whose source Reichenbach attributes to Ludwig Boltzmann's development of the theory of gases. The separation of causality and probability, and the recasting of causality as a higher level concept, required that Reichenbach find a new foundation for probability. Presumably due to the influence of his colleague Richard von Mises, Reichenbach moved towards a view of probability as a property of sequences. Reichenbach's 1925 essay “The Causal Structure of the World” (1925d) is also an early attempt to account for the direction of time in terms of causal and probabilistic asymmetries. Reichenbach there introduces the notion of a “probability implication” with 10 axiom schemes on propositional variables involving both material implication and a new 2-place probability implication connective. The axioms are evidently meant to supplement those of propositional logic. No rules of inference are specified, but substitution and modus ponens are used. The axioms do not guarantee that a probability implication, a ⊇  b[2],  is the conditional probability of b given a, or even that the consequents of a collection of probability implications with a as antecedent satisfy the axioms of finite probability. Interpretation is difficult, since Reichenbach both asserts that the probability of the consequent in a probability implication can be between 0 and 1 inclusive (1925d, 1978, vol. II, p. 89), but then disallows a probability implication because the consequent has probability 0 (p. 92). Reichenbach's thought seems to be that a ⊇ b asserts that in circumstance a, b has a well defined probability, that is, a specifies something like what Ian Hacking (1965) later called a “chance setup,” or as Reichenbach might have put it, implies the existence of a probability function for {b, ~b}. Reichenbach uses the operation very much in that way in his 1925 discussion of the direction of time, which he thinks can be founded on cases in which a ⊇ b is true but b ⊇ a is false. Even under this reading some of his axiom schemes have false instances, e.g., (a ⊇ b) ⊃ (a.c ⊇ b), where the dot is ordinary conjunction. (The claim that b has a probability distribution in context a does not necessarily imply that b has a probability distribution in context a conjoined with context c, since c might make a distribution impossible.) Revised, probability implication later became a foundational notion of Reichenbach's theory of probability and the central concept of his approach to inductive logic. Further Reading. For Reichenbach's views on causality see also the discussion of  “The Direction of Time”  below and the separate entry on Reichenbach's  Common Cause Principle. Reichenbach continued to revise and elaborate his ideas about probability in a series of papers in the early  1930s[3]  until, in 1935, his The Theory of Probability provided a fuller statement of his developed view. Surprisingly, Reichenbach does not acknowledge help from Richard von Mises, his colleague in Berlin and Istanbul in the period and the mathematician whose views on the foundations of probability were closest to his own and are often discussed in the book. He does attribute part of the mathematical work in the book to Valentine Bargmann, who after finishing his doctorate in physics in Berlin fled to Switzerland in 1933 and later became an assistant to von Neumann and to Einstein at the Institute for Advanced Study, from where in the 1940s he also assisted Reichenbach's work on quantum theory. It is fair to say that The Theory of Probability was not well received, drawing intense criticism from Karl Popper (1934), who had read Reichenbach's papers presenting a frequentist interpretation of probability, C.I. Lewis (1952), Bertrand Russell (1948), and Ernest Nagel (1936, 1938). Kolmogorov's measure theoretic axioms for probability, which appeared in 1933, soon overshadowed Reichenbach's formulation of the theory of probability. The Theory of Probability uses class terms—A, B, C—and individual variables—x, y, z—as well as real variables—p, q, u, r, w. Distinct individual variables are (unnecessarily) sometimes and sometimes not associated with distinct class names, but Reichenbach's formulae without iterated probability conditionals can be read as universally quantified with a single individual variable. The earlier 10 axiom schemes for probability implication (1925d) are replaced by 4 axiom schemes expressed in Reichenbach's abbreviated form as (1949f, p. 53–65): Reichenbach's intent with formula I is to say that where it exists, the probability has a unique value. Axiom II is meant to ensure that the probabilities conditional on a nonempty set have values between 0 and 1 inclusive. Axiom III is Reichenbach's version of the requirement that the probability of the union of mutually exclusive events is the sum of their probabilities. Axiom IV is essentially the chain rule of probability: P(CB | A) = P(C | BA) P(B | A). Axiom I is implicit in the Kolmogorov axioms (see Section 1 ("Kolmogorov's Probability Calculus") in the entry on  interpretations of probability)  since probability is taken to be a real valued function. Axiom II corresponds to Kolmogorov's first and second axioms, that probability values are bounded between 0 and 1 inclusive. Axiom III amounts to finite additivity because Reichenbach's logic does not have infinite disjunctions: it is a finite restriction of Kolmogorov's third axiom, which postulates additivity of probabilities for countable, even infinite, disjoint sets. Axiom IV (at least its interpretation in terms of the chain rule) follows from Kolmorogov's first three axioms. Reichenbach requires it as an additional axiom, because of his mixture of logical and mathematical notation. Without the additional fourth axiom, Reichenbach could not switch between logical conjunction and mathematical multiplication. Reichenbach proceeds to show that finite frequencies satisfy his four axioms. He construes all probabilities as frequencies of sub-series in a larger series—or what is the same thing for finite sets, cardinalities of subsets in a universal set. Hence his probabilities are always with respect to a non-empty reference class, so the probability that an event is in a class B is in Reichenbach's notation, P(A, B) where A is the reference class—similar to the modern notation of the conditional probability P(B | A). But the probability logic axioms are so weak that many formal structures satisfy them, and Reichenbach's claim is a long way from a representation theorem. He fails to provide the additional constraints on the space that probabilities are applied to, which in Kolmogorov's case are given by the assumption that the space is a sigma-field, i.e. a field closed under complementation and countable union. Reichenbach's official definition of probability for infinite sequence pairs 〈xi, yi〉 with xi in A, and yi in B, for which the limit p of the relative frequency of B in A exists, is as follows: “the limit p is called the probability from A to B within the sequence pair.” (1949f, p. 69). Constraints on the nature of the sequences are added later (1949f, section 30) that are aimed to formalize aspects of randomness. Probabilities of single cases are “fictive” or elliptical, to be understood as claims about the frequency of a kind of case in an implicit reference class. Elsewhere, Reichenbach puts more emphasis on finite frequencies and even suggests that limiting frequencies are simply a mathematical device for justifying inductive procedures (‘A letter to B. Russell’, 1978, vol. II, p. 405–406). Once introduced, the logical framework is dropped in the mathematical development of probability theory in the book. In combination with the representation of probability relations by claims in a quasilogical language, the limiting frequency interpretation creates fundamental formal problems that Reichenbach did not foresee. Sets of limiting relative frequencies are not closed under finite intersection; they are not closed under countable union; they do not satisfy countable additivity. They do not, in other words, form a sigma field, or a Borel field, or even a field. (See the entries on  interpretations of probability,  the early development of set theory, and  set theory.)  These and several other mathematical difficulties of Reichenbach's setup are described in van Fraassen  (1979).[4] Reichenbach imposes two further axioms—the axioms of order (1949f, p. 137)—that are supposed to hold necessarily of limiting frequencies for infinite time series. One is trivial, essentially asserting that a conditional frequency on lags (Reichenbach's term for lags is “phases”) of a constant “variable” can always be replaced by a conditional frequency on no lag of that variable. The second, however, appears to be a very strong stationarity principle that is not generally true: the probability of one variable conditional on a specified common lag of other variables is invariant under all uniform translations of the lags. This axiom seems to derive directly from Reichenbach's interpretation of the foundations of probability, in particular from Reichenbach's assumption about normal sequences, described below. In addition to an axiomatization, Reichenbach attempts to provide a foundation for probability claims in terms of properties of sequences, similar to von Mises. Reichenbach regarded von Mises attempt (von Mises 1919) at formally characterizing a “random sequence” as a failure and instead attempted to characterize a weaker sequence property—a “normal” sequence. In his account of normal sequences Reichenbach retains (although the second only in a weaker form) two features that are deemed essential for random sequences: the lack of “after-effect” and the invariance of the limiting relative frequency under subsequence selection. Informally, the “invariance under subsequence selection” is supposed to capture the idea that the probabilities of events in any infinite subsequence selected from the original sequence by a procedure based on the indices of events in the original sequence alone will be the same as the probabilities of events in the original sequence. “The lack of aftereffect” is supposed to capture the idea that given any initial segment of a sequence, one cannot predict the probability of the next event any better than predicting it based on the limiting relative frequency of events in the infinite sequence. Reichenbach's definition of lack of aftereffect is not based on initial segments of sequences, but rather on subsequences selected by a particular set of rules (1949f, p. 142). Reichenbach defines a “selection” S as any rule that determines for each member of a sequence whether it is a member of S (p. 143). He intends by a “rule” literally any subsequence. We are unable to reconstruct exactly what Reichenbach may have intended, in particular since his definition of lack of aftereffect is difficult to distinguish from the criterion of invariance under subsequence selection. But we believe it is something close to the following: A sequence of Bi is “free from aftereffect” if (i) a subsequence is selected based on a rule of the form “For each index i in the sequence, include the (i+k)th element in the sequence if the ith element is B (or ~B),” (ii) if the subsequence thus selected has the same event probabilities as the original sequence, and (iii) if this holds for all lags k > 0. If our reconstruction is correct, this would distinguish Reichenbach's account of lack of aftereffect from that of invariance under subsequence selection, because the former includes subsequence selection rules that depend on the values of certain items in the sequence, while the latter includes only rules that are based on the indices. Two more definitions are required for the full picture. First, a selection S of a subsequence of sequence A belongs to the “domain of invariance” of B, if the probability of B (for all lags) in S is unchanged from the probability of B in A, and if the same holds for any selection S from A with a lag. Second, a subsequence selected by an algebraic rule that partitions the sequence A—e.g. take every fourth element (see p. 144 for details)—is called a “regular division” of A. Putting the pieces together, Reichenbach requires for the “normality” of a sequence A that it be free of aftereffect and that all “regular divisions” of A are in the domain of invariance of B. This condition of regular divisions seems to underlie the stationarity expressed in the second axiom of order. If random sequences are taken to satisfy (at least) the conditions of the lack of aftereffect and invariance of subsequence selection under any selection rule, then Reichenbach's restriction of subsequence selection rules to regular divisions implies that the set of normal sequences is a proper superset of that of random sequences. Reichenbach accepts this weakening to avoid some of the difficulties in characterizing a random sequence, and to broaden his earlier notions of probability to include sequences of trials, which might not be perfectly independent. In later writings, he seems to suggest that as long as the sequence converges, probability claims can be applied to the component events. A large section of the book is devoted to reconstructing classical results in the theory of probability as claims about relative frequencies, including various continuous distributions and Bernoulli's theorem. Reichenbach claims that probabilities on continuous domains are “isomorphic” to limiting relative frequencies, but, as van Fraassen (1979) notes, it is difficult to see any sense in which that is true. The remainder of the book is not about probability per se, but about its epistemological role. Further Reading. A detailed attempt at the reconstruction of Reichenbach's account of probability and its epistemological grounding can be found in Eberhardt & Glymour (2011), which includes specific references to the original sources.