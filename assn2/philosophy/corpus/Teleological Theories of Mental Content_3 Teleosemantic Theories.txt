 What all teleological (or “teleosemantic”) theories of mental content have in common is the idea that psycho-semantic norms are ultimately derivable from functional norms. Beyond saying this, it is hard to give a neat definition of the group of theories that qualify. Consider, for instance, some theories that are clearly intended as alternatives to teleosemantics, such as Fodor's (1990b) asymmetric dependency theory or theories that appeal to convergence under ideal epistemic conditions (see Rey 1997 for an outline).  Elaboration of these theories is beyond the scope of this entry but we can note that they both seem to need a notion of normal or proper functioning.  Fodor's theory adverts to the “intact” perceiver and thinker. Presumably this is someone whose perceptual and cognitive systems are functioning properly (this is covered under the ceterus paribus part of the laws to which Fodor's theory refers). The idea of convergence under ideal epistemic conditions also involves a notion of normal functioning, for epistemic conditions are not ideal if perceivers and thinkers are abnormal in certain respects, such as if they are blind or psychotic. If normal or proper functioning is analyzed in terms of an etiological theory, which says that a system functions normally or properly only if all of its parts possess the dispositions for which they were selected, then these theories would qualify as teleological theories of mental content under the characterization provided in the first paragraph of this section.  Those who propose these theories might reject an etiological theory of functions, but they need some analysis of them. There could anyway be etiological or teleological versions of theories of this sort. An appeal to teleological functions can also be combined with a variety of other ideas about how content is determined. For example, there can be both isomorphic and informational versions of teleosemantics.  In the former case, the proposal might be that the relevant isomorphism is one that cognitive systems were adapted to exploit.  An alternative idea is that the isomorphism does not need to be specified given that the targets of representations are determined by teleological functions.  This appears to be the view of Cummins (1996, see esp. p.120) although Cummins is generally critical of teleological functions in biology. A teleological version of an informational theory is given when content is said to depend on information carrying, storing or processing functions of mechanisms. The relevant notion of information is variously defined but (roughly speaking) a type of state (event, etc.) is said to carry natural information about some other state (event, etc.) when it is caused by it or corresponds to it. It is sometimes said that the role of functions in a teleological theory of content is to explain how error is possible, rather than to explain how content is determined, but the two go hand in hand. To see this, it helps to start with the crude causal theory of content and to see how the problem of error arises for it. According to the crude causal theory, a mental representation represents whatever causes representations of the type; Rs represent Cs if and only if Cs cause Rs. One problem with this simple proposal is its failure to provide for the possibility of misrepresentation, as Fodor (1987, 101–104) points out. To see the problem, recall the occasion on which crumpled paper is seen as a cat. The crude causal theory does not permit this characterization of the event because, if crumpled paper caused a tokening of CAT then crumpled paper is in the extension of CAT, according to the crude causal theory. Since cats also sometimes cause CATs, cats are in the extension too. However, the problem is that crumpled paper is included in the extension as soon as it causes a CAT to be tokened and so, on this theory, there is no logical space for the possibility of error since candidate errors are transformed into non-errors by their very occurrence. Note that the problem is simultaneously one of ruling in the right causes without also ruling in the wrong ones. CAT cannot have the content cat unless non-cats (including crumpled paper) are excluded from its content. So explaining how content is determined and how the possibility of error are accommodated are not separate tasks. The error problem is an aspect of what (after Fodor) is often called “the disjunction problem.” With respect to the crude causal theory, the name applies because the theory entails disjunctive contents when it should not.  For example, it entails that CATs have the content cats or crumpled paper in the case just considered. The disjunction problem is larger than the problem of error, however, because it is not only in cases of error that mental representations are caused by things that are not in their extensions (Fodor, 1990c). Suppose, for example, that Mick's talking about his childhood pet dog reminds Scott of his childhood pet cat. In this case no misrepresentation is involved but the crude causal theory again entails inappropriate disjunctive contents. Now it entails that Scott's CATs has a content along the lines of cats or talk of pet dogs. This last aspect of the disjunction problem might be called the problem of representation in absentia: how do we explain our capacity to think about absent things? How do mental representations retain or obtain their contents outside of perceptual contexts? Asking how to alter the crude causal theory to allow for error is one place to begin looking for a more adequate proposal. One approach would be to try to describe certain situations in which only the right causes can produce the representation in question and to maintain that the content of the representation is whatever can cause the representation in such situations. This is sometimes referred to as a “type 1 theory.” A type 1 theory distinguishes between two types of situations, ones in which only the right causes can cause a representation and ones in which other things can too.  A type-1 theory says that the first type of situation is content-determining. A type 1 teleological theory might state, for example, that the content of a perceptual representation is whatever can cause it when the perceptual system is performing its proper function, or when conditions are optimal for the proper performance of its function. The content of representations in abstract thought might then, it might be proposed, be derived from their role in perception. Not all teleological theories of content are type 1 theories, however. The theory described in the next section is arguably a variant of a type 1 theory but some of the theories described in later sections are not. The following sub-sections describe some key differences among teleological theories. It is not possible to describe all extant theories but some different approaches are sketched, along with a brief review of some of their strengths and weaknesses. General objections to teleological theories are discussed later, in  section 4. Stampe (1977) was one of the first philosophers in modern times to suggest a theory of content according to which content is a matter of reliable causes. Dretske's book, Knowledge and the Flow of Information (1981) has also been very influential.  The theory Dretske develops in that book is not a teleological theory of mental content but Dretske (1986, 1988, 1991) later offers a teleo-functional version of indicator-semantics. He begins with a notion of information-carrying, which he calls “indicating”, and suggests that a representation's content is what it has the function to indicate. Dretske (1981) provides the most careful analysis of the indication relation and he often refers back to this in his later work.  However, it adverts to background knowledge and, since knowledge is intentional, this aspect of it is omitted in his theory of content, at least as it applies to the simplest kinds of mental representations. The analysis of indication on which his theory of content relies is as follows: an event of type R indicates that a state of affairs of type C is the case if and only if the probability of C, given that R is instanced, is one (assuming that certain background or “channel conditions” obtain). Although indication is often be underwritten by a causal regularity such that Cs cause Rs, Dretske tell us that it is not a requirement that Cs cause Rs. Cs and Rs might have a common cause, for instance. He also tells us that it need not be a law that if R then C, though it cannot be merely coincidental. For local reasons, it could be that if there is an R then there is always a C. One of his examples is of doorbell ringings: if there is someone ringing the doorbell whenever the doorbell rings in his neighborhood, its ringing indicates that someone is at the door. But if squirrels start to ring doorbells because people start making them out of nuts, a ringing doorbell will no longer indicate that someone is at the door. Dretske points out that representation is not equivalent to indication.  “R indicates C” entails “if R then C.” But, since misrepresentation is possible, it must be the case that “R represents C” does not entail “if R then C.” (At any rate, “R indicates C” entails “if R then C” if the relevant channel conditions obtain.)  So Dretske (1986) suggests that perceptual representations have the function of indicating. The starting idea is this: if something has the function of indicating something else then it is supposed to indicate it but, since items don't always perform their functions, room for error has been made.  Dretske appears to rely on an etiological analysis of functions (see e.g., Dretske 1995, p. 7). He speaks of states acquiring a function to indicate by being selected or recruited for indicating.  Roughly, Dretske suggests that Rs represent Cs iff Rs were recruited for indicating Cs and for causing a bodily movement, M. Dretske (1995, p. 2) says, “[t]he fundamental idea is that a system, S, represents a property, F, if and only if S has the function of indicating (providing information about) the F of a certain domain of objects. The way S performs its function (when it performs it) is by occupying different states s1, s2, … sn corresponding to the different determinate values f1, f2 … fn, of F.” For example, part of the visual system might represent the orientation of lines in a region of the visual field. If so, it does so because it has the function of carrying information about the orientation of lines in that region and it performs this function (when it performs it) by entering into different states when different orientations of lines are present in that region. This account of representation seems to make room for error, because it implies that representations need only indicate their contents during recruitment or in the environment and given the channel conditions in which recruitment took place; error being possible after that time or in other environments or circumstances. However, Dretske (1986) sees a problem with this suggestion. He illustrates the problem with the case of ocean-dwelling anaerobic bacteria that have tiny magnets (magnetesomes) that are attracted to magnetic north, which serve to direct the bacteria downwards into the relatively oxygen-free sediment on the ocean floor . Plausibly, the function of the magnetesomes is to direct the bacteria to anaerobic conditions. If we “fool” the bacteria by holding a bar magnet nearby and lead the bacteria upward to their death, this looks like a case of natural misrepresentation. We were, in Dretske's words, looking for “nature's way of making a mistake” and we seem to have found it. The problem, says Dretske, is that it is indeterminate how we should describe the function of the magnetesomes. We can plausibly say that they have the function of indicating the oxygen-free sediment. But we can also plausibly say that they have the function of indicating geo-magnetic or even local magnetic north. If we say the latter, no misrepresentation has occurred.  So Dretske's interim conclusion is that we cannot count this as an unambiguous case of error, on his theory as outlined so far. A number of distinct problems go under the name of “the functional indeterminacy problem” (section 4.1) and the magnetesome example can be used to illustrate several of them. However, Dretske's response to the indeterminacy problem that he raised suggests that his main concern was with what is known as the problem of distal content. His problem, then, is this.  Suppose that we have a simple system that has just one way of detecting the presence of some feature of the environment. We have just seen a case of this for the anaerobic bacteria have just one way of detecting anaerobic conditions (via the local magnetic field). In such a case, if an inner state indicates the distal feature (anaerobic conditions) it will also indicate the more proximal feature (local magnetic north). Moreover, if there was selection for indicating the distal feature, there will also have been selection for indicating the more proximal feature (since it is by indicating the latter that it indicates the former). Dretske further points out that, even if a creature has several routes by which it can detect a given distal feature (e.g., even if the bacteria can detect anaerobic conditions by means of light sensors as well) there would still be a disjunction of more proximal features that the representation could count as representing, since it could still count as having the function of indicating the disjunction of more proximal features (i.e., local magnetic north or reduced light). While we might be perfectly willing to allow that the magnetesomes in anaerobic bacteria do not represent or misrepresent, the problem of distal content generalizes. When you see a chair across the room as a chair across the room, you represent it as a solid 3D object at a distance from you and not as a stream of light reflected from it or as a pattern of firings in your retinas.  Otherwise you would not try to walk to the chair and sit on it. An informational theory of content must therefore explain how mental representations represent distal features of the world, as opposed to the more proximal items that carry information about those distal features to the representations that represent them. Dretske (1986) therefore modifies his proposal and maintains that a creature that is capable of representing determinate content must be capable of learning any number of new epistemic routes to the same distal feature. In that case, he says, there is no closed disjunction of more proximal stimuli that the representation could count as representing. He speaks of conditioning in this context. The relevant representation is recruited by conditioning to indicate the distal feature rather than the disjunction of more proximal features, because there is no finite time-invariant disjunction of more proximal stimuli that it has the function of indicating. Loewer (1987) points out that conditioning ends at death, at which point no further epistemic routes can be acquired. So, at the death of a creature, there will be a closed disjunction of proximal features that each of the creature's representations was recruited to indicate. (Loewer comments that Dretske might appeal to epistemic routes that could possibly be acquired by a creature but is unsure if this succeeds.) The claim that misrepresentation is impossible without learning anyway seems problematic, since it seems to preclude representations produced by innate input systems, such as innate sensory-perceptual systems. Some psychologists also claim that some core concepts are innate (e.g., see Carey 2009). Later, Dretske (1988) drops his conditioning requirement insofar as it is a requirement on content possession but he keeps it as a requirement for the kind of content that can explain behavior.  (For discussion of Dretske's account of the causal efficacy of content, see the essays in McLaughlin (1991).) This re-raises the question of how representations produced by innate input analyzers have distal content. Dretske's strict characterization of indication is thought by some to be troublesome.  One reason is that there can be no non-intentional process of selection for something to do Z unless that thing, or things of that type at least, did do Z.  Hearts cannot be selected for pumping blood by natural selection unless some hearts pump blood. Similarly, no mechanism can be selected for producing Rs because they indicate Cs unless some Rs indicate Cs. However, all Rs must indicate Cs in a region of space-time if any are to do so, given the strict characterization of indication (for if Rs indicate Cs in that region, then in that region it must be the case that C being the case, given an R-tokening, has a probability of one). Hence, where and while recruitment continues, Rs cannot occur without Cs.  Fodor (1990b) questions whether this requirement would be met or met often enough, given that misrepresentation can occur later. Perhaps Dretske's appeal to channel conditions can help him out of this apparent difficulty.  However, specifying channel conditions without being ad hoc or circular or adverting to intentional phenomena (such as that a perceiver is not distracted) could prove difficult. There are some hints in Dretske's writings of a willingness to use a less strict notion of indication for he sometimes speaks of the content of a representation as the “maximally indicated state.” This suggests that there are more minimally indicated states, which would be an oxymoron on the strict interpretation. However, this looser interpretation is not developed in Dretske's writings and his (1981) offers several arguments against loosening the requirement. A further argument against indicator-semantics involves the claim that something qualifies as a representation only if it is used as a representation. Millikan (1989, pp. 84–90) argues that a representation's content must therefore be determined by its use or else something could count as a representation without representing anything, which would be nonsense. The thought seems to be this: if representational status and representational content are determined separately, they could come apart and, if they could came apart, something could count as a representation by satisfying the requirement for representational status, without representing anything in particular by at the same time failing to satisfy the requirement for representational content. However, there are ways to block this conclusion. Suppose that Dretske is right that something is a representation only if, (a) the mechanisms that produce it were in part recruited for producing it because it indicates something and also because (b) it plays a certain role (e.g.) in causing bodily movements.  Note that (a) concerns production and is also most directly relevant to content determination on Dretske's theory.  Note as well that (b) concerns use.  Whether these two requirements are adequate to characterize representational status is debatable.  But the point here is that even if Millikan is right that representational status is determined by use (as it is, in part, on Dretske's proposal) it does not follow that the the production of representations is irrelevant to determining their content (as it is not on Dretske's proposal). On Dretske's proposal, the production of a representation determines its content but something does not count as a representation unless it also has a use-related function. Millikan (2004, ch.6) also argues that no system can have the function to produce states that carry correlational information, even if the correlation need not be one hundred percent reliable. On Millikan's view, although representation producing systems do produce representations that carry a form of natural information when they function properly, they do not have the function to do so. (Recall that, while hearts produce thumping sounds when they are functioning properly, they do not have the function to produce thumping sounds; it is a side effect of their proper functioning.) She points out that it cannot be the function of her visual system to ensure a general correlation between representations of a certain type (e.g., all REDs produced by human visual systems) and contents of a certain type (e.g., all red instantiations). Her visual system, for instance, cannot have the function to ensure that your visual system produces REDs only in the presence of red.  If this objection succeeds, it still leaves open the possibility that an alternative notion of natural information, such as a causal notion, could be used (as discussed in section 3.5). Despite some problems with the detailed articulation of Dretske's indicator semantics, his central insight seems important and appealing. It is plausible that sensory-perceptual systems have the function to produce representations that carry information and that this bears on their content. An alternative attempt to elaborate this insight is sketched later. Millikan (1984) and Papineau (1984) were the first to offer non-informational, “benefit-based” or “consumer-based,” versions of teleological theories of mental content.  Millikan's theory is described in this section and Papineau's in the next.  Millikan's view is richly elaborated in her (1984), her (1989) provides a compressed version, while her (2004, part IV) is somewhere between the two in terms of detail. At least in her earlier work, Millikan's theory of content focussed heavily on the “consumers” of representations, where the consumers of representations are the systems that have historically used the mapping between the representations and their contents to perform their (the consumers') proper functions. In her (1989) Millikan maintains that the production of mental representations is irrelevant to their contents.  She has claimed that attention to the consumers is crucial for solving a certain functional indeterminacy problem, a claim to be discussed in section 4.1. On Millikan's theory, when the relevant representation is used to communicate between creatures, the producer and the consumer of the representation are different creatures. One of Millikan's examples is of a beaver splash: the beaver that splashes its tail is the producer of the representation and the consumers are the nearby beavers that dive for cover, having been warned of danger. In the case of internal representations, it is less clear what counts as the producer and consumer. Millikan sometimes speaks as if they are different sub-systems and sometimes as if they are different time-slices of the same system, before and after the representation is tokened. In either case, a consumer is a system that Normally exploits the mapping between a representation and its represented in the performance of its proper function, where 'Normally' is understood in a teleological and not a statistical sense. Consumers might or might not be cognitive systems; Millikan does not seem to require them to be cognitive systems. Consider the often mentioned case of the frog, which responds to anything appropriately small, dark and moving past its retinas by darting out its tongue. In this case, one relevant consumer of the frog's sensory-perceptual representation might be the frog's digestive system. The performance of its function of feeding the frog depends on and in that sense exploits the mapping between the frog's sensory-perceptual representation and its content, which is (Millikan says) frog food. To find out the content of a representation, says Millikan, we look at the functions of its consumers, which are co-adapted with the producing systems.  If a consumer system has a function then past systems of the type did something adaptive that contributed to the preservation or proliferation of such systems in the population. Ancestral frogs had ancestral digestive systems, for example, and these did things that contributed to the preservation and proliferation of such digestive systems in frogs. It is the explanation of this selection of the consumer system that most nearly concerns the content of the representation, says Millikan. To determine the content of a representation, we consider those past occasions on which consumer systems of the type contributed to selection of that type of system and we ask what mapping between the representation and the world was required for this contribution. According to Millikan, the frog's visual representation represents frog food, since it was only when there was frog food where the frog snapped that the frog was fed and so it was only then that the frog's digestive system contributed to the selection of systems of that type through the use of the representation. Millikan calls that which must have mapped on to the representation in this way the Normal condition for the performance of the proper function of the consumer (in the Normal way).  The Normal condition is the content of the representation. An issue worth considering is whether a multiplicity of consumers (e.g., the frog's motor control system employed in orienting toward the stimulus, the digestive system that digests the food, the circulatory system that circulates the digested nutrients and so on) for a given representation will lead to inappropriate content ambiguity. This will depend on whether different consumers have different Normal conditions for the use of the same representation. If the Normal conditions for the functions of various systems that consume a representation in an individual routinely coincide one might wonder if the Normal conditions for the functions of producing systems will also coincide and, if so, why we need to focus on consumers in particular. This might be one reason why, in later writings, Millikan does not emphasize the consumer's functions over the producer's to the same extent. Some argue that Millikan's theory has advantages in comparison with Dretske's indicator semantics (see e.g., Godfrey-Smith 1989 and Millikan 2004). On Millikan's theory, a representation, R, can represent some environmental feature, C, even if it was never entirely reliable that if there was an R then there was a C. It is enough, on her theory, that Rs mapped on to Cs often enough for the representation's consumers to have (so to speak) benefited from that mapping. There is no need to provide independently specifiable channel conditions or to distinguish between recruitment and post-recruitment environments. It can also be argued that Millikan has solved the problem of distal content for innate as well as learned concepts. Neither retinal images nor light reflected from prey feed a frog. So it can be argued that the Normal condition for the performance of the proper function of the consumer of the frog's perceptual representation is frog food, not light reflected from the prey or retinal images. However, whether Millikan's solution to the problem of distal content survives closer scrutiny is not clear. A solution must exclude inappropriately proximal items, as well as include appropriately distal items. Food is included in the content of the frog's perceptual representation, on Millikan's theory, but the issue is whether the proximal items that carry information about the food to the frog are excluded. Frog food is of no use to a frog if the frog cannot detect it and a frog can only Normally detect its prey if light is reflected from it and an appropriate retinal image results.  So a worry is whether the Normal condition includes the more proximal links in the causal chain as well. Millikan considers a related objection to do with omnipresent beneficial background conditions, the prima facie worry being whether her theory excludes them. To stay with the same example, consider that other things besides frog food were required for a contribution to fitness on past occasions when the frog's perceptual representation was used (e.g., oxygen and gravity). Does her theory entail that the frog's perceptual representation means, not frog food, but something more like frog food in the presence of oxygen and gravity. Millikan excludes such background conditions on the grounds that they do not explain the success of the systems that consume the representation. This entry refers to Millikan's theory as a “benefit-based” theory, since it links content to the benefit to the creatures (or to the consuming systems) that accrues from the use of a representation. That to which a representation refers is not necessarily beneficial; it might instead be its avoidance that is beneficial (e.g., the avoidance of danger, in the case of the beaver splash).  While gravity is beneficial, being tied to Earth by gravity is not a benefit that accrues to frogs due to the use of their prey-representations. The ingestion of nutritional substances, on the other hand, is something that results from the use of the prey-representations. Benefit-based theories need not be consumer-based theories, however, since we could speak of benefits to producing systems or (when the relevant selection is natural selection operating over an evolutionary span of time) to the inclusive fitness of the creature as a whole. One objection to Millikan's Normal conditions is that they are overly specific for plausible contents. Consider the fact that all sorts of circumstances could prevent a contribution to fitness: for example, an infected fly or a crow standing nearby could spell disease or death instead of nutrition for the frog (Hall, 1990). It has been argued that Millikan's theory has the unintended consequence that the frog's representation has the content food that is not infected, when no crow is standing by … etc.. Pietroski (1992) also argues that Millikan's theory provides implausible intentional explanations. His tale of the kimu is intended to press the point.  The kimu are color-blind creatures, until a mutation arises which results in a mechanism that produces a brain state, B, in response to red. Those who inherit this mechanism enjoy the sensation, which leads them to climb to the top of the nearest hill every morning (to see the rising sun or some flowers). The result is that they avoid the dawn-marauding predators, the snorf, who hunt in the valley below and, solely as a result of this, there is selection for the mutation.  As Pietroski wants to describe the case, Bs have the content red (or there is some red) and the kimu enjoy the sight or red and seek out the sight of red things. The point of the story is that Millikan's theory does not allow the story to be told this way. On her theory, the kimu do not see a visual target as red or desire the sight of red, given that it was not the mapping between Bs and red but between Bs and snorf-free-space that was crucial for the fitness of the kimu (and so for the selection of any relevant consumers of the representation). On Millikan's theory, Bs mean snorf-free-space and there is no representation of red in a kimu's brain. Pietroski argues that biting the bullet is radically revisionist in this case. Behavioral tests, he says, could support his claim.  Plant a red flag among a crowd of snorf and the kimu will eagerly join them. It is consistent with his story that contemporary kimu might never have seen a snorf and might be unable to recognise one were it stood smack in front of their faces. Intuitively, we want to say that they might know nothing of snorf, he says. Pietroski suggests that this might be a problem for all teleological theories of content. However, it is more specifically an objection to a benefit-based version (some other teleological theories of content imply that the kimu represent red, see  section 3.5). Millikan (2000, p. 149) agrees that her theory entails that the kimu's B-states represent fewer snorf this way. She argues that we need to distinguish between the properties represented and the properties that cause representations. How else, she asks, could a tortoise think chow this way, given that being nutritious is an invisible property and so could not cause a sensory-perceptual representation? Setting aside what a tortoise really thinks, the worry is how a causal theory of content can allow for the representation of that which lies behind the surface features of objects, or how a causal theory of content can account for natural kind concepts that have hidden or unknown “essences” (e.g., a concept of water, which is necessarily composed of H2O). Price (2001) offers a detailed teleological theory that is similar to Millikan's.  She defends Millikan's interpretation of the mind of the kimu on the ground that it better explains their behavior. She endorses the idea that the point of making content ascriptions is to rationalize behavior and her claim is that a desire to avoid snorf is a better reason to climb to the top of the hill than a desire to watch the sun rise or see red flowers. Several responses are possible. One is that a desire to watch a sunrise is reason enough to climb a hill. Another is that we are left without a rational explanation of why a kimu would be eager to enter snorf-infested space when the snorf are near red, other than that they are psychologically incapable of correctly representing the presence of snorf when snorf are near red. A further possible response is to question whether it is the role of content ascriptions to rationalize behavior (as famously claimed by Davidson (1985) and Dennett (1996)). In relation to this last point, one can ask if some content ascriptions are suitable for some theoretical purposes and others for others. One might agree that folk psychological ascriptions of intentional mental states are meant to rationalize behavior but question whether this is their role in cognitive science. In the latter case, the aim is to explain the psychological capacities of humans and (in the case of cognitive neuroethology) other creatures. Thus a question to ask is what content ascriptions would serve the explanatory purposes of the mind and brain sciences, rather than our folk psychological intuitions.  Neander (2006) and Schulte (forthcoming) argue that benefit-based theories generate the wrong contents for mainstream (information-processing) theories of perception in relation to the simple system cases discussed in the philosophy literature.  A principle of such mainstream theories is is that, in vision, the invisible properties of objects are only represented after the visible surface features of objects are first represented (see, e.g., Palmer 1999).  The worry is that benefit-based theories can entail that it is only the invisible but beneficial property that are represented in perception. Further afield, Shapiro (1992) discusses the role of content ascriptions in foraging theory, which raises a different set of theoretical considerations. Millikan occasionally makes it clear that her theory is intended as a version of an isomorphism theory. According to an isomorphism theory, representation is a matter of mirroring the relations among the elements in the represented domain in the relations among elements in the representing domain.  Since the relevant resemblances are relational, there is no requirement that representations share properties other than abstract relational properties with their representeds. This makes isomorphism theories more plausible than crude resemblance theories. However, this aspect of Millikan's theory is not much developed. (See Shea 2012 for discussion of the role of isomorphism in her theory.) To a large extent, Millikan's theory has been responsible for the great interest, both positive and negative, that philosophers have shown in this general class of theories. Her writings on the topic are extensive and this section has only touched on the basics of her view. A further way in which teleological theories of content can differ is with respect to the contents that they aim to explain. David Papineau's theory, developed at the same time as Millikan's, will help illustrate this point. Papineau (1984, 1987, 1990 and 1993) develops a theory that is top-down, or non-combinatorial, insofar as the representational states to which his theory most directly applies are whole propositional attitudes (e.g., beliefs and desires). In early writings, Millikan sometimes seems to hold a similar view and some objections initially raised against her theory are based on this interpretation of her view (see, e.g., Fodor 1990b, 64–69, where he raises some of the following points). In Papineau's theory, the contents of desires are primary and those of beliefs are secondary in terms of their derivation. According to Papineau, a desire's “real satisfaction condition” is “… that effect which it is the desire's biological purpose to produce” (1993, 58–59), by which he means that “[s]ome past selection mechanism has favored that desire — or, more precisely, the ability to form that type of desire — in virtue of that desire producing that effect” (1993, 59). So desires have the function of causing us, in collaboration with our beliefs, to bring about certain conditions, conditions that enhanced the fitness of people in the past who had these desires. Desires, in general, were selected for causing us to bring about conditions that contributed to our fitness, and particular desires were selected for causing us to bring about particular conditions. These conditions are referred to as their satisfaction conditions and they are the contents of desires. The “real truth condition” of a belief, Papineau tells us, is the condition that must obtain if the desire with which it collaborates in producing an action is to be satisfied by the condition brought about by that action. A desire that has the function of bringing it about that we have food has the content that we have food, since it was selected for bringing it about that we have food, and if this desire collaborates with a belief to cause us to go to the fridge, the content of the belief is that there is food in the fridge if our desire for food would only be satisfied by our doing so if it is true that there is food in the fridge (Papineau's example). This seems to reject the Language of Thought hypothesis, according to which thought employs a combinatorial semantics. Language is combinatorial to the extent that the meaning of a sentence is a function of the meanings of the words in the sentence and their syntactic relations. “Rover attacked Fluff” has a combinatorial meaning if its meaning is a function of the meaning of “Rover”, the meaning of “attacked” and the meaning of “Fluff”, along with their syntactic relations (so that “Rover attacked Fluff” differs in meaning from “Fluff attacked Rover”). According to some philosophers (see esp. Fodor 1975) the content of propositional attitudes is combinatorial in an analogous sense. That is, for instance, the content of a belief is a function of the contents of the component concepts employed in the proposition believed, along with their syntactic relations. A teleological theory of content can be combinatorial, for it can maintain that the content of a representation that expresses a proposition is determined by the separate histories of the representations for the conceptual constituents of the proposition (and, perhaps, by the selection history of the syntactic rules that apply to their syntactic relations). Papineau's theory is not combinatorial, at least for some propositional attitudes.  Instead, the proposal is that the contents of concepts are a function of their role in the beliefs and desires in which they participate. Papineau's theory is a benefit-based theory, and some issues discussed in the previous sub-section are relevant to an assessment of it. For instance, it is unclear that what we desire is always what is beneficial to fitness. One might want sex, not babies or bonding, and yet it might be the babies and the bonding that are crucial for fitness. However, this section will not attempt an overview of the strengths and weaknesses of this theory but will focus on issues peculiar to non-combinatorial accounts. Any non-combinatorial theory must face certain general objections to non-combinatorial theories, such as the objection that it cannot account for the productivity and systematicity of thought (Fodor 1981, 1987). This entry will not rehearse that argument (see the entry on  the language of thought hypothesis)   but special problems for a teleological version of a non-combinatorial theory need to be mentioned. Consider, for example, the desire to dance around a magnolia tree when the stars are bright, while wearing two carrots for horns and two half cabbages for breasts. Probably no-one has wanted to do this. But now suppose that someone does develop this desire (to prove Papineau wrong, say) so that it is desired for the first time. We cannot characterize the situation in this way, according to a non-combinatorial teleological theory.  Since it has never been desired before, it has no history of selection and so no content on its first occurrence, on that style of theory. It is also a problem for this kind of theory that some desires do not or cannot contribute to their own satisfaction (e.g., the desire for rain tomorrow or the desire to be immortal) and that some desires that do contribute to their own satisfaction will not be selected for doing so (e.g., the desire to smoke or to kill one's children). In contrast, teleological theories that are combinatorial have no special problem with novel desires, desires that cannot contribute to bringing about their own satisfaction conditions or desires that have satisfaction conditions that do not enhance fitness, as long as their constitutive concepts have appropriate selection histories or are somehow built up from simpler concepts that have appropriate selection histories. Papineau can respond by agreeing that some concessions to a combinatorial semantics have to be made.  Once some desires and beliefs have content, the concepts involved acquire content from their role in these and they can be used to produce further novel, or self-destructive or causally impotent desires. However, it needs to be shown that such a concession is not ad hoc. The problem is to justify the claim that the desire to blow up a plane with a shoe explosive is combinatorial, whereas the belief that there is food in the fridge is not. In contrast to Papineau's theory, some teleological theories are combinatorial theories. According to these theories, a teleological theory directly accounts for the contents of just the representational simples and combinatorial processes are in addition involved in determining the content of more complex representations. There are two kinds of possible combinatorial processes that might be involved. One operates at the level of a proposition, or at the level of entire map-like or pictorial representations. This type of combinatorial process is thought to play a role that is roughly analogous to the role of a grammar in a spoken language, or a role that is roughly analogous to the principles of map-formation in cartography or pictorial composition in picturing.  For example, it might allow us to combine the concepts CAT, ON and MAT to produce the thought (belief, desire, etc.) that the cat is on the mat. A second kind of combinatorial process that might be involved operates at the level of single concepts and their associated conceptions. Some think that simpler concepts could be combined in conceptions to formulate more sophisticated concepts or to fix the reference of more sophisticated concepts that remain at roughly the grain of the lexemes of a language. Most simply, the concepts MALE, ADULT and NOT MARRIED might be combined to form the concept BACHELOR by means of a definitional conception. Or there might be other types of conceptions involved, such as Wittgensteinian family resemblance conceptions or prototype-style conceptions. Teleological theories can be more or less modest in their scope. A modest theory only aims to directly account for the contents of representational simples.  Dretske (1986), expresses a “modest” view when he gives voice to the hope that more sophisticated representations can be built out of the simple sensory-perceptual representations his theory accommodates. However, there is as yet no clear agreement among philosophers or psychologists as to which the representational simples are. One modest view is that a teleological theory should directly apply to sensory-perceptual and motor representations and to innate concepts only (i.e., those that can be produced without learning). However, even this needs qualifying, since it is controversial which of our concepts are innate. On a radical nativist view, such as that of Fodor (1981), all or almost all of the concepts expressed by the lexical morphemes (the smallest meaningful components) of a language are innate (not learned, only triggered). If that were really so, a theory that aimed to account for the contents of all innate concepts would need to be quite ambitious.  Those who propose genuinely modest teleological theories of content do not hold this view, for they claim that some mental representations that correspond to lexical morphemes are sophisticated, in the sense that they are somehow composed out of or acquired through the use of other representations. Sterelny (1990) describes his teleological theory as “modest” because it only attempts to give an account of innate representations and he assumes these to be a relatively small subset of the complete set of our mental representations.  As for giving an account of the human propositional attitudes, Sterelny maintains that a teleological theory of content will face “appalling difficulties.” He believes that a teleological theory for the representational simples will be part of the complete psycho-semantic theory but not the whole of it. This contrasts with Papineau's theory, which most directly applies to propositional attitudes.  It also contrasts with Millikan's (1984) highly ambitious attempt to directly account, not only for the contents of all mental representations, but also for the meanings of all linguistic utterances via a teleological theory. A modest teleological theory might claim some advantages. Most obviously, unless some concepts can be derived from other concepts, teleological theories would seem to have trouble accounting for empty concepts. For example, no unicorns were ever indicated by UNICORNs, the presence of a unicorn was never a Normal condition for the performance of the proper function of a consumer of UNICORNs, and the desire to find a unicorn has never been satisfied so that the conditions involved in the satisfaction of this desire could not have contributed to selection of the mechanisms that produce desires of the type.  This problem is avoided by a teleological theory that aims to directly account for the contents of just the representational simples, on the assumption that no representational simple expresses an empty concept. (Rey (2010) questions that assumption.) It is sometimes argued that the lack of unicorns as (e.g.) Normal conditions is unproblematic since UNICORN does not refer (to anything actual). Arguably, non-modest theories deliver the correct referential content.  It is a question whether a theory of referential content needs to determine the extension of a concept in all possible worlds. (If the reader's view is that there are no unicorns in any possible worlds because unicorns are essentially fictional, the reader should here substitute another example of an actually empty but possibly non-empty concept, such as a concept of phlogiston or of entelechies.) Some theories of referential content do and some do not take on this task. The greatest challenge to those offering modest theories will be to explain how complex concepts can be composed out of or derived from simpler concepts. It might fairly be said that it is not the task of a fundamental theory of mental content per se to explain how complex concepts can be composed out of simpler ones, but it is a problem for modest theories if no such explanation is available. Moreover, providing such an explanation is generally thought to be problematic. Some say that “modest” theories have some seriously immodest consequences. One is alleged to be that there must be a principled analytic/synthetic distinction.  See, for instance, Fodor and Lepore (1992), who argue that we must choose between three options: defending a principled analytic/synthetic distinction, accepting meaning holism or accepting that virtually no concepts of roughly the grain of the lexemes of a language are composed out of simpler concepts. They further argue that the first two options are not viable.  However, some psychologists maintain that we must somehow “bootstrap” up from simple to sophisticated concepts (see e.g., Carey (2009)). And some philosophers are anyway unconvinced by Fodor and Lepore's arguments.  (Readers who would like to read more on concepts and conceptions might start with the introduction to and readings in Margolis and Laurence (1999) and the entries in this encyclopedia on concepts and on the analytic-synthetic distinction.) To round out this survey of views, we return to informational theories, to look at some more recent work that is broadly in the tradition of Stampe and Dretske. These theories take seriously the idea that mental representations have informational functions. First, a response is offered to an argument that is intended to block all informational versions of teleosemantics.  This argument is that, because functions are selected effects, any appeal to representational functions must be an appeal to the effects of representations and not their causes (Millikan (1989b, 85), Papineau (1998, 3)). One response is to accept this argument's conclusion but to maintains that an additional informational requirement can nonetheless be added to an appeal to functions; teleological theories of mental content can appeal to other things besides functions (Shea, 2007). An alternative response rejects the argument. Neander (2012) claims that sensory-perceptual systems have what she calls “response functions,” where to respond to something is to be caused by it to do something else. For example, a visual system might be caused by a red instantiation to change into a RED state, and it might have been selected (in part) for being disposed to change into a RED state in response to red and have the function to do so. On Neander's view, these state changes represent the causes to which the system is supposed to respond by producing the representation in question.  They are, so to speak, the Normal causes of the producer of the representation, rather than the Normal conditions for the performance of the proper function of the representation's consumer. On this view, RED has the content red if the visual system that produces it has the function to produce it in response to red, or more specifically in response to red being instanced in the receptive field of the perceptual processing pathways responsible for the RED's production. This is the basic idea though further complications are added.  One is intended to solve the problem of distal content as follows: The second requirement is intended to determine appropriately distal content and is to be applied only after the first requirement is applied. The first requirement on its own does not determine suitably distal content because there is a causal chain leading from C to R and, if the system had been selected for responding to Cs by producing Rs, it must also have been selected for responding to the proximal items in the causal chain (such as the light reflected from Cs toward the retina of the eye, in the case of visual perception). These more proximal items in the causal chain carry information about C to the system and through the system to the R.  There is, however, an asymmetry, to which the second requirement appeals.  The system was selected for its disposition to respond to the proximal items because by that means it responded to the more distal items, but the system was not selected for responding to the more distal item because by that means it responded to the more proximal items. (It does not respond to the more proximal items by means of its responding to the more distal items; that is not how the means-end analysis pans out). On this causal theory, a sensory-perceptual system need not have produced Rs only in the presence of Cs during selection of the system.  There is no need to specify channel conditions or conditions in which representation is reliable. This is not a type-1 teleological theory of content. The idea that representations are reliably caused by or correlated with their contents in some conditions does not figure in the proposal. The first requirement ensures different content ascriptions to those generated by benefit-based teleological theories. For example, consider again the kimu (see section 3.2).  As stipulated by Pietrosky, it is the presence of red and not the absence of snorf that causes the relevant mechanism in a kimu to produce a B-state. Mechanisms of the type were not selected for a disposition to be caused by an absence of snorf to produce B-states.  They had no such disposition, so they could not have been selected for it. The relevant mechanisms in the kimu were selected for a disposition to be caused by red to produce a B-state, as well as for further causing certain movements (hill climbing of a morning) thereby. They were selected for this because red correlated well enough with snorflessness in the kimu's habitat. However, on this proposal, that further fact becomes a background evolutionary fact that is not content constitutive. The candidate content fewer snorf this way fails to pass the first requirement. Consider too the notorious case of the frog. Plausibly, the relevant visual pathways in the frog's brain were selected for their disposition to be caused by a certain configuration of visible features (roughly, something's being small, dark and moving) to produce the sensory-perceptual representation in question, as well as for their disposition to initiate orienting and so on thereby.  They were plausibly selected for this preferential response to the configuration of visible features because things with these features were often enough nutritious for the frog. The visual pathways in the frog were not selected for a disposition to respond to the nutritional value of a stimulus, however. For the normal frog's visual system has no causal sensitivity to the nutritional value of the stimulus and cannot have been selected for a causal sensitivity it did not have. So, on this proposal, the visual content of the representation is something small, dark, moving (or something along these lines) rather than frog food. According to Neander (2006) the configuration of visible features is the right style of visual content to ascribe for the purpose of mainstream scientific explanations of an anuran's visual capacities. Nor does this proposal seem to generate overly specific contents of the kind mentioned earlier in relation to benefit-based theories.  On this informational theory, the frog does not represent the stimulus as not carrying an infectious disease, even if only those small, dark and moving things that were not carrying an infectious disease contributed to frog fitness when the frog was fed. Sensory-perceptual systems can only have been selected for causal dispositions which past systems of the type possessed. Since past systems had no disposition to respond preferentially to the absence of an infectious disease in visual stimuli that were small, dark and moving, the fact that contributions to fitness were made only on those occasions when an infectious disease was absent is, again, a background evolutionary fact that is not content-constitutive on this proposal. One possible concern is whether sufficient room for misrepresentation has been made. Some early discussions of teleological theories of content assumed that the content of the frog's representation must be frog food or fly or else misrepresentation would be impossible.  The frog would not be in error when it snapped at something small, dark and moving that was not frog food, or not a fly.  However, misrepresentation is possible on this proposal.  A representation that is supposed to be produced in response to something that is small, dark and moving and is instead produced in response to something large and looming would count as misrepresenting and a neurologically damaged frog (e.g., one with a damaged thalamus) will indeed attempt to catch all sorts of inappropriate things (e.g., an experimenter's hand or even the frog's own limbs). This informational theory also entails that a kimu's B-state will misrepresent if it is tokened in response to anything that is not red. More importantly, perhaps, it seems to entail that human REDs will misrepresent if tokened at something not-red, as could happen in red-green color blindness, in color contrast illusions or in unusual viewing conditions. As Millikan (2012) and others have pointed out, there are representations that cannot be caused by their contents, such as TOMORROW. No tomorrow has ever caused a thought about tomorrow. However, TOMORROW is not a sensory-perceptual representation and so this is not an objection to this proposal per se.  As with other modest theories, however, the challenge is explaining how to link this modest theory for some mental contents to a more comprehensive theory that accounts for all of the contents of all of our concepts (see section section 3.4).