 Because eliminative materialism is grounded in the claim that common sense psychology is radically false, arguments for eliminativism are generally arguments against the tenability of folk psychology. These arguments typically fall into one of two major families. One family involves arguments stemming from a broad range of considerations that pertain to the assessment of theories in general. The second family focuses upon deficiencies that are unique to folk psychology and its central posits. Patricia and Paul Churchland have offered a number of arguments based on general considerations about theory evaluation. For example, they have argued that any promising and accurate theory should offer a fertile research program with considerable explanatory power. They note, however, that common-sense psychology appears to be stagnant, and there is a broad range of mental phenomena that folk psychology does not allow us to explain. Questions about why we dream, various aspects of mental illness, consciousness, memory and learning are completely ignored by folk psychology. According to the Churchlands, these considerations indicate that folk psychology may be in much worse shape than we commonly recognize (P. M. Churchland, 1981; P.S. Churchland, 1986). Another argument that appeals to general theoretical considerations offers an inductive inference based on the past record of folk theories. Folk physics, folk biology, folk epidemiology and the like all proved to be radically mistaken. Since folk theories generally turn out to be mistaken, it seems quite improbable that folk psychology will turn out true. Indeed, since folk psychology concerns a subject that is far more complex and difficult than any past folk theory, it seems wildly implausible that this one time we actually got things right (Churchland, P.M. 1981). These general theoretical arguments do not seem to have significantly undermined the intuitive support that folk psychology enjoys. In response to the charge that folk psychology is stagnant, many have argued that this assessment is unfair, and that folk psychology has actually stimulated a number of fruitful research programs in scientific psychology (Greenwood, 1991; Horgan and Woodward, 1985). Moreover, defenders of folk psychology note that it hardly follows from the observation that a given theory is incomplete, or fails to explain everything, that it is therefore radically false (Horgan and Woodward, 1985). Defenders of folk psychology object that these theoretical considerations cannot outweigh the evidence provided by everyday, ordinary experience of our own minds, such as our introspective experience, which seems to vividly support the reality of mental states like beliefs. Regarding this last point, eliminativists like the Churchlands warn that we should be deeply suspicious about the reliability of introspective “evidence” about the inner workings of the mind. If inner observation is as theory-laden as many now suppose outer perception to be, what we introspect may be largely determined by our folk psychological framework. In other words, “introspecting” beliefs may be just like people “seeing” demonic spirits or celestial spheres (Churchland, P.M., 1988). This skepticism about the reliability of introspection is bolstered by empirical work that calls into question the reliability of introspection (Nisbett and Wilson, 1977). As we will see in Section 3.3, the idea that introspection offers an illusory image of the mind is gaining popularity not just with regard to information bearing states like beliefs, but also with regard to phenomenal states like qualia. The second family of eliminative materialist arguments focuses upon idiosyncratic features of folk-psychological posits and ultimately denies that these features will be accommodated by a scientific account of the mind. The most widely discussed features are two associated with the apparent linguistic nature of beliefs and other propositional attitudes. First, as a number of philosophers have recently noted, propositional attitudes appear to have a form similar to public language sentences, with a compositional structure and syntax. For example, a person’s belief that, say, the president dislikes terrorists appears to be composed of the concepts “THE PRESIDENT”, “DISLIKES”, and “TERRORISTS”, and differs from the belief that terrorists dislike the president by virtue of something analogous to syntactic arrangement. Second, beliefs resemble public sentences in that they have semantic properties. Beliefs, like public linguistic representations, are about different states of affairs. Both of these quasi-linguistic features of propositional attitudes—their alleged sentential structure and their semantic (or intentional) properties—have been used by philosophers to mount arguments for eliminativism. Some writers have emphasized the apparent mismatch between the sentential structure of propositional attitudes on the one hand, and the actual neurological structures of the brain on the other hand. Whereas the former involves discrete symbols and a combinatorial syntax, the latter involves action potentials, spiking frequencies and spreading activation. As Patricia Churchland (1986) has argued, it is hard to see where in the brain we are going to find anything that even remotely resembles the sentence-like structure that appears to be essential to beliefs and other propositional attitudes. In response to this line of reasoning, many have argued that it is mistake to treat folk psychology as committed to a quasi-linguistic structure to propositional attitudes (Horgan and Graham, 1991; Dennett, 1991). And even for those who find this reading of folk psychology plausible, there is a further difficulty regarding the relevance of neuroscience for determining the status of folk psychology. Some, such as Zenon Pylyshyn (1984), have insisted that just as the physical circuitry of a computer is the wrong level of analysis to look for computational symbol structures, so too, the detailed neurological wiring of the brain is the wrong level of organization to look for structures that might qualify as beliefs. Instead, if we view the mind as the brain’s program, as many advocates of classical AI do, then folk posits exist at a level of analysis that is more abstract than the neuro-physical details. Consequently, many realists about the posits of folk psychology discount the importance of any apparent mis-match between neurological architecture and the alleged linguistic form of propositional attitudes (Fodor & Pylyshyn, 1988; McLaughlin & Warfield, 1994). The second type of argument against beliefs focuses upon their semantic properties and concludes that these sorts of properties make propositional attitudes ill-suited for even a computational theory of the mind. Stephen Stich (1983) has emphasized that folk psychology individuates beliefs by virtue of their semantic properties, e.g., we taxonomize states like beliefs by virtue of what they are about. However, according to Stich, there are a host of reasons for rejecting a semantic taxonomy for scientific psychology. Semantic taxonomies ignore causally salient aspects of cognitive states, involve a high degree of vagueness, and break down in the case of the mentally ill or the very young. In place of the semantic individuation method adopted by folk psychology, Stich argues for a syntactic taxonomy that is based upon the causally relevant syntactic or physical properties of a given cognitive state. Yet, as Stich himself notes, even if it should turn out that folk posits do not belong in a scientific psychology, more is needed to establish that they do not actually exist. After all, we do not doubt the existence of several sorts of things (e.g., chairs, articles of clothing) that are defined in ways that make them ill-suited for science. Thus, Stich’s account is not truly eliminativist for the reasons we saw in Section 2.3: his prescription is for a scientifically superior taxonomy that still involves belief-like states. Moreover, if our best scientific account posited states that share many features with beliefs, such as similar causal roles, then even if the two taxonomies pulled apart in certain cases, we may still regard folk psychology as, in some sense, vindicated. While the scientific taxonomy may not list beliefs as basic cognitive states, it could conceivably still provide the resources for developing a realist interpretation of these and other folk psychological states. One way to get a stronger eliminativist conclusion would be to argue that there is nothing posited in a scientific account of cognition that shares the central properties we attribute to folk psychological states, at any level of analysis. For example, Ramsey, Stich and Garon (1990) have argued that if certain  connectionist  models of memory and inference prove successful, then this would form the basis for eliminative materialism regarding states like propositional memories. Since some connectionist models store information in a highly distributed manner, there are no causally discrete, semantically evaluable data structures that represent specific propositions. It is not just that these models lack the sort of sentential, compositional representations assumed in more traditional (or “language of thought”) models. Rather, it is that in these networks there are no causally distinct structures that stand for specific states of affairs. Consequently, there do not appear to be any structures in these networks that might serve as candidates for beliefs and other propositional attitudes. This is noteworthy since many critics of eliminativism claim it is virtually impossible to imagine what a psychological theory would look like that doesn’t invoke propositional attitudes to explain cognition (Hannan, 1993). If Ramsey, Stich and Garon are right, certain connectionist models may, for the first time, provide us with a plausible account of cognition that supports the denial of belief-like states. More recently, Ramsey (2007) has argued that this earlier argument does not go far enough, insisting that connectionist models of this sort not only fail to invoke inner representations that are sufficiently similar to the posits of folk psychology, but that they don’t actually invoke inner representational states at all. Ramsey, Stich and Garon’s argument assumes that in highly distributed networks, it is impossible to specify the semantic content of elements of the network that are causally responsible for various cognitive episodes. Some have responded to their argument by suggesting that, with highly sophisticated forms of analysis, it actually is possible to pick out causally relevant pieces of stored information (Forster and Saidel, 1994). Others have argued that, like the Churchlands, Ramsey, Stich and Garon have offered a mistaken interpretation of folk psychology, suggesting it requires far less in the way of explicit, discrete structures than they suggest (Dennett, 1991; Heil, 1991). This is a common criticism of eliminative materialism, and we will look at it more closely in Section 4.3. Another development in cognitive science that has pushed some people in the direction of eliminativism is the attempt to understand cognitive systems as neither classical nor connectionist computational devices, but rather as dynamic systems, described using the mathematical framework of dynamic systems theory (Beer, 2000; van Gelder, 1992; Port and van Gelder, 1995). This approach is often conjoined with some version of embodied cognition, as both place a strong emphasis on the way cognitive agents move about and interact with their environment. While neither the dynamic nor the embodied approaches are inherently anti-representational in nature, at least some authors have employed them to develop accounts of cognitive processes that abandon inner representational states altogether. For example, Anthony Chemero has promoted what he calls “radical embodied cognitive science” (Chemero, 2009). This theoretical framework treats the cognitive agent and environment as a complex coupled system best explained by a mix of dynamics and James Gibson’s ecological theory of perception (Gibson, 1950). Chemero explicitly endorses eliminativism by rejecting the traditional assumption that agents solve problems and navigate through the world by consulting mental representations. He thus joins others in the cognitive science community, like artificial intelligence researcher Rodney Brooks (Brooks, 1991), who have tried to account for cognition without invoking representational entities. Of course, it is too early to know how successful these non-representational approaches will ultimately be, and many defenders of representationalism argue that these efforts are not likely to account for more sophisticated “representation-hungry” tasks like planning (Clark and Toribio, 1994). A related theoretical development in the philosophy of cognitive science that also pushes a strong anti-representational perspective, at least for basic cognitive states, and that has its roots in the embodied, embedded tradition is radical enactivism. Authors like Daniel Hutto and Erik Myin reject the traditional information-processing outlook and insist that whey they call the “hard problem of content”— the problem of providing a naturalistic account of the semantic properties of representational content (as opposed to mere co-variation) — is probably unsolvable for most inner states commonly thought as mental representations (Hutto and Myin, 2012). Thus, Hutto and Myin join other authors who have endorsed eliminativism about mental representations by focusing upon the problematic nature of content. Although most discussions regarding eliminativism focus on the status of our notion of belief and other propositional attitudes, some philosophers have endorsed eliminativist claims about the phenomenal or qualitative states of the mind (see the entry on  qualia).  For example, Daniel Dennett (1978) has argued that our concept of  pain  is fundamentally flawed because it includes essential properties, like infallibility and intrinsic awfulness, that cannot co-exist in light of a well-documented phenomenon know as “reactive disassociation”. In certain conditions, drugs like morphine cause subjects to report that they are experiencing excruciating pain, but that it is not unpleasant. It seems we are either wrong to think that people cannot be mistaken about being in pain (wrong about infallibility), or pain needn’t be inherently awful (wrong about intrinsic awfulness). Dennett suggests that part of the reason we may have difficulty replicating pain in computational systems is because our concept is so defective that it picks out nothing real. A similar view about pain has been offered by Valerie Hardcastle (1999). Hardcastle argues that the neurological basis for pain sensations is so complex that no one thing answers to our folk conception. However, despite her own characterication of pain as a “myth”, Hardcastle’s arguments appear to be aimed not at showing that pain is unreal, but rather that it is actually a more complicated phenomenon than suggested by our folk conception. In another well-known article, “Quining Qualia” (1988), Dennett challenges not just our conception of pain, but all of our different notions of qualitative states. His argument focuses on the apparently essential features of qualia, including their inherent subjectivity and their private nature. Dennett discusses several cases—both actual and imaginary—to expose ways in which these ordinary intuitions about qualia pull apart. In so doing, Dennett suggests our qualia concepts are fundamentally confused and fail to correspond with the actual inner workings of our cognitive system. Some writers have suggested an eliminativist outlook not just with regard to particular states of consciousness, but with regard to phenomenal consciousness itself. For example, Georges Rey (1983, 1988) has argued that if we look at the various neurological or cognitive theories of what consciousness might amount to, such as internal monitoring or the possession of second-order representational states, it seems easy to imagine all of these features incorporated in a computational device that lacks anything we intuitively think of as “real” or robust consciousness. Rey suggests that the failure of these accounts to capture our ordinary notion of consciousness may be because the latter corresponds with no actual process or phenomenon; the “inner light” we associate with consciousness may be nothing more than a remnant of misguided Cartesian intuitions (see also Wilkes, 1988; 1995 and Irvine and Sprevak, forthcoming). A somewhat similar outlook has been proposed by Keith Frankish and others, and is commonly referred to as “Illusionism” about consciousness, a label designed to help indicate why it seems to us that phenomenal consciousness is real (Frankish, 2016, 2017). Illusionism is motivated in part by broader theoretical considerations, such as the problematic nature of consciousness from the standpoint of physicalism and the observation that even reductive accounts of phenomenal experience typically suggest some sort of misapprehension of what is really going on. Illusionism claims that introspection involves something analogous to ordinary sensory illusions; just as our perceptual systems can yield states that radically misrepresent the nature of the outer world, so too, introspection yields representations that substantially misrepresent the actual nature of our inner experience. In particular, introspection represents experiential states as having phenomenal properties—the infamous and deeply problematic what-it-is-likeness of our qualitative mental states. Illusionists claim that these phenomenal properties do not exist, making them eliminativists about phenomenal consciousness. What is real are quasi-phenomenal properties—the non-phenomenal properties of inner states that are detected by introspection and misrepresented as phenomenal. An obvious challenge for such a view is explaining how we can experience something as having feature X without such as experience actually involving the real experience of X. It could be argued that even if the what-it-is-likeness is a feature of how we introspectively represent certain mental states, it would nevertheless be a real aspect of introspection—a feature that is perhaps relocated, but not removed. Famously, the illusion/reality gap seems to collapse when it comes to our inner experiences; as Searle puts it, “where conscoiusness is concerned the existence of the appearance is the reality” (Searle, 1997, p.122, italics in original). Frankish insists that we can introspectively represent ourselves as having a certain type of experience without actually having that type of experience: “...when we think we are having a greenish experience we are in fact merely misrepresenting ourselves as having one” (Frankish, 2016, p. 33). Illusionism thereby forces us to reconsider the sort of access we have to our own experiential states.