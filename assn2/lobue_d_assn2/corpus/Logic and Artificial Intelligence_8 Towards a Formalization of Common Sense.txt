 John McCarthy’s explicit long-term goal—the formalization of common sense knowledge—has been adopted and pursued by a relatively small, but active, subcommunity of AI researchers.  A larger group (those involved in knowledge representation, cognitive robotics, and qualitative physics) can be considered to work on specialized projects that support the larger goal.  Anything like a formalization of common sense is so far from being accomplished that—if it is achievable at all—it is not even possible to estimate when we could expect the task to be completed.  However, since 2001 (the date of a symposium on common sense reasoning held at The Courant Institute—see  The Common Sense 2001 Homepage) something like a cooperative, sustained effort in this direction has begun to emerge.  This effort is yielding a better sense of how to develop a workable methodology for formalizing common sense, and of how to divide the larger problem up into more manageable parts.  Many of the papers presented at this conference were presented in expanded form in 2004 in an issue of Artificial Intelligence.  The introduction to this issue,  Davis & Morgenstern 2004, provides a useful survey and appreciation of the general research area. This cooperative formalization effort (1) seeks to account for many areas of knowledge, and at the same time (2) attempts to see how this formalized knowledge can be brought to bear on moderately complex common-sense reasoning problems.  The first book-length treatment of this topic, Davis 1991, divides the general problem into the following subtopics. Several of these topics overlap with concerns of the qualitative physics and qualitative reasoning community.  Although it can be hard to tell where common sense ends and physics begins, the formalization of common sense reasoning can be seen as a more general formalization project that can draw on a tradition in qualitative physics that has gone through many years of development and by now is fairly   mature.[39] And a few of them overlap with the work on the formalization of planning that was described above in Section 4.  Minds and society, however, are new and different topics; the former has to do with common sense psychology and its application in introspective and interpersonal reasoning, and the latter, of course, should have to do with social and political knowledge and reasoning, but this is the least-developed area of formalized common sense knowledge: the chapter on this topic in Davis 1991 is very brief, and discusses mutual attitudes and communication.  More recently, Andrew S. Gordon and Jerry Hobbs have undertaken a large-scale, ambitious formalization of common-sense psychology.  See, for instance,   Hobbs & Gordon 2005. A more recent book-length treatment of the formalization of common sense,   Mueller, 2006, follows a similar pattern.  More than half of the book is devoted to reasoning about actions and change.  There are short chapters on space and mental states, and a longer treatment of default reasoning.  Although logical techniques and formalization methods take center stage in this book, it also contains material on nonlogical methods and on implementations related to the  formalizations. Even when attempted on a moderate scale, the formalization of common sense knowledge puts considerable pressure on the resources of even the most powerful logical systems that were devised for the formalization of mathematics.  As we tried to show in discussing the special case of action and planning in Section 4, this pressure may lead us to seek logics that can facilitate the formalization projects: for instance, nonmonotomic logics and logics that explicitly represent context. When larger-scale formalizations are attempted, other challenges arise that are similar to those that software engineering tries to address.  Even fairly small programs and systems of axioms are difficult to comprehend and can be highly unpredicable, yielding unexpected consequences and unanticipated interactions.  The creation and use of larger programs and formalizations raises questions of how to enable teams of developers to produce coherent results when modules are integrated, how to maintain and test large systems, and how to use knowledge sources such as dictionaries and knowledge bases to automatically generate axioms. You can think of the philosophical methodology of providing analyses as a collection of attempts to formalize or partially formalize various common sense notions.  These attempts are far smaller in scale, less systematic, and more heterogeneous than the parallel effort that is emerging in AI.  Philosophers have never chosen a specific domain comparable to the planning domain and mounted a sustained attempt to formalize it, along with a companion effort to develop appropriate logics.  And no matter how complex the notions with which they which they are concerned, philosophers have never allowed their analyses to grow to the complexity where  methodological issues arise similar to those that apply to the development and maintenance of large software systems. The techniques emerging in AI are of great potential significance for philosophy because it is easy to suspect that many philosophically important phenomena have the sort of complexity that can only be dealt with by accepting the problems that go along with developing complex formalizations.  Limitations of the philosophical methods that were used throughout the twentieth century and are still in use may make it impossible to produce theories that do justice to the subject matter. It would therefore be a great mistake for philosophers to disparage and ignore the large-scale formalizations that are beginning to emerge in AI because these efforts begin to raise engineering issues.  It may well be that, although philosophy requires us to address complex phenomena in a rigorous way, the traditional philosophical methods are capable of doing justice to the complexity.  Methods that promise to do this are worth taking seriously. Among other methods borrowed from computer science,  the common sense reasoning community has sought to develop  suites of “benchmark problems”.  The idea is to publicize problems that are difficult but not impossibly difficult, to encourage the community to create solutions, and compare the solutions. Probably the best-studied problem to date is Ernest Davis’ “egg-cracking problem.”  This is formulated as follows on the Common Sense Reasoning Problem webpage. Along with the problem itself  three solutions are posted:  Shanahan 2004,   Lifschitz 1998b,  and a version of   Morgenstern 2001.  Comparing the solutions is instructive: similarities outweigh differences.  All the authors think of this as a planning problem, and use a versions of the Situation Calculus or the Event Calculus in the formalization. Each axiomatization is modular, with, for instance, separate modules devoted to the relevant geometrical and material properties.  Each author provides a “proof of concept” for the formalization by showing that the axioms support a proof of the correctness of a plan to crack the egg in the simple case.  None of the authors considers all of Davis’ elaborations of the problem, but the axioms are framed with elaboration in mind and some elaborations are considered.  It isn’t clear whether any of the authors actually implemented the formalization (for instance, using a theorem prover). The egg-cracking case raises the problem of how to evaluate moderately large formalizations of common sense problems. Morgenstern and Shanahan express this issue explicitly.  Morgenstern suggests that the important criteria are (1) Epistemological adequacy (correspondence to intuitive reasoning, as experienced by people who engage in it), (2) Faithfulness to the real world, (3) Reusability, and (4) Elaboration tolerance.  It isn’t clear whether the first two of these criteria are too subjective to be useful.  To these, Shanahan adds (5) Usability, which probably is presupposed by Morgenstern’s third criterion. There is anecdotal evidence that the larger AI community is somewhat skeptical about such research projects—or, if not skeptical, at least puzzled about how to evaluate them.  In considering these doubts, it is necessary to appreciate the complexity of these formalization problems, and the preliminary and tentative status of the research program.  Nevertheless, this criticism has some legitimacy, the common sense reasoning community is sensitive to these criticisms, and is working to develop and refine the methods and criteria for evaluating this work. As long as formalization problems remain relatively simple, we can treat formalization as an art rather than as a discipline with a well-articulated methodology.  But the trends we’ve been discussing show that formalization of even moderate-sized realistic common sense reasoning problems is not merely an art.  Just as programming systems, expert systems and knowledge bases have created corresponding software engineering disciplines, large-scale formalization projects require a carefully thought through and tested methodology.