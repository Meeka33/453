 Epistemic logic is another area in which logic in computer science have been influenced by philosophical logic. The classical source for epistemic logic is  Hintikka 1962,  in which Jaakko Hintikka showed that a modal approach to single-agent epistemic attitudes could be informative and rewarding. This work discusses at length the question of exactly which constraints are appropriate for knowledge and belief, when these attitudes are viewed as explicated by a model theoretic relation over possible worlds; in both cases, Hintikka argues for S4 type operators. In several papers (including  McCarthy 1979),  John McCarthy has recommended an approach to formalizing knowledge that uses first-order logic, but that quantifies explicitly over such things as individual concepts. In this section, we discuss the approach taken by most computer scientists, who, unlike McCarthy, use a modal language to formalize propositional attitudes. The logical aspects of modal epistemic logic were not significantly developed after Hintikka’s 1962 presentation; instead, the philosophical literature (which is not extensive, compared with many other topics in the area) concentrates on the issue of hyperintensionality, or closure of epistemic attitudes under logical consequence. This topic is especially challenging, turning out to be closely related to the semantic paradoxes, and the philosophical literature is inconclusive. Intuitions seem to conflict, and it is difficult to find ways to model the important phenomena using logical techniques.[35] Fagin et al. 1984  begins a tradition in computational logic that revives the modal approach to epistemic logic, developing generalized logical foundations and applications that had not occurred to the philosophers. The technical idea is to simplify the modality, using S5 (or deontic S5 for belief), but to introduce multiple agents, and to concentrate on reasoning having to do with agents’ attitudes about one another’s attitudes. Such logics have direct applications in the analysis of distributed systems, dynamic systems in which change is effected by message actions, which change the knowledge of agents according to rules determined by a communications protocol. As such, this work belongs to a separate area of computer science, but one that overlaps to some extent with AI. Later, this work has interacted with a research tradition in economics that is concerned with the role of knowledge in games and bargaining; see, for  instance,  Geanakopolos 1994;  Osborne & Rubenstein 1994 [Chapter 5]. For some reason, the multi-agent case did not occur to philosophical logicians.[36]  This is another example of the way in which need for an application (in this case, the need for a theory of distributed systems) provided the inspiration for an important logical development. The logical details are extensively and systematically  recorded in  Fagin et al. 1995;  this is essential reading for anyone seriously interested in this topic. Much of the interdisciplinary work in applications of the logic of knowledge is reported in the proceedings of a series of conferences initiated in 1986 with  Halpern 1986.  These conferences record one of the most successful collaborations of philosophers with logicians in Computer Science, although the group of involved philosophers has been relatively small. The focus of the conferences has gradually shifted from Computer Science to Economics. AI applications deal with with knowledge in the form of stored representations, and the tradition in AI with which we are concerned here thinks of reasoning as the manipulation of symbolic representations. Also, it is mainly due to AI that the problem of limited rationality has become a topic of serious interest, providing a counterbalance to the idealizations of philosophy and economics.[37]  So you would think that a logical model of propositional attitudes that is committed to closure under logical consequence would be highly unpopular in AI. But this is not so; the possible worlds approach to attitudes is not only the leading theory in the areas discussed in  Fagin et al. 1995,  but has even been advocated in robotics applications; see  Rosenschein & Kaelbling 1995;  Rosenschein 1989.  Nevertheless, the issue of hyperintensionality has been investigated in the AI literature; see  Perlis 1985;  Konolige 1986;  Lakemeyer 1997;  Levesque 1984).  Though there are some new positive results here, the AI work in this area has, for the most part, been as inconclusive as that in philosophy. The philosophical literature on a related topic, the logic of perception, has not been extensive; the main reference is  Hintikka 1970.[38]  But sensation is addressed in recent work in the AI literature which is concerned with developing logical frameworks for general-purpose applications in robotics. The main idea in this area is to add sensing actions to the repertoire of a planning formalism of the sort discussed in  Section 4.  The earliest work in this area was carried out in the 1980s by Robert Moore; see  Moore 1995b;  Moore 1985.  For some of the contemporary work in cognitive robotics, see  Baral et al. 2000,  Bacchus et al. 1999,  Golden & Weld, 1996,  Pirri & Finzi 1999,  and  Thielscher 2000.