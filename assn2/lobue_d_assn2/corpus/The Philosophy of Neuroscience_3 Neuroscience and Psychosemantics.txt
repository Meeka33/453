 Developing and defending theories of content is a central topic in contemporary philosophy of mind. A common desideratum in this debate is a theory of cognitive representation consistent with a physical or naturalistic ontology. We’ll here describe a few contributions neurophilosophers have made to this project. When one perceives or remembers that he is out of coffee, his brain state possesses intentionality or “aboutness”. The percept or memory is about one’s being out of coffee; it represents one as being out of coffee. The representational state has content. A psychosemantics seeks to explain what it is for a representational state to be about something, to provide an account of how states and events can have specific representational content. A physicalist psychosemantics seeks to do this using resources of the physical sciences exclusively. Neurophilosophers have contributed to two types of physicalist psychosemantics: the Functional Role approach and the Informational approach. For a description of these and other theories of mental content, see the entries on  causal theories of mental content,  mental representation, and  teleological theories of mental content. The core claim of a functional role semantics is that a representation has its specific content in virtue of relations it bears to other representations. Its paradigm application is to concepts of truth-functional logic, like the conjunctive “and” or disjunctive “or”. A physical event instantiates the “and” function just in case it maps two true inputs onto a single true output. Thus it is the relations an expression bears to others that give it the semantic content of “and”. Proponents of functional role semantics propose similar analyses for the content of all representations (Block 1995). A physical event represents birds, for example, if it bears the right relations to events representing feathers and others representing beaks. By contrast, informational semantics ascribe content to a state depending upon the causal relations obtaining between the state and the object it represents. A physical state represents birds, for example, just in case an appropriate causal relation obtains between it and birds. At the heart of informational semantics is a causal account of information (Dretske 1981, 1988). Red spots on a face carry the information that one has measles because the red spots are caused by the measles virus. A common criticism of informational semantics holds that mere causal covariation is insufficient for representation, since information (in the causal sense) is by definition always veridical while representations can misrepresent. A popular solution to this challenge invokes a teleological analysis of “function”. A brain state represents X by virtue of having the function of carrying information about being caused by X (Dretske 1988). These two approaches do not exhaust the popular options for a psychosemantics, but are the ones to which neurophilosophers have most contributed. Paul Churchland’s allegiance to functional role semantics goes back to his earliest views about the semantics of terms in a language. In his (1979) book, he insisted that the semantic identity (content) of a term derives from its place in the network of sentences of the entire language. The functional economies envisioned by early functional role semanticists were networks with nodes corresponding to the objects and properties denoted by expressions in a language. Thus one node, appropriately connected, might represent birds, another feathers, and another beaks. Activation of one of these would tend to spread activation to the others. As “connectionist” neural network modeling developed (as discussed in the previous section above), alternatives arose to this one-representation-per-node “localist” approach. By the time Churchland (1989) provided a neuroscientific elaboration of functional role semantics for cognitive representations generally, he too had abandoned the “localist” interpretation. Instead, he offered a “state-space semantics”. We saw in the previous section how (vector) state spaces provide an interpretation for activity patterns in neural networks, both biological and artificial. A state-space semantics for cognitive representations is a species of a functional role semantics because the individuation of a particular state depends upon the relations obtaining between it and other states. A representation is a point in an appropriate state space, and points (or subvolumes) in a space are individuated by their relations to other points (locations, geometrical proximity). Paul Churchland (1989, 1995) illustrated a state-space semantics for neural states by appealing to sensory systems. One popular theory in sensory neuroscience of how the brain codes for sensory qualities (like color) is the opponent process account (Hardin 1988). Churchland (1995) describes a three-dimensional activation vector state-space in which every color perceivable by humans is represented as a point (or subvolume). Each dimension corresponds to activity rates in one of three classes of photoreceptors present in the human retina and their efferent paths: the red-green opponent pathway, yellow-blue opponent pathway, and black-white (contrast) opponent pathway. Photons striking the retina are transduced by photoreceptors, producing an activity rate in each of the segregated pathways. A represented color is hence a triplet of neuronal activation frequency rates. As an illustration, consider again  Figure 3.  Each dimension in that three-dimensional space will represent average frequency of action potentials in the axons of one class of ganglion cells projecting out of the retina. Each color perceivable by humans will be a region of that space. For example, an orange stimulus produces a relatively low level of activity in both the red-green and yellow-blue opponent pathways (x-axis and y-axis, respectively), and middle-range activity in the black-white (contrast) opponent pathway (z-axis). Pink stimuli, on the other hand, produce low activity in the red-green opponent pathway, middle-range activity in the yellow-blue opponent pathway, and high activity in the black-white (contrast) opponent  pathway.[7]  The location of each color in the space generates a “color solid”. Location on the solid, and geometrical proximity between these locations, reflect structural similarities between the perceived colors. Human gustatory representations are points in a four-dimensional state space, with each dimension coding for activity rates generated by gustatory stimuli in each type of taste receptor (sweet, salty, sour, and bitter) and their segregated efferent pathways. When implemented in a neural network with structural resources, and hence computational resources as vast as the human brain, the state space approach to psychosemantics generates a theory of content for a huge number of cognitive  states.[8] Jerry Fodor and Ernest LePore (1992) raised an important challenge to Churchland’s psychosemantics. Location in a state space alone seems insufficient to fix a state’s representational content. Churchland never explains why a point in a three-dimensional state space represents a color, as opposed to any other quality, object, or event that varies along three  dimensions.[9].  So Churchland’s account achieves its explanatory power by the interpretation imposed on the dimensions. Fodor and LePore alleged that Churchland never specified how a dimension comes to represent, e.g., degree of saltiness, as opposed to yellow-blue wavelength opposition. One obvious answer appeals to the stimuli that form the “external” inputs to the neural network in question. Then, for example, the individuating conditions on neural representations of colors are that opponent processing neurons receive input from a specific class of photoreceptors. The latter in turn have electromagnetic radiation (of a specific portion of the visible spectrum) as their activating stimuli. However, this appeal to “external” stimuli as the ultimate individuating conditions for representational content makes the resulting approach a version of informational semantics. Is this approach consonant with other neurobiological details? The neurobiological paradigm for informational semantics is the feature detector: one or more neurons that are (i) maximally responsive to a particular type of stimulus, and (ii) have the function of indicating the presence of that stimulus type. Examples of such stimulus-types for visual feature detectors include high-contrast edges, motion direction, and colors. A favorite feature detector among philosophers is the alleged fly detector in the frog. Lettvin et al. (1959) identified cells in the frog retina that responded maximally to small shapes moving across the visual field. The idea that these cells’ activity functioned to detect flies rested upon knowledge of the frogs’ diet. (Bechtel 1998 provides a useful discussion.) Using experimental techniques ranging from single-cell recording to sophisticated functional imaging, neuroscientists discovered a host of neurons that are maximally responsive to a variety of complex stimuli. However, establishing condition (ii) on a feature detector is much more difficult. Even some paradigm examples have been called into question. David Hubel and Torsten Wiesel’s (1962) Nobel Prize-winning work establishing the receptive fields of neurons in striate (visual) cortex is often interpreted as revealing cells whose function is edge detection. However, Lehky and Sejnowski (1988) challenged this interpretation. They trained an artificial neural network to distinguish the three-dimensional shape and orientation of an object from its two-dimensional shading pattern. Their network incorporates many features of visual neurophysiology. Nodes in the trained network turned out to be maximally responsive to edge contrasts, but did not appear to have the function of edge detection. (See Churchland and Sejnowski 1992 for a review.) Kathleen Akins (1996) offered a different neurophilosophical challenge to informational semantics and its affiliated feature-detection view of sensory representation. We saw in the previous section that Akins argued that the physiology of thermoreception violates three necessary conditions on “veridical” representation. From this fact she raised doubts about looking for feature-detecting neurons to ground a psychosemantics generally, including for thought contents. Human thoughts about flies, for example, are sensitive to numerical distinctions between particular flies and the particular locations they can occupy. But the ends of frog nutrition are well served without a representational system sensitive to such ontological niceties. Whether a fly seen now is numerically identical to one seen a moment ago need not, and perhaps cannot, figure into the frog’s feature detection repertoire. Akins’ critique cast doubt on whether details of sensory transduction will scale up to provide an adequate unified psychosemantics for all concepts. It also raised new questions for human intentionality. How do we get from activity patterns in “narcissistic” sensory receptors, keyed not to “objective” environmental features but rather only to effects of the stimuli on the patch of tissue innervated, to human ontologies replete with enduring objects with stable configurations of properties and relations, types and their tokens (as the “fly-thought” example presented above reveals), and the rest? And how did the development of a stable, rich ontology confer survival advantages to human ancestors?