 There are three components to the traditional (“tripartite”) analysis of knowledge. According to this analysis, justified, true belief is necessary and sufficient for knowledge. The tripartite analysis of knowledge is often abbreviated as the “JTB” analysis, for “justified true belief”. Much of the twentieth-century literature on the analysis of knowledge took the JTB analysis as its starting-point. It became something of a convenient fiction to suppose that this analysis was widely accepted throughout much of the history of philosophy. In fact, however, the JTB analysis was first articulated in the twentieth century by its  attackers.[1]  Before turning to influential twentieth-century arguments against the JTB theory, let us briefly consider the three traditional components of knowledge in turn. Most epistemologists have found it overwhelmingly plausible that what is false cannot be known. For example, Hillary Clinton did not win the 2016 US Presidential election. Consequently, nobody knows that Hillary Clinton won the election. One can only know things that are true. Sometimes when people are very confident of something that turns out to be wrong, we use the word “knows” to describe their situation. Many people expected Clinton to win the election. Speaking loosely, one might even say that many people “knew” that Clinton would win the election—until she lost. Hazlett (2010) argues on the basis of data like this that “knows” is not a factive  verb.[2]  Hazlett’s diagnosis is deeply controversial; most epistemologists will treat sentences like “I knew that Clinton was going to win” as a kind of exaggeration—as not literally true. Something’s truth does not require that anyone can know or prove that it is true. Not all truths are established truths. If you flip a coin and never check how it landed, it may be true that it landed heads, even if nobody has any way to tell. Truth is a metaphysical, as opposed to epistemological, notion: truth is a matter of how things are, not how they can be shown to be. So when we say that only true things can be known, we’re not (yet) saying anything about how anyone can access the truth. As we’ll see, the other conditions have important roles to play here. Knowledge is a kind of relationship with the truth—to know something is to have a certain kind of access to a  fact.[3] The belief condition is only slightly more controversial than the truth condition. The general idea behind the belief condition is that you can only know what you believe. Failing to believe something precludes knowing it. “Belief” in the context of the JTB theory means full belief, or outright belief. In a weak sense, one might “believe” something by virtue of being pretty confident that it’s probably true—in this weak sense, someone who considered Clinton the favourite to win the election, even while recognizing a nontrivial possibility of her losing, might be said to have “believed” that Clinton would win. Outright belief is stronger (see, e.g., Fantl & McGrath 2009: 141; Nagel 2010: 413–4; Williamson 2005: 108; or Gibbons 2013: 201.). To believe outright that p, it isn’t enough to have a pretty high confidence in p; it is something closer to a commitment or a being  sure.[4] Although initially it might seem obvious that knowing that p requires believing that p, a few philosophers have argued that knowledge without belief is indeed possible. Suppose Walter comes home after work to find out that his house has burned down. He says: “I don’t believe it”. Critics of the belief condition might argue that Walter knows that his house has burned down (he sees that it has), but, as his words indicate, he does not believe it. The standard response is that Walter’s avowal of disbelief is not literally true; what Walter wishes to convey by saying “I don’t believe it” is not that he really does not believe that his house has burned down, but rather that he finds it hard to come to terms with what he sees. If he genuinely didn’t believe it, some of his subsequent actions, such as phoning his insurance company, would be rather mysterious. A more serious counterexample has been suggested by Colin Radford (1966). Suppose Albert is quizzed on English history. One of the questions is: “When did Queen Elizabeth die?” Albert doesn’t think he knows, but answers the question correctly. Moreover, he gives correct answers to many other questions to which he didn’t think he knew the answer. Let us focus on Albert’s answer to the question about Elizabeth: Radford makes the following two claims about this example: Radford’s intuitions about cases like these do not seem to be idiosyncratic; Myers-Schutz & Schwitzgebel (2013) find evidence suggesting that many ordinary speakers tend to react in the way Radford suggests. In support of (a), Radford emphasizes that Albert thinks he doesn’t know the answer to the question. He doesn’t trust his answer because he takes it to be a mere guess. In support of (b), Radford argues that Albert’s answer is not at all just a lucky guess. The fact that he answers most of the questions correctly indicates that he has actually learned, and never forgotten, such historical facts. Since he takes (a) and (b) to be true, Radford holds that belief is not necessary for knowledge. But either of (a) and (b) might be resisted. One might deny (a), arguing that Albert does have a tacit belief that (E), even though it’s not one that he thinks amounts to knowledge. David Rose and Jonathan Schaffer (2013) take this route. Alternatively, one might deny (b), arguing that Albert’s correct answer is not an expression of knowledge, perhaps because, given his subjective position, he does not have justification for believing (E). The justification condition is the topic of the next section. Why is condition (iii) necessary? Why not say that knowledge is true belief? The standard answer is that to identify knowledge with true belief would be implausible because a belief might be true even though it is formed improperly. Suppose that William flips a coin, and confidently believes—on no particular basis—that it will land tails. If by chance the coin does land tails, then William’s belief was true; but a lucky guess such as this one is no knowledge. For William to know, his belief must in some epistemic sense be proper or appropriate: it must be  justified.[5] Socrates articulates the need for something like a justification condition in Plato’s Theaetetus, when he points out that “true opinion” is in general insufficient for knowledge. For example, if a lawyer employs sophistry to induce a jury into a belief that happens to be true, this belief is insufficiently well-grounded to constitute knowledge. There is considerable disagreement among epistemologists concerning what the relevant sort of justification here consists in. Internalists about justification think that whether a belief is justified depends wholly on states in some sense internal to the subject. According to one common such sense of “internal”, only those features of a subject’s experience which are directly or introspectively available count as “internal”—call this “access internalism”. According to another, only intrinsic states of the subject are “internal”—call this “state internalism”. See Feldman & Conee 2001 for the distinction. Conee and Feldman present an example of an internalist view. They have it that S’s belief that p is justified if and only if believing that p is the attitude towards p that best fits S’s evidence, where the latter is understood to depend only on S’s internal mental states. Conee and Feldman call their view “evidentialism”, and characterize this as the thesis that justification is wholly a matter of the subject’s evidence. Given their (not unsubstantial) assumption that what evidence a subject has is an internal matter, evidentialism implies  internalism.[6] Externalists about justification think that factors external to the subject can be relevant for justification; for example, process reliabilists think that justified beliefs are those which are formed by a cognitive process which tends to produce a high proportion of true beliefs relative to false  ones.[7]  We shall return to the question of how reliabilist approaches bear on the analysis of knowledge in  §6.1. It is worth noting that one might distinguish between two importantly different notions of justification, standardly referred to as “propositional justification” and “doxastic justification”. (Sometimes “ex ante” justification and “ex post” justification,  respectively.)[8]  Unlike that between internalist and externalist approaches to justification, the distinction between propositional and doxastic justification does not represent a conflict to be resolved; it is a distinction between two distinct properties that are called “justification”. Propositional justification concerns whether a subject has sufficient reason to believe a given  proposition;[9]  doxastic justification concerns whether a given belief is held  appropriately.[10]  One common way of relating the two is to suggest that propositional justification is the more fundamental, and that doxastic justification is a matter of a subject’s having a belief that is appropriately responsive to or based on their propositional justification. The precise relation between propositional and doxastic justification is subject to controversy, but it is uncontroversial that the two notions can come apart. Suppose that Ingrid ignores a great deal of excellent evidence indicating that a given neighborhood is dangerous, but superstitiously comes to believe that the neighborhood is dangerous when she sees a black cat crossing the street. Since forming beliefs on the basis of superstition is not an epistemically appropriate way of forming beliefs, Ingrid’s belief is not doxastically justified; nevertheless, she does have good reason to believe as she does, so she does have propositional justification for the proposition that the neighborhood is dangerous. Since knowledge is a particularly successful kind of belief, doxastic justification is a stronger candidate for being closely related to knowledge; the JTB theory is typically thought to invoke doxastic justification (but see Lowy 1978).