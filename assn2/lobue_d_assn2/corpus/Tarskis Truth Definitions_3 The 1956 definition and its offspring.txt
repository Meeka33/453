 In 1933 Tarski assumed that the formal languages that he was dealing with had two kinds of symbol (apart from punctuation), namely constants and variables. The constants included logical constants, but also any other terms of fixed meaning. The variables had no independent meaning and were simply part of the apparatus of quantification. Model theory  by contrast works with three levels of symbol. There are the logical constants \((=, \neg\), & for example), the variables (as before), and between these a middle group of symbols which have no fixed meaning but get a meaning through being applied to a particular structure. The symbols of this middle group include the nonlogical constants of the language, such as relation symbols, function symbols and constant individual symbols. They also include the quantifier symbols \(\forall\) and \(\exists\), since we need to refer to the structure to see what set they range over. This type of three-level language corresponds to mathematical usage; for example we write the addition operation of an abelian group as +, and this symbol stands for different functions in different groups. So one has to work a little to apply the 1933 definition to model-theoretic languages. There are basically two approaches: (1) Take one structure \(A\) at a time, and regard the nonlogical constants as constants, interpreted in \(A\). (2) Regard the nonlogical constants as variables, and use the 1933 definition to describe when a sentence is satisfied by an assignment of the ingredients of a structure \(A\) to these variables. There are problems with both these approaches, as Tarski himself describes in several places. The chief problem with (1) is that in model theory we very frequently want to use the same language in connection with two or more different structures – for example when we are defining elementary embeddings between structures (see the entry on  first-order model theory).  The problem with (2) is more abstract: it is disruptive and bad practice to talk of formulas with free variables being ‘true’. (We saw in Section 2.2 how Tarski avoided talking about truth in connection with sentences that have varying interpretations.) What Tarski did in practice, from the appearance of his textbook in 1936 to the late 1940s, was to use a version of (2) and simply avoid talking about model-theoretic sentences being true in structures; instead he gave an indirect definition of what it is for a structure to be a ‘model of’ a sentence, and apologised that strictly this was an abuse of language. (Chapter VI of Tarski 1994 still contains relics of this old approach.) By the late 1940s it had become clear that a direct model-theoretic truth definition was needed. Tarski and colleagues experimented with several ways of casting it. The version we use today is based on that published by Tarski and Robert Vaught in 1956. See the entry on  classical logic  for an exposition. The right way to think of the model-theoretic definition is that we have sentences whose truth value varies according to the situation where they are used. So the nonlogical constants are not variables; they are definite descriptions whose reference depends on the context. Likewise the quantifiers have this indexical feature, that the domain over which they range depends on the context of use. In this spirit one can add other kinds of indexing. For example a Kripke structure is an indexed family of structures, with a relation on the index set; these structures and their close relatives are fundamental for the semantics of modal,  temporal  and  intuitionist  logic. Already in the 1950s model theorists were interested in formal languages that include kinds of expression different from anything in Tarski’s 1933 paper. Extending the truth definition to infinitary logics was no problem at all. Nor was there any serious problem about most of the generalised quantifiers proposed at the time. For example there is a quantifier \(Qxy\) with the intended meaning: \(QxyF(x,y)\) if and only if there is an infinite set \(X\) of elements such that for all \(a\) and \(b\) in \(X, F(a,b)\). This definition itself shows at once how the required clause in the truth definition should go. In 1961 Leon Henkin pointed out two sorts of model-theoretic language that didn’t immediately have a truth definition of Tarski’s kind. The first had infinite strings of quantifiers: The second had quantifiers that are not linearly ordered. For ease of writing I use Hintikka’s later notation for these: Here the slash after \(\exists v_4\) means that this quantifier is outside the scope of the earlier quantifier \(\forall v_1\) (and also outside that of the earlier existential quantifier). Henkin pointed out that in both cases one could give a natural semantics in terms of Skolem functions. For example the second sentence can be paraphrased as which has a straightforward Tarski truth condition in second order logic. Hintikka then observed that one can read the Skolem functions as winning strategies in a game, as in the entry on  logic and games.  In this way one can build up a compositional semantics, by assigning to each formula a game. A sentence is true if and only if the player Myself (in Hintikka’s nomenclature) has a winning strategy for the game assigned to the sentence. This game semantics agrees with Tarski’s on conventional first-order sentences. But it is far from fully abstract; probably one should think of it as an operational semantics, describing how a sentence is verified rather than whether it is true. The problem of giving a Tarski-style semantics for Henkin’s two languages turned out to be different in the two cases. With the first, the problem is that the syntax of the language is not well-founded: there is an infinite descending sequence of subformulas as one strips off the quantifiers one by one. Hence there is no hope of giving a definition of satisfaction by recursion on the complexity of formulas. The remedy is to note that the explicit form of Tarski’s truth definition in Section 2.1 above didn’t require a recursive definition; it needed only that the conditions on the satisfaction relation \(S\) pin it down uniquely. For Henkin’s first style of language this is still true, though the reason is no longer the well-foundedness of the syntax. For Henkin’s second style of language, at least in Hintikka’s notation (see the entry on  independence friendly logic),  the syntax is well-founded, but the displacement of the quantifier scopes means that the usual quantifier clauses in the definition of satisfaction no longer work. To get a compositional and fully abstract semantics, one has to ask not what assignments of variables satisfy a formula, but what sets of assignments satisfy the formula ‘uniformly’, where ‘uniformly’ means ‘independent of assignments to certain variables, as shown by the slashes on quantifiers inside the formula’. (Further details of revisions of Tarski’s truth definition along these lines are in the entry on  dependence logic.)  Henkin’s second example is of more than theoretical interest, because clashes between the semantic and the syntactic scope of quantifiers occur very often in natural languages.