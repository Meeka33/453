 Another candidate fourth condition on knowledge is sensitivity. Sensitivity, to a first approximation, is this counterfactual relation: S’s belief that p is sensitive if and only if, if p were false, S would not believe that  p.[14] A sensitivity condition on knowledge was defended by Robert Nozick (1981). Given a Lewisian (Lewis 1973) semantics for counterfactual conditionals, the sensitivity condition is equivalent to the requirement that, in the nearest possible worlds in which not-p, the subject does not believe that p. One motivation for including a sensitivity condition in an analysis of knowledge is that there seems to be an intuitive sense in which knowledge requires not merely being correct, but tracking the truth in other possible circumstances. This approach seems to be a plausible diagnosis of what goes wrong in at least some Gettier cases. For example, in Dharmottara’s desert water case, your belief that there is water in a certain location appears to be insensitive to the fact of the water. For if there were no water there, you would have held the same belief on the same grounds—viz., the mirage. However, it is doubtful that a sensitivity condition can account for the phenomenon of Gettier cases in general. It does so only in cases in which, had the proposition in question been false, it would have been believed anyway. But, as Saul Kripke (2011: 167–68) has pointed out, not all Gettier cases are like this. Consider for instance the Barn County case mentioned above. Henry looks at a particular location where there happens to be a barn and believes there to be a barn there. The sensitivity condition rules out this belief as knowledge only if, were there no barn there, Henry would still have believed there was. But this counterfactual may be false, depending on how the Barn County case is set up. For instance, it is false if the particular location Henry is examining is not one that would have been suitable for the erecting of a barn façade. Relatedly, as Kripke has also indicated (2011: 186), if we suppose that barn facades are always green, but genuine barns are always red, Henry’s belief that he sees a red barn will be sensitive, even though his belief that he sees a barn will not. (We assume Henry is unaware that colour signifies anything relevant.) Since intuitively, the former belief looks to fall short of knowledge in just the same way as the latter, a sensitivity condition will only handle some of the intuitive problems deriving from Gettier cases. Most epistemologists today reject sensitivity requirements on knowledge. The chief motivation against a sensitivity condition is that, given plausible assumptions, it leads to unacceptable implications called “abominable   conjunctions”.[15]  To see this, suppose first that skepticism about ordinary knowledge is false—ordinary subjects know at least many of the things we ordinarily take them to know. For example, George, who can see and use his hands perfectly well, knows that he has hands. This is of course perfectly consistent with a sensitivity condition on knowledge, since if George did not have hands—if they’d been recently chopped off, for instance—he would not believe that he had hands. Now imagine a skeptical scenario in which George does not have hands. Suppose that George is the victim of a Cartesian demon, deceiving him into believing that he has hands. If George were in such a scenario, of course, he would falsely believe himself not to be in such a scenario. So given the sensitivity condition, George cannot know that he is not in such a scenario. Although these two verdicts—the knowledge-attributing one about ordinary knowledge, and the knowledge-denying one about the skeptical scenario—are arguably each intuitive, it is intuitively problematic to hold them together. Their conjunction is, in DeRose’s term, abominable: “George knows that he has hands, but he doesn’t know that he’s not the handless victim of a Cartesian demon”. A sensitivity condition on knowledge, combined with the nonskeptical claim that there is ordinary knowledge, seems to imply such abominable  conjunctions.[16] Most contemporary epistemologists have taken considerations like these to be sufficient reason to reject sensitivity   conditions.[17]  However, see Ichikawa (2011a) for an interpretation and endorsement of the sensitivity condition according to which it may avoid commitment to abominable conjunctions. Although few epistemologists today endorse a sensitivity condition on knowledge, the idea that knowledge requires a subject to stand in a particular modal relation to the proposition known remains a popular one. In his 1999 paper, “How to Defeat Opposition to Moore”, Ernest Sosa proposed that a safety condition ought to take the role that sensitivity was intended to play. Sosa characterized safety as the counterfactual contrapositive of sensitivity. Sensitivity: If p were false, S would not believe that p. Safety: If S were to believe that p, p would not be  false.[18] Although contraposition is valid for the material conditional \((A \supset B\) iff \(\mathord{\sim} B \supset \mathord{\sim}A)\), Sosa suggests that it is invalid for counterfactuals, which is why sensitivity and safety are not equivalent. An example of a safe belief that is not sensitive, according to Sosa, is the belief that a distant skeptical scenario does not obtain. If we stipulate that George, discussed above, has never been at risk of being the victim of a Cartesian demon—because, say, Cartesian demons do not exist in George’s world—then George’s belief that he is not such a victim is a safe one, even though we saw in the previous section that it could not be sensitive. Notice that although we stipulated that George is not at risk of deceit by Cartesian demons, we did not stipulate that George himself had any particular access to this fact. Unless he does, safety, like sensitivity, will be an externalist condition on knowledge in the “access” sense. It is also externalist in the “state” sense, since the truth of the relevant counterfactuals will depend on features outside the subject. Characterizing safety in these counterfactual terms depends on substantive assumptions about the semantics of counterfactual  conditionals.[19]  If we were to accept, for instance, David Lewis’s or Robert Stalnaker’s treatment of counterfactuals, including a strong centering condition according to which the actual world is always uniquely closest, all true beliefs would count as safe according to the counterfactual analysis of  safety.[20]  Sosa intends the relevant counterfactuals to be making a stronger claim, requiring roughly that in all nearby worlds in which S believes that p, p is not false. Rather than resting on a contentious treatment of counterfactuals, then, it may be most perspicuous to understand the safety condition more directly in these modal terms, as Sosa himself often does: Safety: In all nearby worlds where S believes that p, p is not false. Whether a JTB+safety analysis of knowledge could be successful is somewhat difficult to evaluate, given the vagueness of the stated “nearby” condition. The status of potential counterexamples will not always be straightforward to apply. For example, Juan Comesaña (2005) presents a case he takes to refute the requirement that knowledge be safe. In Comesaña’s example, the host of a Halloween party enlists Judy to direct guests to the party. Judy’s instructions are to give everyone the same directions, which are in fact accurate, but that if she sees Michael, the party will be moved to another location. (The host does not want Michael to find the party.) Suppose Michael never shows up. If a given guest does not, but very nearly does, decide to wear a very realistic Michael costume to the party, then his belief, based in Judy’s testimony, about the whereabouts of the party will be true, but could, Comesaña says, easily have been false. (Had he merely made a slightly different choice about his costume, he would have been deceived.) Comesaña describes the case as a counterexample to a safety condition on knowledge. However, it is open to a safety theorist to argue that the relevant skeptical scenario, though possible and in some sense nearby, is not near enough in the relevant respect to falsify the safety condition. Such a theorist would, if she wanted the safety condition to deliver clear verdicts, face the task of articulating just what the relevant notion of similarity amounts to (see also Bogardus 2014). Not all further clarifications of a safety condition will be suitable for the use of the latter in an analysis of knowledge. In particular, if the respect of similarity that is relevant for safety is itself explicated in terms of knowledge, then an analysis of knowledge which made reference to safety would be in this respect circular. This, for instance, is how Timothy Williamson characterizes safety. He writes, in response to a challenge by Alvin Goldman: In many cases, someone with no idea of what knowledge is would be unable to determine whether safety obtained. Although they could use the principle that safety entails truth to exclude some cases, those are not the interesting ones. Thus Goldman will be disappointed when he asks what the safety account predicts about various examples in which conflicting considerations pull in different directions. One may have to decide whether safety obtains by first deciding whether knowledge obtains, rather than vice versa. (Williamson 2009: 305) Because safety is understood only in terms of knowledge, safety so understood cannot serve in an analysis of knowledge. Nor is it Williamson’s intent that it should do so; as we will see below, Williamson rejects the project of analyzing knowledge. This is of course consistent with claiming that safety is a necessary condition on knowledge in the straightforward sense that the latter entails the former. A third approach to modal conditions on knowledge worthy of mention is the requirement that for a subject to know that p, she must rule out all “relevant alternatives” to p. Significant early proponents of this view include Stine 1976, Goldman 1976, and Dretske 1981. The idea behind this approach to knowledge is that for a subject to know that p, she must be able to “rule out” competing hypotheses to p—but that only some subset of all not-p possibilities are “relevant” for knowledge attributions. Consider for example, the differences between the several models that have been produced of Apple’s iPhone. To be able to know by sight that a particular phone is the 6S model, it is natural to suppose that one must be able to tell the difference between the iPhone 6S and the iPhone 7; the possibility that the phone in question is a newer model is a relevant alternative. But perhaps there are other possibilities in which the belief that there is an iPhone 6S is false that do not need to be ruled out—perhaps, for instance, the possibility that the phone is not an iPhone, but a Chinese knock-off, needn’t be considered. Likewise for the possibility that there is no phone at all, the phone-like appearances being the product of a Cartesian demon’s machinations. Notice that in these cases and many of the others that motivate the relevant-alternatives approach to knowledge, there is an intuitive sense in which the relevant alternatives tend to be more similar to actuality than irrelevant ones. As such, the relevant alternatives theory and safety-theoretic approaches are very similar, both in verdict and in spirit. As in the case of a safety theorist, the relevant alternatives theorist faces a challenge in attempting to articulate what determines which possibilities are relevant in a given  situation.[21]