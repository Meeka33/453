 Now that we have definitions of “mental simulation of” and cognate notions, it is time to consider which mental states and processes satisfy them, if any. Are there really simulated mental states? That is, are there mental states generated by the reuse of cognitive mechanisms? And do these mental states resemble the mental states generated by the use of such mechanisms? For example, is it truly the case that visual images are mental simulations of visual experiences? What about decisions, emotions, beliefs, desires, and bodily sensations? Can our minds generate simulated counterparts of all these types of mental states? In this section, we consider how Simulation Theorists have tackled these problems. We will do so by focusing on the following question: are there really simulation processes (as defined by  PROC)?  If the answer to this question is positive, it follows that there are mental states standing in the relation of mental simulation (as defined by  RES+REU),  and thus simulated mental states. Following Goldman (2006), it has become customary among Simulation Theorists to argue for the existence of two types of simulation processes: high-level simulation processes and low-level simulation processes (see, however, de Vignemont 2009). By exploring this distinction, we begin to articulate the cognitive architecture underlying mental simulation proposed by ST. High-level simulation processes are cognitive processes with the following features: (a) they are typically conscious, under voluntary control, and stimulus-independent; (b) they satisfy  PROC,  that is, they are implemented by the reuse of a certain cognitive mechanism, C, and their output states resemble the output states generated by the use of  C.[4]  Here are some cognitive processes that, according to Simulation Theorists, qualify as high-level simulation processes. Visualizing: the cognitive process generating visual images (Currie 1995; Currie & Ravenscroft 2002; Goldman 2006); motor imagination: the cognitive process generating imagined bodily movements and actions (Currie & Ravenscroft 1997, 2002; Goldman 2006); imagining deciding: the cognitive process generating decision-like imaginings (Currie & Ravenscroft 2002); imagining believing: the cognitive process generating belief-like imaginings (Currie & Ravenscroft 2002); imagining desiring: the cognitive process generating desire-like imaginings (Currie 2002). In what follows, we shall consider a couple of them in some detail. Visualizing first. It is not particularly hard to see why visualizing satisfies condition (a). Typically: one can decide to visualize (or stop visualizing) something; the process is not driven by perceptual stimuli; and at least some parts of the visualization process are conscious. There might be cases in which visualizing is not under voluntary control, is stimulus-driven and, maybe, even entirely unconscious. This, however, is not a problem, since we know that there are clear cases satisfying (a). Unsurprisingly, the difficult task for Simulation Theorists is to establish that visualizing has feature (b), that is: it is implemented by the reuse of the visual mechanism; and its outputs (that is, visual images) resemble genuine visual experiences. Simulation Theorists maintain that they have strong empirical evidence supporting the claim that visualizing satisfies  PROC.  Here is a sample (this and further evidence is extensively discussed in Currie 1995, Currie & Ravenscroft 2002, and in Goldman 2006): On this basis, Simulation Theorists conclude that visualizing is indeed implemented by the reuse of the visual mechanism (evidence i and ii) and that its outputs, i.e., visual images, do resemble visual experiences (evidence iii, iv, and v). Thus, visualizing is a process that qualifies as high-level simulation, and visual images are simulated mental states. Visual images are mental simulations of perceptual states. Are there high-level simulation processes whose outputs instead are mental simulations of propositional attitudes? (If you think that visual experiences are propositional attitudes, you can rephrase the question as follows: are there high-level simulation processes whose outputs are mental simulations of non-sensory states?) Three candidate processes have received a fair amount of attention in the simulationist literature: imagining desiring, imagining deciding, and imagining believing. The claims made by Simulation Theorists about these cognitive processes and their output states have generated an intense debate (Doggett & Egan 2007; Funkhouser & Spaulding 2009; Kieran & Lopes 2003; Nichols 2006a, 2006b; Nichols & Stich 2003; Velleman 2000). We do not have space to review it here (two good entry points are the introduction to Nichols 2006a and the entry on  imagination).  Rather, we shall confine ourselves to briefly illustrating the simulationist case in favour of the thesis that imagining believing is a high-level simulation process. I don’t believe that Rome is in France, but I can imagine believing it. Imagining believing typically is a conscious, stimulus-independent process, under voluntary control. Thus, imagining believing satisfies condition (a). In order for it to count as an instance of high-level simulation process, it also needs to have feature (b), that is: (b.i) its outputs (i.e., belief-like imaginings) have to resemble genuine beliefs in some significant respects; (b.ii) it has to be implemented by the reuse of the cognitive mechanism (whose use implements the cognitive process) that generates genuine beliefs—let us call it “the belief-forming mechanism”. Does imagining believing satisfy (b)? Currie and Ravenscroft (2002) argue in favour of (b.i). Beliefs are individuated in terms of their content and functional role. Belief-like imaginings—Currie and Ravenscroft say—have the same content and a similar functional role to their genuine counterparts. For example, the belief that Rome is in France and the belief-like imagining that Rome is in France have exactly the same propositional content: that Rome is in France. Moreover, belief-like imaginings mirror the inferential role of genuine beliefs. If one believes both that Rome is in France and that French is the language spoken in France, one can infer the belief that French is the language spoken in Rome. Analogously, from the belief-like imagining that Rome is in France and the genuine belief that French is the language spoken in France, one can infer the belief-like imagining that French is the language spoken in Rome. So far, so good (but see Nichols 2006b). What about (b.ii)? Direct evidence bearing on it is scarce. However, Simulation Theorists can give an argument along the following lines. First, one owes an explanation of why belief-like imaginings are, well, belief-like—as we have said above, it seems that they have the same type of content as, and a functional role similar to, genuine beliefs. A possible explanation for this is that both types of mental states are generated by (cognitive processes implemented by) the same cognitive mechanism. Second, it goes without saying that our mind contains a mechanism for generating beliefs (the belief-forming mechanism), and that there must be some mechanism or another in charge of generating belief-like imaginings. It is also well known that cognitive mechanisms are evolutionary costly to build and maintain. Thus, evolution might have adopted the parsimonious strategy of redeploying a pre-existing mechanism (the belief-forming mechanism) for a non-primary function, i.e., generating belief-like imaginings—in general, this hypothesis is also supported by the idea that neural reuse is one of the fundamental organizational principle of the brain (Anderson 2008). If one puts these two strands of reasoning together, one gets a prima facie case for the claim that imagining believing is implemented by the reuse of the belief-forming mechanism—that is, a prima facie case for the conclusion that imagining believing satisfies (b.ii). Since imagining believing appears also to satisfy (b.i) and (a), lacking evidence to the contrary, Simulation Theorists are justified in considering it to be a high-level simulation process. Let’s take stock. We have examined a few suggested instances of high-level simulation processes. If Simulation Theorists are correct, they exhibit the following commonalities: they satisfy  PROC  (this is why they are simulation processes); they are typically conscious, under voluntary control, and stimulus-independent (this is why they are high-level). Do they have some other important features in common? Yes, they do—Simulation Theorists say. They all are under the control of a single cognitive mechanism: imagination (more precisely, Currie & Ravenscroft (2002) talk of Re-Creative Imagination, while Goldman (2006, 2009) uses the expression “Enactment Imagination”). The following passage will give you the basic gist of the proposal: What is distinctive to high-level simulation is the psychological mechanism … that produces it, the mechanism of imagination. This psychological system is capable of producing a wide variety of simulational events: simulated seeings (i.e., visual imagery), … simulated motor actions (motor imagery), simulated beliefs, … and so forth. … In producing simulational outputs, imagination does not operate all by itself. … For example, it recruits parts of the visual system to produce visual imagery …. Nonetheless, imagination “‘takes the lead”’ in directing or controlling the other systems it enlists for its project. (Goldman 2009: 484–85) Here is another way to make the point. We already know that, according to ST, visualizing is implemented by the reuse of the visual mechanism. In the above passage, Goldman adds that the reuse of the visual mechanism is initiated, guided and controlled by imagination. The same applies, mutatis mutandis, to all cases of high-level simulation processes. For example, in imagining hearing, imagination “gets in control” of the auditory mechanism, takes it off-line, and (re)uses it to generate simulated auditory experiences. Goldman (2012b, Goldman & Jordan 2013) supports this claim by making reference to neuroscientific data indicating that the same core brain network, the so-called “default network”, subserves all the following self-projections: prospection (projecting oneself into one’s future); episodic memory (projecting oneself into one’s past); perspective taking (projecting oneself into other minds); and navigation (projecting oneself into other places) (see Buckner & Carroll 2007 for a review). These different self-projections presumably involve different high-level simulation processes. However, they all have something in common: they all involve imagination-based perspectival shifts. Therefore, the fact that there is one brain network common to all these self-projections lends some support to the claim that there is one common cognitive mechanism, i.e., imagination, which initiates, guides, and controls all high-level simulation processes. If Goldman is right, and all high-level simulation processes are guided by imagination, we can then explain why, in our common parlance, we tend to describe high-level simulation processes and outputs in terms of imaginings, images, imagery, etc. More importantly, we can also explain why high-level simulation processes are conscious, under voluntary control, and stimulus-independent. These are, after all, typical properties of imaginative processes. However, there are simulation processes that typically are neither conscious, nor under voluntary control, nor stimulus independent. This indicates that they are not imagination-based. It is to this other type of simulation processes that we now turn. Low-level simulation processes are cognitive processes with these features: (a*) they are typically unconscious, automatic, and stimulus-driven; (b) they satisfy  PROC,  that is, they are implemented by the reuse of a certain cognitive mechanism, C, and their output states resemble the output states generated by the use of C. What cognitive processes are, according to ST, instances of low-level simulation? The answer can be given in two words: mirroring processes. Clarifying what these two words mean, however, will take some time. The story begins at the end of the 1980s in Parma, Italy, where the neuroscientist Giacomo Rizzolatti and his team were investigating the properties of the neurons in the macaque monkey ventral premotor cortex. Through single-cell recording experiments, they discovered that the activity of neurons in the area F5 is correlated with goal-directed motor actions and not with particular movements (Rizzolatti et al. 1988). For example, some F5 neurons fire when the monkey grasps an object, regardless of whether the monkey uses the left or the right hand. A plausible interpretation of these results is that neurons in monkey area F5 encode motor intentions (i.e., those intentions causing and guiding actions like reaching, grasping, holding, etc.) and not mere kinematic instructions (i.e., those representations specifying the fine-grained motor details of an action). (In-depth philosophical analyses of the notion of motor intention can be found in: Brozzo forthcoming; Butterfill & Sinigaglia 2014; Pacherie 2000). This was an already interesting result, but it was not what the Parma group became famous for. Rather, their striking discovery happened a few years later, helped by serendipity. Researchers were recording the activity of F5 neurons in a macaque monkey performing an object-retrieval task. In between trials, the monkey stood still and watched an experimenter setting up the new trial, with microelectrodes still measuring the monkey’s brain activity. Surprisingly, some of the F5 neurons turned out to fire when the monkey saw the experimenter grasping and placing objects. This almost immediately led to new experiments, which revealed that a portion of F5 neurons not only fire when the monkey performs a certain goal-directed motor action (say, bringing a piece of food to the mouth), but also when it sees another agent performing the same (type of) action (di Pellegrino et al. 1992; Gallese et al. 1996; Rizzolatti et al. 1996). For this reason, these neurons were aptly called “mirror neurons”, and it was proposed that they encode motor intentions both during action execution and action observation (Rizzolatti & Sinigaglia 2007, forthcoming). Later studies found mirror neurons also in the macaque monkey inferior parietal lobule (Gallese et al. 2002), which together with the ventral premotor cortex constitutes the monkey cortical mirror neuron circuit (Rizzolatti & Craighero 2004). Subsequent evidence suggested that an action mirror mechanism—that is, a cognitive mechanism that gets activated both when an individual performs a certain goal-directed motor action and when she sees another agent performing the same action—also exists in the human brain (for reviews, see Rizzolatti & Craighero 2004, and Rizzolatti & Sinigaglia forthcoming). In fact, it appears that there are mirror mechanisms in the human brain outside the action domain as well: a mirror mechanism for disgust (Wicker et al. 2003), one for pain (Singer at al. 2004; Avenanti et al. 2005), and one for touch (Blakemore et al. 2005). Given the variety of mirror mechanisms, it is not easy to give a definition that fits them all. Goldman (2008b) has quite a good one though, and we will draw from it: a cognitive mechanism is a mirror mechanism if and only if it gets activated both when an individual undergoes a certain mental event endogenously and when she perceives a sign that another individual is undergoing the same (type of) mental event. For example, the pain mirror mechanism gets activated both when individuals experience “a painful stimulus and … when they observe a signal indicating that [someone else] is receiving a similar pain stimulus” (Singer et al. 2004: 1157). Having introduced the notions of mirror neuron and mirror mechanism, we can define the crucial notion of this section: mirroring process. We have seen that mirror mechanisms can get activated in two distinct modes: (i) endogenously; (ii) in the perception mode. For example, my action mirror mechanism gets endogenously activated when I grasp a mug, while it gets activated in the perception mode when I see you grasping a mug. Following again Goldman (2008b), let us say that a cognitive process is a mirroring process if and only if it is constituted by the activation of a mirror mechanism in the perception mode. For example, what goes on in my brain when I see you grasping a mug counts as a mirroring process. Now that we know what mirroring processes are, we can return to our initial problem—i.e., whether they are low-level simulation processes (remember that a cognitive process is a low-level simulation process if and only if: (a*) it is typically unconscious, automatic, and stimulus-driven; (b) it satisfies  PROC).  For reasons of space, we will focus on disgust mirroring only. Wicker et al. (2003) carried out an fMRI study in which participants first observed videos of disgusted facial expressions and subsequently underwent a disgust experience via inhaling foul odorants. It turned out that the same neural area—the left anterior insula—that was preferentially activated during the experience of disgust was also preferentially activated during the observation of the disgusted facial expressions. These results indicate the existence of a disgust mirror mechanism. Is disgust mirroring (the activation of the disgust mirror mechanism in the perception mode) a low-level simulation process? Simulation Theorists answer in the affirmative. Here is why disgust mirroring satisfies (a*): the process is stimulus-driven: it is sensitive to certain perceptual stimuli (disgusted facial expressions); it is automatic; and it is typically unconscious (even though its output, i.e., “mirrored disgust”, is sometimes conscious). What about condition (b)? Presumably, the primary (evolutionary) function of the disgust mechanism is to produce a disgust response to spoiled food, germs, parasites etc. (Rozin et al. 2008). In the course of evolution, this mechanism could have been subsequently co-opted to also get activated by the perception (of a sign) that someone else is experiencing disgust, in order to facilitate social learning of food preferences (Gariépy et al. 2014). If this is correct, then disgust mirroring is implemented by the reuse of the disgust mechanism (by employing this mechanism for a function different than its primary one). Moreover, the output of disgust mirroring resembles the genuine experience of disgust in at least two significant respects: first, both mental states have the same neural basis; second, when conscious, they share a similar phenomenology. Accordingly, (b) is satisfied. By putting all this together, Simulation Theorists conclude that disgust mirroring is a low-level simulation process, and mirrored disgust is a simulated mental state (Goldman 2008b; Barlassina 2013)