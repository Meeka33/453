 In common parlance, we talk of putting ourselves in others’ shoes, or empathizing with other people. This talk is typically understood as adopting someone else’s point of view, or perspective, in our imagination. For example, it is quite natural to interpret the request “Try to show some empathy for John!” as asking you to use your imaginative capacity to consider the world from John’s perspective. But what is it for someone to imaginatively adopt someone else’s perspective? To a first approximation, according to Simulation Theorists, it consists of mentally simulating, or re-creating, someone else’s mental states. Currie and Ravenscroft (2002) make this point quite nicely: Imagination enables us to project ourselves into another situation and to see, or think about, the world from another perspective. These situations and perspectives … might be those of another actual person, [or] the perspective we would have on things if we believed something we actually don’t believe, [or] that of a fictional character. … Imagination recreates the mental states of others. (Currie & Ravenscroft 2002: 1, emphasis added). Thus, according to ST, empathizing with John’s sadness consists of mentally simulating his sadness, and adopting Mary’s political point of view consists of mentally simulating her political beliefs. This is the intuitive and general sense of mental simulation that Simulation Theorists have in mind. Needless to say, this intuitive characterization of “mental simulation” is loose. What exactly does it mean to say that a mental state is a mental simulation of another mental state? Clearly, we need a precise answer to this question, if the notion of mental simulation is to be the fundamental building block of a theory. Simulation Theorists, however, differ over how to answer this question. The central divide concerns whether “mental simulation” should be defined in terms of resemblance (Heal 1986, 2003; Goldman 2006, 2008a) or in terms of reuse (Hurley 2004, 2008; Gallese & Sinigaglia 2011). We consider these two proposals in turn. The simplest interpretation of “mental simulation” in terms of resemblance goes like this: (RES-1) Token state M* is a mental simulation of token state M if and only if: Two clarifications are in order. First, we will elaborate on the “significant respects” in which a mental state has to resemble another mental state in due course (see, in particular,  section 3).  For the moment, it will suffice to mention some relevant dimensions of resemblance: similar functional role; similar content; similar phenomenology; similar neural basis (an important discussion of this topic is Fisher 2006). Second, RES-1 defines “mental simulation” as a dyadic relation between mental states (the relation being a mental simulation of). However, the expression “mental simulation” is also often used to pick out a monadic property of mental states —the property being a simulated mental state (as will become clear soon, “simulated mental state” does not refer here to the state which is simulated, but to the state that does the simulating). For example, it is common to find in the literature sentences like “M* is a mental simulation”. To avoid ambiguities, we shall adopt the following terminological conventions: It follows from this that, strictly speaking,  RES-1  is a definition of “mental simulation of”. Throughout this entry, we shall characterize “simulated mental state” in terms of “mental simulation of”: we shall say that if M* is a mental simulation of M, then M* is a simulated mental  state.[1] With these clarifications in place, we will consider the strengths and weaknesses of  RES-1.  Suppose that Lisa is seeing a yellow banana. At the present moment, there is no yellow banana in my own surroundings; thus, I cannot have that (type of) visual experience. Still, I can visualize what Lisa is seeing. Intuitively, my visual imagery of a yellow banana is a mental simulation of Lisa’s visual experience.  RES-1  captures this, given that both my visual imagery and Lisa’s visual experience are mental states and the former resembles the latter. RES-1,  however, faces an obvious problem (Goldman 2006). The resemblance relation is symmetric: for any x and y, if x resembles y, then y resembles x. Accordingly, it follows from  RES-1  that Lisa’s visual experience is a mental simulation of my visual imagery. But this is clearly wrong. There is no sense in which one person’s perceptual experience can be a mental simulation of another person’s mental imagery (see Ramsey 2010 for other difficulties with  RES-1). In order to solve this problem, Goldman (2006) proposes the following resemblance-based definition of “mental simulation of”: (RES-2) Token state M* is a mental simulation of token state M if and only if: Under the plausible assumption that one of the functions of visual imagery is to resemble visual experiences, RES-2 correctly predicts that my visual imagery of a yellow banana counts as a mental simulation of Lisa’s visual experience. At the same time, since visual experiences do not have the function of resembling visual images, RES-2 does not run into the trouble of categorizing the former as a mental simulation of the latter. Clearly,  RES-2  is a better definition of “mental simulation of” than  RES-1.  Hurley (2008), however, argued that it won’t do either, since it fails to distinguish ST from its main competitor, i.e., the Theory-Theory (TT), according to which mindreading depends on a body of information about mental states and processes  (section 5).  The crux of Hurley’s argument is this. Suppose that a token visual image V* resembles a token visual experience V and, in doing so, fulfils one of its functions. In this case,  RES-2  is satisfied. But now suppose further that visualization works like a computer simulation: it generates its outputs on the basis of a body of information about vision. On this assumption,  RES-2  still categorizes V* as a mental simulation of V, even though V* has been generated by exactly the kind of process described by TT: a theory-driven and information-rich process. According to Hurley (who follows here a suggestion by Currie & Ravenscroft 2002), the solution to this difficulty lies in the realization that “the fundamental … concept of simulation is reuse, not resemblance” (Hurley 2008: 758, emphasis added). Hurley’s reuse-based definition of “mental simulation of” can be articulated as follows: (REU) Token state M* is a mental simulation of token state M if and only if: To have a full understanding of REU, we need to answer three questions: (a) What is a cognitive process? (b) What is a cognitive mechanism? (c) What is the difference between using and reusing a certain cognitive mechanism? Let’s do it! It is a commonplace that explanation in cognitive science is structured into different levels. Given our aims, we can illustrate this idea through the classical tri-level hypothesis formulated by David Marr (1982). Suppose that one wants to explain a certain cognitive capacity, say, vision (or mindreading, or moral judgment). The first level of explanation, the most abstract one, consists in describing what the cognitive capacity does—what task it performs, what problem it solves, what function it computes. For example, the task performed by vision is roughly “to derive properties of the world from images of it” (Marr 1982: 23). The second level of analysis specifies how the task is accomplished: what algorithm our mind uses to compute the function. Importantly, this level of analysis abstracts from the particular physical structures that implement the algorithm in our head. It is only at the third level of analysis that the details of the physical implementation of the algorithm in our brain are spelled out. With these distinctions at hand, we can answer questions (a) and (b). A cognitive process is a cognitive capacity considered as an information-processing activity and taken in abstraction from its physical implementation. Thus, cognitive processes are individuated in terms of what function they perform and/or in terms of what algorithms compute these functions (fair enough, the “and/or” is a very big deal, but it is something we can leave aside here). This means that the same (type of) cognitive process can be multiply realized in different physical structures. For example, parsing (roughly, the cognitive process that assigns a grammatical structure to a string of signs) can be implemented both by a human brain and a computer. On the contrary, cognitive mechanisms are particular (types of) physical structures—e.g., a certain part of the brain—implementing certain cognitive processes. More precisely, cognitive mechanisms are organized structures carrying out cognitive processes in virtue of how their constituent parts interact (Bechtel 2008; Craver 2007; Machamer et al. 2000). We now turn to question (c), which concerns the distinction between use and reuse of a cognitive mechanism. At a first approximation, a cognitive mechanism is used when it performs its primary function, while it is reused when it is activated to perform a different, non-primary function. For example, one is using one’s visual mechanism when one employs it to see, while one is reusing it when one employs it to conjure up a visual image (see Anderson 2008, 2015 for further discussion of the notion of reuse). All this is a bit sketchy, but it will do. Let’s now go back to  REU.  The main idea behind it is that whether a mental state is a mental simulation of another mental state depends on the cognitive processes generating these two mental states, and on the cognitive mechanisms implementing such cognitive processes. More precisely, in order for mental state M* to be a mental simulation of mental state M, it has to be case that: (i) cognitive processes P* and P, which respectively generate M* and M, are both implemented by the same (type of) cognitive mechanism C; (ii) P is implemented by the use of C, while P* is implemented by the reuse of C. Now that we know what  REU  means, we can consider whether it fares better than  RES-2  in capturing the nature of the relation of mental simulation. It would seem so. Consider this hypothetical scenario. Lisa is seeing a yellow banana, and her visual experience has been generated by cognitive process V1, which has been implemented by the use of her visual mechanism. I am visualizing a yellow banana, and my visual image has been generated by cognitive process V2, which has been implemented by the reuse of my visual mechanism. Rosanna-the-Super-Reasoner is also visualizing a yellow banana, but her visual image has been generated by an information-rich cognitive process: a process drawing upon Rosanna’s detailed knowledge of vision and implemented by her incredibly powerful reasoning mechanism.  REU  correctly predicts that my visual image is a mental simulation of Lisa’s visual experience, but not vice versa. More importantly, it also predicts that Rosanna’s visual image does not count as a mental simulation of Lisa’s visual experience, given that Rosanna’s cognitive process was not implemented by the reuse of the visual mechanism. In this way,  REU  solves the problem faced by  RES-2  in distinguishing ST from TT. Should we then conclude that “mental simulation of” has to be defined in terms of reuse, rather than in terms of resemblance? Goldman (2008a) is still not convinced. Suppose that while Lisa is seeing a yellow banana, I am using my visual mechanism to visualize the Golden Gate Bridge. Now, even though Lisa’s visual experience and my visual image have been respectively generated by the use and the reuse of the visual mechanism, it would be bizarre to say that my mental state is a mental simulation of Lisa’s. Why? Because my mental state doesn’t resemble Lisa’s (she is seeing a yellow banana; I am visualizing the Golden Gate Bridge!) Thus—Goldman concludes—resemblance should be taken as the central feature of mental simulation. In order to overcome the difficulties faced by trying to define “mental simulation of” in terms of either replication or reuse, philosophers have built on the insights of both RES and  REU  and have proposed definitions that combine replication and reuse elements (Currie & Ravenscroft 2002; in recent years, Goldman himself seems to have favoured a mixed account; see Goldman 2012a). Here is one plausible definition: (RES+REU) Token state M* is a mental simulation of token state M if and only if: RES+REU has at least three important virtues. The first is that it solves all the aforementioned problems for RES and  REU—we  leave to the reader the exercise of showing that this is indeed the case. The second is that it fits nicely with an idea that loomed large in the simulationist literature: the idea that simulated mental states are “pretend” (“as if”, “quasi-”) states—imperfect copies of, surrogates for, the “genuine” states normally produced by a certain cognitive mechanism, obtained by taking this cognitive mechanism “off-line”. Consider the following case. Frank is in front of Central Café (and believes that he is there). He desires to drink a beer and believes that he can buy one at Central Café. When he feeds these mental states into his decision-making mechanism, the mechanism implements a decision-making process, which outputs the decision to enter the café. In this case, Frank’s decision-making mechanism was “on-line”—i.e., he used it; he employed it for its primary function. My situation is different. I don’t believe I am in front of Central Café, nor do I desire to drink a beer right now. Still, I can imagine believing and desiring so. When I feed these imagined states into my decision-making mechanism, I am not employing it for its primary function. Rather, I am taking it off-line (I am reusing it). As a result, the cognitive process implemented by my mechanism will output a merely imagined decision to enter the café. Now, it seems fair to say that my imagined decision resembles Frank’s decision (more on this in  section 3).  If you combine this with how these two mental states have been generated, the result is that my imagined decision is a mental simulation of Frank’s decision, and thus it is a simulated mental state. It is also clear why Frank’s decision is genuine, while my simulated mental state is just a pretend decision: all else being equal, Frank’s decision to enter Central Café will cause him to enter the café; on the contrary, no such behaviour will result from my simulated decision. I have not really decided so. Mine was just a quasi-decision—an imperfect copy of, a surrogate for, Frank’s genuine decision. And here is  RES+REU’s  third virtue. So far, we have said that “mental simulation” can either pick out a dyadic relation between mental states or a monadic property of mental states. In fact, its ambiguity runs deeper than this, since philosophers and cognitive scientists also use “mental simulation” to refer to a monadic property of cognitive processes, namely, the property being a (mental) simulation process (or: “process of mental simulation”, “simulational process”, “simulative process”, etc.) As a first stab, a (mental) simulation process is a cognitive process generating simulated mental states.  RES+REU  has the resources to capture this usage of “mental simulation” too. Indeed,  RES+REU implicitly contains the following definition of “simulation process”: (PROC): Token process P* is a (mental) simulation process if and only if: Go back to the case in which Lisa was having a visual experience of a yellow banana, while I was having a visual image of a yellow banana. Our two mental states resembled one another, but different cognitive processes generated them: seeing in Lisa’s case, and visualizing in my case. Moreover, Lisa’s seeing was implemented by the use of the visual mechanism, while my visualizing was implemented by its reuse. According to PROC, the latter cognitive process, but not the former, was thus a simulation process. To sum up,  RES+REU  captures many of the crucial features that Simulation Theorists ascribe to mental simulation. For this reason, we shall adopt it as our working definition of “mental simulation of”—consequently, we shall adopt PROC as a definition of “simulated mental  state”.[2]  We can put this into a diagram. Figure 1 The hexagon at the bottom depicts a cognitive mechanism C (it could be, say, the visual mechanism). When C is used (arrow on the left), it implements cognitive process P (say, seeing); when it is re-used (arrow on the right), it implements cognitive process P* (say, visualizing). P generates mental state M (say, a visual experience of a red tomato), while P* generates mental state M* (say, a visual image of a red tomato). These two mental states (M and M*) resemble one another. Given this: M* is a mental simulation of M; M* is a simulated mental state; and P* is a simulation  process.[3] In this section, we shall finally consider three worries raised for adopting  RES+REU  as a definition of “mental simulation of”. If you have already had enough of  RES+REU,  please feel free to move straight to  section 3. Heal (1994) pointed out a problem with committing ST to a particular account of the cognitive mechanisms that underlie it. Suppose that the human mind contains two distinct decision-making mechanisms: Mec1, which takes beliefs and desires as input, and generates decisions as output; and Mec2, which works by following exactly the same logical principles as Mec1, but takes imagined beliefs and imagined desires as input and generates imagined decisions as output. Consider again Frank’s decision to enter Central Café and my imagined decision to do so. According to the two mechanisms hypothesis, Frank desired to drink a beer and believed that he could buy one at Central Café, fed these mental states into Mec1, which generated the decision to enter the café. As for me, I fed the imagined desire to drink a beer and the imagined belief that I could buy one at Central Café into a distinct (type of) mechanism, i.e., Mec2, which generated the imagined decision to enter Central Café. Here is the question: does my imagined decision to enter Central Café count as a mental simulation of Frank’s decision to do so? If your answer is “Yes, it does”, then  RES+REU  is in trouble, since my imagined decision was not generated by reusing the same (type of) cognitive mechanism that Frank used to generate his decision; his decision was generated by Mec1, my imagined decision by Mec2. Thus, Heal concludes, a definition “mental simulation of” should not contain any commitment about cognitive mechanisms—it should not make any implementation claim—but should be given at a more abstract level of description. In the face of this difficulty, a defender of  RES+REU  can say the following. First, she might reject the intuition that, in the two mechanisms scenario, my imagined decision counts as a mental simulation of Frank’s decision. At a minimum, she might say that this scenario does not elicit any robust intuition in one direction or the other: it is not clear whether these two mental states stand in the relation being a mental simulation of. Second, she might downplay the role of intuitions in the construction of a definition for “mental simulation of” and cognate notions. In particular, if she conceives of ST as an empirical theory in cognitive science, she will be happy to discount the evidential value of intuitions if countervailing theoretical considerations are available. This, e.g., is Currie and Ravenscroft’s (2002) position, who write that there are two reasons … why the Simulation Theorist should prefer [a one mechanism hypothesis]: … first, the postulation of two mechanisms is less economical than the postulation of one; second, … we have very good reasons to think that imagination-based decision making does not operate in isolation from the subject’s real beliefs and desires. … If imagination and belief operate under a system of inferential apartheid—as the two-mechanisms view has it—how could this happen? (Currie & Ravenscroft 2002: 67–68) A second worry has to do with the fact that  RES+REU  appears to be too liberal. Take this case. Yesterday, Angelina had the visual experience of a red apple. On the night of June 15, 1815, Napoleon conjured up the visual image of a red apple. Angelina used her visual mechanism to see, while Napoleon reused his to imagine. If we add to this that Napoleon’s mental state resembled Angelina’s,  RES+REU  predicts that Napoleon’s (token) visual image was a mental simulation of Angelina’s (token) visual experience. This might strike one as utterly bizarre. In fact, not only did Napoleon not intend to simulate Angelina’s experience: he could not even have intended to do it. After all, Angelina was born roughly 150 years after Napoleon’s death. By the same token, it is also impossible that Napoleon’s visual image has been caused by Angelina’s visual experience. As a matter of fact, the visual image Napoleon had on the night of June 15, 1815 is entirely disconnected from the visual experience that Angelina had yesterday. Thus, how could the former be a mental simulation of the latter? If you think about it, the problem is even worse than this.  RES+REU  has it that Napoleon’s visual image of a red apple is a mental simulation of all the visual experiences of a red apple that have obtained in the past, that are currently obtaining, and that will obtain in the future. Isn’t that absurd? Again, a defender of  RES+REU  can give a two-fold answer. First, she can develop an argument that this is not absurd at all. Intuitively, the following principle seems to be true: (TYPE): the mental state type visual image of a red apple is a mental simulation of the mental state type visual experience of a red apple. If TYPE is correct, then the following principle has to be true as well: (TOKEN): Any token mental state of the type visual image of a red apple is a mental simulation of every token mental state of the type visual experience of a red apple. But TOKEN entails that Napoleon’s (token) visual image of a red apple is a mental simulation of Angelina’s (token) visual experience of a red apple, which is exactly what  RES+REU  predicts. Thus,  RES+REU’s  prediction, rather than being absurd, independently follows from quite intuitive assumptions. Moreover, even though TOKEN and  RES+REU  make the same prediction about the Napoleon-Angelina case, TOKEN is not entailed by  RES+REU,  since the latter contains a restriction on how visual images have to be generated. Thus, if one finds TOKEN intuitively acceptable, it is hard to see how one can find  RES+REU  to be too liberal. The second component of the answer echoes one of the answers given to Heal: for a Simulation Theorist who conceives of ST as a theory in cognitive science, intuitions have a limited value in assessing a definition of “mental simulation of”. In fact, the main aim of this definition is not that of capturing folk intuitions, but rather that of offering a clear enough picture of the relation of mental simulation on the basis of which an adequate theory of mindreading can be built. So, if the proposed definition fails, say, to help distinguishing ST from TT, or is of limited use in theory-building, or is contradicted by certain important results from cognitive science, then one has a good reason to abandon it. On the contrary, it should not be a cause for concern if  RES+REU  does not match the folk concept MENTAL SIMULATION OF. The notion “mental simulation of” is a term of art—like, say, the notions of I-Language or of Curved Space. These notions do poorly match the folk concepts of language and space, but linguists and physicists do not take this to be a problem. The same applies to the notion of mental simulation. And here is the third and final worry.  RES+REU  is supposed to be a definition of “mental simulation of” on the basis of which a theory of mindreading can be built. However, neither  RES+REU  nor  PROC  make any reference to the idea of representing others’ mental states. Thus, how could these definitions help us to construct a Simulation Theory of mindreading? The answer is simple: they will help us exactly as a clear definition of “computation”, which has nothing to do with how the mind works, helped to develop the Computational Theory of Mind (see entry on  computational theory of mind). Here is another way to make the point. ST is made up of two distinct claims: the first is that mental simulation is psychologically real, i.e., that there are mental states and processes satisfying  RES+REU  and  PROC.  The second claim is that mental simulation plays a central role in mindreading. Clearly, the second claim cannot be true if the first is false. However, the second claim can be false even if the first claim is true: mental simulation could be psychologically real, but play no role in mindreading at all. Hence, Simulation Theorists have to do three things. First, they have to establish that mental simulation is psychologically real. We consider this issue in  section 3.  Second, they have to articulate ST as a theory of mindreading. That is, they have to spell out in some detail the crucial role that mental simulation is supposed to play in representing others’ mental states, and contrast the resulting theory with other accounts of mindreading. We dwell on this in sections  4  and  5.  Finally, Simulation Theorists have to provide evidence in support of their theory of mindreading—that is, they have to give us good reasons to believe that mental simulation does play a crucial role in representing others’ mental states. We discuss this issue in  section 6.