{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_directory = '/home/meeka/Desktop/NU/453/assn2/philosophy/corpus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Classes to label corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create vocabulary sets for class divisions\n",
    "\n",
    "logic=['logic', 'logical', 'logics', 'syllogism', 'syllogisms', 'model']\n",
    "mathematics=['mathematics','mathematical', 'number', 'set', 'sets', 'probability','probabilities', 'proof']\n",
    "language=['language', 'linguistic', 'sentences', 'sentence', 'proposition', 'propositions', 'verb', 'verbs',\n",
    "         'discourse', 'word', 'words']\n",
    "mind=['cognition', 'cognitive', 'consciousness', 'thought', 'thoughts','knowledge', 'know', 'mental', \n",
    "        'perception', 'neural', 'brain', 'mind', 'selfknowledge']\n",
    "ontology=['objects', 'object', 'truth', 'abstract', 'abstraction', 'phenomenal', 'phenomenology',\n",
    "             'representation', 'representational', 'representations', 'experience', 'experiences']\n",
    "ethics=['ethics', 'ethical', 'moral', 'morality', 'religion']\n",
    "\n",
    "top_vocab=[]\n",
    "\n",
    "def merge_list(group):\n",
    "    for word in group:\n",
    "        top_vocab.append(word)\n",
    "\n",
    "merge_list(logic)\n",
    "merge_list(mathematics)\n",
    "merge_list(language)\n",
    "merge_list(mind)\n",
    "merge_list(ontology)\n",
    "merge_list(ethics)\n",
    "\n",
    "len(top_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dict of entire corpus\n",
    "\n",
    "def load_doc(filename):\n",
    "    file=open(filename, 'r')\n",
    "    text=file.read()\n",
    "    file.close()\n",
    "    return text    \n",
    "\n",
    "def clean_doc(doc):\n",
    "    tokens=doc.split()\n",
    "    tokens=[word.lower() for word in tokens]\n",
    "    re_punc=re.compile('[%s]'% re.escape(string.punctuation))\n",
    "    tokens=[re_punc.sub('',w) for w in tokens]\n",
    "    tokens=[word for word in tokens if word.isalpha()]\n",
    "    stop_words=set(stopwords.words('english'))\n",
    "    tokens=[word for word in tokens if not word in stop_words]\n",
    "    tokens=[word for word in tokens if len(word)>2]\n",
    "    return tokens\n",
    "\n",
    "def process_docs(directory):\n",
    "    for filename in listdir(directory):\n",
    "        path=directory+'/'+filename\n",
    "        doc=load_doc(path)\n",
    "        tokens=clean_doc(doc)\n",
    "        #process lists, counters, dicts:\n",
    "        vocab.update(tokens)\n",
    "        wordcount=Counter(tokens)\n",
    "        corpus_dict_top5[filename]=wordcount.most_common(5)\n",
    "        line= ' '.join(tokens)\n",
    "        corpus_dict_sent[filename]=line\n",
    "        vocab_tokens=[word for word in tokens if word in top_vocab]\n",
    "        vocabcount=Counter(vocab_tokens)\n",
    "        corpus_vdict[filename]=vocabcount\n",
    "\n",
    "def save_list(lines, filename):\n",
    "    data='\\n'.join(lines)\n",
    "    file=open(filename, 'w')\n",
    "    file.write(data)\n",
    "    file.close()\n",
    "\n",
    "vocab=Counter()\n",
    "\n",
    "#Top 5 words in each document for categorization\n",
    "corpus_dict_top5={}\n",
    "#Dict with top wordcounts for top vocab 6 group categorization list\n",
    "corpus_vdict={}\n",
    "#Dict with full length sentences\n",
    "corpus_dict_sent={}\n",
    "\n",
    "process_docs(corpus_directory)\n",
    "\n",
    "min_occurrence=50\n",
    "vocab=[k for k,c in vocab.items() if c >= min_occurrence]\n",
    "save_list(vocab, 'vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mind           189\n",
       "logic          139\n",
       "ontology       135\n",
       "language       128\n",
       "mathematics     95\n",
       "ethics          55\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create subset for class labels, merge with main corpus to align docs with classes\n",
    "\n",
    "def group_dfs(group):\n",
    "    group_set={}\n",
    "    for k,v in corpus_dict_top5.items():\n",
    "        for name, count in v:\n",
    "            if name in group:\n",
    "                group_set[k]=v\n",
    "    dkeys=[]\n",
    "    dvals=[]\n",
    "    for x,y in group_set.items():\n",
    "        dkeys.append(x)\n",
    "        dv=[]\n",
    "        for item in y:\n",
    "            dv.append(str(item[0]+'-'+str(item[1])))\n",
    "        dvals.append(dv)\n",
    "    headers=[]\n",
    "    for x in range(1,6):\n",
    "        label=str('word'+str(x))\n",
    "        headers.append(label)\n",
    "    newdf=pd.DataFrame(dvals, columns=headers, index=dkeys)\n",
    "    return newdf\n",
    "\n",
    "logic_df=group_dfs(logic)\n",
    "mathematics_df=group_dfs(mathematics)\n",
    "language_df=group_dfs(language)\n",
    "mind_df=group_dfs(mind)\n",
    "ontology_df=group_dfs(ontology)\n",
    "ethics_df=group_dfs(ethics)\n",
    "\n",
    "logic_df['class']='logic'\n",
    "mathematics_df['class']='mathematics'\n",
    "language_df['class']='language'\n",
    "mind_df['class']='mind'\n",
    "ontology_df['class']='ontology'\n",
    "ethics_df['class']='ethics'\n",
    "\n",
    "frames=[logic_df, mathematics_df, language_df, mind_df, ontology_df, ethics_df]\n",
    "full_df=pd.concat(frames)\n",
    "full_df=full_df.reset_index()\n",
    "full_df=full_df.rename(columns={\"index\":\"document\"})\n",
    "full_df.to_csv('full_concat.csv')\n",
    "    \n",
    "full_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full df shape:  (741, 7)\n",
      "unique docs shape:  (482, 7)\n",
      "dups docs shape:  (259, 7)\n",
      "\n",
      "Value counts of unique docs:\n",
      "mind           141\n",
      "logic           84\n",
      "ontology        75\n",
      "language        72\n",
      "mathematics     66\n",
      "ethics          44\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Identify Dups, separate datasets:\n",
    "\n",
    "dups=full_df.duplicated(subset=['document'])\n",
    "df_dup=pd.concat([full_df['document'], dups],axis=1, join='inner')\n",
    "df_dup=df_dup.rename(columns={0:'duplicate'})\n",
    "df_dup=df_dup[df_dup.duplicate]\n",
    "\n",
    "duplist=df_dup.document.to_list()\n",
    "uniquedocs=full_df[~full_df.document.isin(duplist)]\n",
    "dupdocs=full_df[full_df.document.isin(duplist)]\n",
    "\n",
    "print('full df shape: ', full_df.shape)\n",
    "print('unique docs shape: ', uniquedocs.shape)\n",
    "print('dups docs shape: ', dupdocs.shape)\n",
    "print('\\nValue counts of unique docs:')\n",
    "print(uniquedocs['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final corpus shape:  (546, 7)\n",
      "final corpus counts: \n",
      "\n",
      "mind           141\n",
      "logic           84\n",
      "ontology        75\n",
      "language        72\n",
      "mathematics     66\n",
      "ethics          44\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Clean duplicate docs based on first word assignment to category\n",
    "\n",
    "docfilter=dupdocs.drop_duplicates(subset='document').copy(deep=True)\n",
    "docfilter2=docfilter.copy(deep=True)\n",
    "docfilter2[['word1w','word1c']]=docfilter2.word1.str.split(\"-\",expand=True)\n",
    "\n",
    "keepcols=['document','word1w']\n",
    "primaryword=docfilter2.filter(items=keepcols, axis=1).copy(deep=True)\n",
    "\n",
    "NaN=np.nan\n",
    "primaryword['class']=NaN\n",
    "\n",
    "def firstword(group, name):\n",
    "    for i in range(len(primaryword)):\n",
    "        for word in group:\n",
    "            if primaryword.iloc[i,1]==word:\n",
    "                primaryword.iloc[i,2]=name\n",
    "\n",
    "firstword(logic, 'logic')\n",
    "firstword(mathematics, 'math')\n",
    "firstword(language, 'language')\n",
    "firstword(mind, 'mental')\n",
    "firstword(ontology, 'ontology')\n",
    "firstword(ethics, 'ethics')\n",
    "\n",
    "primaryword.dropna(subset=['class'], inplace=True)\n",
    "docfilter=docfilter.drop(columns=['class'])\n",
    "uniquefiltered=pd.concat([docfilter, primaryword['class']],axis=1, join='inner')\n",
    "uniquefiltered.shape\n",
    "\n",
    "frames=[uniquedocs, uniquefiltered]\n",
    "final_corpus_df=pd.concat(frames)\n",
    "print('final corpus shape: ', final_corpus_df.shape)\n",
    "print('final corpus counts: \\n')\n",
    "print(uniquedocs['class'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Part 1:  Analyst Judgement vs TfIdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1: Analyst Judgment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selfknowledge</th>\n",
       "      <th>knowledge</th>\n",
       "      <th>thought</th>\n",
       "      <th>cognitive</th>\n",
       "      <th>mental</th>\n",
       "      <th>know</th>\n",
       "      <th>thoughts</th>\n",
       "      <th>consciousness</th>\n",
       "      <th>phenomenal</th>\n",
       "      <th>experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Self Knowledge_1 The Distinctiveness of SelfKnowledge.txt</th>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Folk Psychology as Mental Simulation_7 Conclusion.txt</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gertrude Elizabeth Margaret Anscombe_3 Metaphysics.txt</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consciousness and Intentionality_8 Consciousness in Mind.txt</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thomas Reid_6 Moral Philosophy.txt</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Folk Psychology as Mental Simulation_6 Simulation Theory Pros and Cons.txt</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Narrow Mental Content_3 Arguments for Narrow Content.txt</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Externalism About Mental Content_6 Externalism and Selfknowledge.txt</th>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Self Knowledge_2 Doubts about the distinctiveness of selfknowledge.txt</th>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Self Knowledge_3 Accounts of SelfKnowledge.txt</th>\n",
       "      <td>73.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    selfknowledge  knowledge  \\\n",
       "Self Knowledge_1 The Distinctiveness of SelfKno...           18.0        5.0   \n",
       "Folk Psychology as Mental Simulation_7 Conclusi...            1.0        1.0   \n",
       "Gertrude Elizabeth Margaret Anscombe_3 Metaphys...            1.0        NaN   \n",
       "Consciousness and Intentionality_8 Consciousnes...            1.0        NaN   \n",
       "Thomas Reid_6 Moral Philosophy.txt                            1.0        4.0   \n",
       "Folk Psychology as Mental Simulation_6 Simulati...            2.0        6.0   \n",
       "Narrow Mental Content_3 Arguments for Narrow Co...            1.0        1.0   \n",
       "Externalism About Mental Content_6 Externalism ...           15.0       11.0   \n",
       "Self Knowledge_2 Doubts about the distinctivene...           10.0        5.0   \n",
       "Self Knowledge_3 Accounts of SelfKnowledge.txt               73.0       31.0   \n",
       "\n",
       "                                                    thought  cognitive  \\\n",
       "Self Knowledge_1 The Distinctiveness of SelfKno...      2.0        1.0   \n",
       "Folk Psychology as Mental Simulation_7 Conclusi...      NaN        3.0   \n",
       "Gertrude Elizabeth Margaret Anscombe_3 Metaphys...      1.0        NaN   \n",
       "Consciousness and Intentionality_8 Consciousnes...     10.0        5.0   \n",
       "Thomas Reid_6 Moral Philosophy.txt                      2.0        NaN   \n",
       "Folk Psychology as Mental Simulation_6 Simulati...      NaN        4.0   \n",
       "Narrow Mental Content_3 Arguments for Narrow Co...      5.0        NaN   \n",
       "Externalism About Mental Content_6 Externalism ...      7.0        NaN   \n",
       "Self Knowledge_2 Doubts about the distinctivene...      4.0        1.0   \n",
       "Self Knowledge_3 Accounts of SelfKnowledge.txt          4.0        6.0   \n",
       "\n",
       "                                                    mental  know  thoughts  \\\n",
       "Self Knowledge_1 The Distinctiveness of SelfKno...    19.0   3.0       6.0   \n",
       "Folk Psychology as Mental Simulation_7 Conclusi...     2.0   NaN       NaN   \n",
       "Gertrude Elizabeth Margaret Anscombe_3 Metaphys...     NaN   NaN       NaN   \n",
       "Consciousness and Intentionality_8 Consciousnes...     6.0   1.0       1.0   \n",
       "Thomas Reid_6 Moral Philosophy.txt                     2.0   1.0       NaN   \n",
       "Folk Psychology as Mental Simulation_6 Simulati...    25.0   2.0       NaN   \n",
       "Narrow Mental Content_3 Arguments for Narrow Co...    10.0   NaN      10.0   \n",
       "Externalism About Mental Content_6 Externalism ...     1.0   9.0      14.0   \n",
       "Self Knowledge_2 Doubts about the distinctivene...     8.0   7.0       NaN   \n",
       "Self Knowledge_3 Accounts of SelfKnowledge.txt        49.0  15.0       8.0   \n",
       "\n",
       "                                                    consciousness  phenomenal  \\\n",
       "Self Knowledge_1 The Distinctiveness of SelfKno...            1.0         2.0   \n",
       "Folk Psychology as Mental Simulation_7 Conclusi...            NaN         NaN   \n",
       "Gertrude Elizabeth Margaret Anscombe_3 Metaphys...            NaN         NaN   \n",
       "Consciousness and Intentionality_8 Consciousnes...           27.0         5.0   \n",
       "Thomas Reid_6 Moral Philosophy.txt                            NaN         NaN   \n",
       "Folk Psychology as Mental Simulation_6 Simulati...            NaN         NaN   \n",
       "Narrow Mental Content_3 Arguments for Narrow Co...            NaN        23.0   \n",
       "Externalism About Mental Content_6 Externalism ...            NaN         NaN   \n",
       "Self Knowledge_2 Doubts about the distinctivene...            NaN         NaN   \n",
       "Self Knowledge_3 Accounts of SelfKnowledge.txt                4.0        12.0   \n",
       "\n",
       "                                                    experience  \n",
       "Self Knowledge_1 The Distinctiveness of SelfKno...         2.0  \n",
       "Folk Psychology as Mental Simulation_7 Conclusi...         NaN  \n",
       "Gertrude Elizabeth Margaret Anscombe_3 Metaphys...         NaN  \n",
       "Consciousness and Intentionality_8 Consciousnes...         2.0  \n",
       "Thomas Reid_6 Moral Philosophy.txt                         1.0  \n",
       "Folk Psychology as Mental Simulation_6 Simulati...         1.0  \n",
       "Narrow Mental Content_3 Arguments for Narrow Co...         5.0  \n",
       "Externalism About Mental Content_6 Externalism ...         NaN  \n",
       "Self Knowledge_2 Doubts about the distinctivene...         1.0  \n",
       "Self Knowledge_3 Accounts of SelfKnowledge.txt            11.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_texts=final_corpus_df['document']\n",
    "final_texts=final_texts.to_list()\n",
    "\n",
    "final_vcorpus={}\n",
    "\n",
    "for k,v in corpus_vdict.items():\n",
    "    for word in final_texts:\n",
    "        if k == word:\n",
    "            final_vcorpus[k]=v\n",
    "\n",
    "vocab_matrix=pd.DataFrame.from_dict(final_vcorpus, orient='index')\n",
    "vocab_matrix.to_csv('vocab_matrix_analyst.csv')\n",
    "vocab_matrix.iloc[:10,:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2: TfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(546, 2901)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "final_corpus=[]\n",
    "final_labels=[]\n",
    "\n",
    "for k,v in corpus_dict_sent.items():\n",
    "    for word in final_texts:\n",
    "        if k == word:\n",
    "            final_corpus.append(v)\n",
    "            final_labels.append(k)\n",
    "\n",
    "vectorizer=TfidfVectorizer(vocabulary=vocab)\n",
    "X=vectorizer.fit_transform(final_corpus)\n",
    "print(X.shape)\n",
    "\n",
    "feature_names=vectorizer.get_feature_names()\n",
    "corpus_index=[n for n in final_corpus]\n",
    "Tfidf_df_matrix=pd.DataFrame(X.todense(), index=final_labels, columns=feature_names)\n",
    "Tfidf_df_matrix.T.to_csv('vocab_matrix_tfidf.csv')\n",
    "\n",
    "Tfidf_df_matrix_topVocab=Tfidf_df_matrix[top_vocab]\n",
    "Tfidf_df_matrix_topVocab.iloc[:10,:10]\n",
    "Tfidf_df_matrix_topVocab.to_csv('Tfidf_df_matrix_topVocab.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis 2: Test Train Split & Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items in X set: 546 and items in y set: 546\n"
     ]
    }
   ],
   "source": [
    "#extract data from overall corpus and split into train test for modelling\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "doc_class_df=final_corpus_df[['document','class']]\n",
    "final_texts=doc_class_df.values.tolist()\n",
    "\n",
    "final_corpus_dict={}\n",
    "final_labels_dict={}\n",
    "final_analysis_dict={}\n",
    "\n",
    "for k,v in corpus_dict_sent.items():\n",
    "    for item in final_texts:\n",
    "        if k == item[0]:\n",
    "            final_corpus_dict[k]=v\n",
    "            final_labels_dict[k]=item[1]\n",
    "            final_analysis_dict[v]=item[1]\n",
    "\n",
    "X=list(final_analysis_dict.keys())\n",
    "y=list(final_analysis_dict.values())\n",
    "print('items in X set: %d and items in y set: %d' %(len(X), len(y)))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=100, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logic</th>\n",
       "      <th>logical</th>\n",
       "      <th>logics</th>\n",
       "      <th>syllogism</th>\n",
       "      <th>syllogisms</th>\n",
       "      <th>model</th>\n",
       "      <th>mathematics</th>\n",
       "      <th>mathematical</th>\n",
       "      <th>number</th>\n",
       "      <th>set</th>\n",
       "      <th>...</th>\n",
       "      <th>representation</th>\n",
       "      <th>representational</th>\n",
       "      <th>representations</th>\n",
       "      <th>experience</th>\n",
       "      <th>experiences</th>\n",
       "      <th>ethics</th>\n",
       "      <th>ethical</th>\n",
       "      <th>moral</th>\n",
       "      <th>morality</th>\n",
       "      <th>religion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mathematics</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mental</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mathematics</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mind</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ontology</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             logic  logical  logics  syllogism  syllogisms  model  \\\n",
       "mathematics      0        0       0          0           0      0   \n",
       "mental           0        1       0          0           0      1   \n",
       "mathematics      2        0       0          0           0      0   \n",
       "mind             1        0       0          0           0      0   \n",
       "ontology         0        0       0          0           0      0   \n",
       "\n",
       "             mathematics  mathematical  number  set  ...  representation  \\\n",
       "mathematics            0             1       2    6  ...               0   \n",
       "mental                 0             0       3    0  ...              17   \n",
       "mathematics            1             0       0   16  ...               0   \n",
       "mind                   1             0       0    0  ...               0   \n",
       "ontology               0             0       0    0  ...               0   \n",
       "\n",
       "             representational  representations  experience  experiences  \\\n",
       "mathematics                 0                0           0            0   \n",
       "mental                      1               28           0            0   \n",
       "mathematics                 0                0           0            0   \n",
       "mind                        0                0           2            1   \n",
       "ontology                    0                0           0            0   \n",
       "\n",
       "             ethics  ethical  moral  morality  religion  \n",
       "mathematics       0        0      0         0         0  \n",
       "mental            0        0      2         0         0  \n",
       "mathematics       0        0      0         0         0  \n",
       "mind              0        0      0         0         0  \n",
       "ontology          0        0      0         0         0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analysis 1: Judgment\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Analyst Dataframe\n",
    "analyst_vectorizer=CountVectorizer(vocabulary=top_vocab)\n",
    "X_train_analyst=analyst_vectorizer.fit_transform(X_train)\n",
    "X_train_analyst_df=pd.DataFrame(X_train_analyst.todense(), columns=analyst_vectorizer.get_feature_names(), index=y_train)\n",
    "X_test_analyst=analyst_vectorizer.fit_transform(X_test)\n",
    "X_train_analyst_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abelard</th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absence</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>abstract</th>\n",
       "      <th>abstraction</th>\n",
       "      <th>...</th>\n",
       "      <th>xyz</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yet</th>\n",
       "      <th>yield</th>\n",
       "      <th>yields</th>\n",
       "      <th>zalta</th>\n",
       "      <th>zero</th>\n",
       "      <th>zfc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mathematics</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mental</th>\n",
       "      <td>0.016249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.218344</td>\n",
       "      <td>0.026257</td>\n",
       "      <td>0.010218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087336</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mathematics</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mind</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ontology</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.354342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             abandoned  abelard  abilities   ability      able  absence  \\\n",
       "mathematics   0.000000      0.0   0.000000  0.000000  0.000000      0.0   \n",
       "mental        0.016249      0.0   0.218344  0.026257  0.010218      0.0   \n",
       "mathematics   0.000000      0.0   0.000000  0.000000  0.000000      0.0   \n",
       "mind          0.000000      0.0   0.000000  0.000000  0.000000      0.0   \n",
       "ontology      0.000000      0.0   0.000000  0.000000  0.000000      0.0   \n",
       "\n",
       "             absolute  absolutely  abstract  abstraction  ...  xyz  year  \\\n",
       "mathematics       0.0         0.0  0.000000          0.0  ...  0.0   0.0   \n",
       "mental            0.0         0.0  0.087336          0.0  ...  0.0   0.0   \n",
       "mathematics       0.0         0.0  0.000000          0.0  ...  0.0   0.0   \n",
       "mind              0.0         0.0  0.000000          0.0  ...  0.0   0.0   \n",
       "ontology          0.0         0.0  0.354342          0.0  ...  0.0   0.0   \n",
       "\n",
       "                years  yellow       yet  yield  yields     zalta  zero  zfc  \n",
       "mathematics  0.000000     0.0  0.000000    0.0     0.0  0.000000   0.0  0.0  \n",
       "mental       0.000000     0.0  0.016893    0.0     0.0  0.018481   0.0  0.0  \n",
       "mathematics  0.000000     0.0  0.000000    0.0     0.0  0.000000   0.0  0.0  \n",
       "mind         0.016821     0.0  0.037315    0.0     0.0  0.000000   0.0  0.0  \n",
       "ontology     0.000000     0.0  0.000000    0.0     0.0  0.000000   0.0  0.0  \n",
       "\n",
       "[5 rows x 3000 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analysis 2: Tf-Idf Dataframe\n",
    "\n",
    "#tfidf_vectorizer=TfidfVectorizer(max_features=1000)\n",
    "tfidf_vectorizer=TfidfVectorizer(max_features=3000)\n",
    "X_train_tfidf=tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf=tfidf_vectorizer.fit_transform(X_test)\n",
    "\n",
    "X_train_tfidf_df=pd.DataFrame(X_train_tfidf.todense(), columns=tfidf_vectorizer.get_feature_names(), index=y_train)\n",
    "X_train_tfidf_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis 3:  NN Embeddings (Doc2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(446, 50)\n",
      "(100, 50)\n"
     ]
    }
   ],
   "source": [
    "#Analysis 3: Doc2Vec\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.test.utils import get_tmpfile\n",
    "\n",
    "def tokenize_docs(X):\n",
    "    word_tokens=[]\n",
    "    for doc in X:\n",
    "        tokens=doc.split()\n",
    "        word_tokens.append(tokens)\n",
    "    return word_tokens\n",
    "    \n",
    "X_train_tokens=tokenize_docs(X_train)\n",
    "X_test_tokens=tokenize_docs(X_test)\n",
    "\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(X_train_tokens)]\n",
    "model_50dim = Doc2Vec(documents, vector_size=50, window=4, min_count=2, epochs=50)\n",
    "model_50dim.train(documents, total_examples = model_50dim.corpus_count, epochs = model_50dim.epochs)\n",
    "\n",
    "#Vectorize Training Set:\n",
    "doc2vec_50_vectors = np.zeros((len(X_train_tokens), 50)) \n",
    "for i in range(0, len(X_train_tokens)):\n",
    "    doc2vec_50_vectors[i,] = model_50dim.infer_vector(X_train_tokens[i]).transpose()\n",
    "print(doc2vec_50_vectors.shape)\n",
    "\n",
    "#Vectorize Test Set:\n",
    "doc2vec_50_vectors_test = np.zeros((len(X_test_tokens), 50))\n",
    "for i in range(0, len(X_test_tokens)):\n",
    "    doc2vec_50_vectors_test[i,] = model_50dim.infer_vector(X_test_tokens[i]).transpose()\n",
    "print(doc2vec_50_vectors_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Count/Random forest F1 classification performance in test set: 0.65\n",
      "\n",
      "TF-IDF/Random forest F1 classification performance in test set: 0.168\n",
      "\n",
      "Doc2Vec_50/Random forest F1 classification performance in test set: 0.506\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "count_clf = RandomForestClassifier(n_estimators = 100, max_depth = 10, random_state = 42)\n",
    "count_clf.fit(X_train_analyst, y_train)\n",
    "count_pred = count_clf.predict(X_test_analyst)\n",
    "print('\\nCount/Random forest F1 classification performance in test set:',\n",
    "    round(metrics.f1_score(y_test, count_pred, average='macro'), 3))\n",
    "\n",
    "#Tf-Idf\n",
    "tfidf_clf = RandomForestClassifier(n_estimators = 100, max_depth = 10, random_state = 42)\n",
    "tfidf_clf.fit(X_train_tfidf, y_train)\n",
    "tfidf_pred = tfidf_clf.predict(X_test_tfidf)\n",
    "print('\\nTF-IDF/Random forest F1 classification performance in test set:',\n",
    "    round(metrics.f1_score(y_test, tfidf_pred, average='macro'), 3))\n",
    "\n",
    "#Doc2Vec\n",
    "doc2vec_50_clf = RandomForestClassifier(n_estimators = 100, max_depth = 10, random_state = 42)\n",
    "doc2vec_50_clf.fit(doc2vec_50_vectors, y_train)\n",
    "doc2vec_50_pred = doc2vec_50_clf.predict(doc2vec_50_vectors_test)\n",
    "print('\\nDoc2Vec_50/Random forest F1 classification performance in test set:',\n",
    "    round(metrics.f1_score(y_test, doc2vec_50_pred, average='macro'), 3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Language Py3.7",
   "language": "python",
   "name": "language"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
