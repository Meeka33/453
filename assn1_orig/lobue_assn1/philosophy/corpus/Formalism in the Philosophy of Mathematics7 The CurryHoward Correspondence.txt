 Haskell Curry was also to play an important role in developments linking logic to computer science which some argue can lend support to formalism in mathematics. His work on combinatory logic along with work of W.A. Howard’s led to the ‘Curry-Howard correspondence’ (‘Curry-Howard’ henceforth written ‘CH’) or ‘CH isomorphism’ linking logic, proof theory and computer science. Curry intended to provide a general theory of functionality as part of a foundation for logic, “pre-logic”, as Curry called it. See in particular (Curry 1934) and, with Robert Feys, (Curry and Feys 1958). At around the same time as Curry’s first publications in the area, Alonzo Church developed his untyped \(\lambda\)-calculus, also designed to provide a foundation for logic, indeed mathematics more generally, and also taking functions, very generally applicable, as fundamental. In these functional calculi, (for a comprehensive account see Barendregt (1984), also the entry on  the lambda calculus)  a concatenation \(fg\) is used to represent the application of function \(f\) to argument \(g\) yielding an output value, where both argument and value can themselves be functions and where self-application is allowed. Whereas Curry’s system is variable-free, variable binding in Church’s occurs by means of the \(\lambda\) term, the variable \(x\) if and where it occurs in \(N\) being bound in \(\lambda x.N\). The fundamental operation in \(\lambda\)-calculus is \(\beta\)-reduction, the transformation which takes us from \((\lambda x.N)M\) to \(N[x := M].\) Here \(N[x := M]\) is the result of substituting \(M\) for all free occurrences of \(x\) in  \(N\).[1]  So, for example, \((\lambda x.xx)f\) \(\beta\)-reduces to \(ff\). We can write this as: Thus these calculi achieve what Wittgenstein in the Tractatus (see above) seems to be gesturing at in his operations/function distinction, for in Church and Curry we have a fully developed theory of ‘operations’, that is functions which can take functions as arguments and values. Of course self-application, as in the infinite looping \(\beta\)-reduction: raises worries that paradox may emerge. Church thought that eschewing the use of free variables and restricting excluded middle (Church, 1932: 346–7) blocked paradox but Kleene and Rosser showed (1935), using a strategy based on Richard’s paradox, that the system was trivial: every formula could be derived using the rules. Church fixed this up to produce a consistent untyped \(\lambda\) calculus, but the important step with regard to the CH correspondence was the development of typed \(\lambda\) calculi. Now ‘type’ is a very overworked word. Tokens of that type, to use one of its meanings (roughly as abstract syntactic object), have sometimes been used to stand for properties, including higher-order properties, as in Russell’s various type theories. Church was to continue this tradition in his simple typed version of \(\lambda\)-calculus (Church, 1940). In this usage, types, such as the property of caninity or of being a shape, have instances such as Fido, in the first case, or the lower-order property of being square in the second case. Thus instances of types in this sense need not be abstract entities. Another usage is syntactic, as when the basic expressions of a language are divided into various disjoint categories (‘types’) and formation rules for generating well-formed expressions are set down making use of the type distinctions. In this usage ‘type’ is an expression in the syntactic metatheory of the language of some object theory. In some cases the syntactic theory is in fact part of the object theory under discussion. Independently of this, some presentations of syntactic type theories ‘push down’ the syntactic metatheory into the object theory under discussion by stipulating that the well-formed expressions of the object language contain syntactic proper parts, tags as it were, which are correlated with the metatheoretic type of the expression and have no semantic role. In Howard (1969), for example, the well-formed formula of the conditional fragment of propositional logic are used as type symbols superscripting terms of the type theory. The expression «\(N: \tau\)» which is usually read along the lines of: can be, therefore, read in a number of ways, for example: I: Non-syntactic: the entity referred to by \(N\) is an instance of the class/set/property referred to by \(\tau\), an instance which need not be syntactic nor, more generally, abstract. II: Meta-syntactic: the expression referred to by \(N\) is an instance of the syntactic category \(\tau\). The syntactic theory in which the ascription of term to type occurs is ‘meta’, relative to a background intellectual context, in that it is not there presented as (under its intended interpretation) part of a more general, non-syntactic theory expressed in a language for which it itself provides the syntax. III: Syntactic: the expression \(N\) is an instance of the syntactic category \(\tau\) and the type theory \(is\) a syntactic theory for the language which it itself belongs to. Whilst some textbooks on type theory can seem, to the logician, to be rather hazy on exactly which, if any, of the above interpretations of ‘type’ is at issue this is certainly not generally the case with the pioneers of these theories. Howard, for example, writes in his classic paper ‘The Formula-as-Types Notion of Construction’: and distinguishes between types and type symbols (480). There are non-syntactic models of various type theories, though these were developed later, for example (Scott, 1970), and make fairly strong set-theoretic cardinality assumptions, such as the existence of inaccessible cardinals. Much more relevant for the formalist are ‘term models’, syntactic models similar to the interpretations of languages which make use of their own symbols as the members of the domain, interpretations to be found in Henkin completeness proofs; and especially ‘syntactic semantic’ approaches, as in some interpretations of Per Martin-Löf’s intuitionist type theory (see the entry on  intuitionistic type theory),  or the ‘proof-theoretic semantics’ of Peter Schroeder-Heister  (see the entry on proof-theoretic semantics)  which eschew attempts to give meanings to types and terms by reference to ‘external’ truth-conditions: mathematical language is not to be taken as a representation of some independent reality. In such a context, the distinction between meta-syntactic and syntactic readings of ‘type’ is not very important. Even if ‘type’ is taken to be a purely metatheoretic notion, the axioms and rules of inference of type theory enable us to prove meta-theorems about types. The situation can be compared to the relation between sequent calculus and natural deduction, with the turnstile \(\vdash\) of the former interpretable as a relation of derivability in some underlying natural deduction system, and the sequent calculus providing higher-order theorems about object language derivability. Thus whether or not one thinks of types as meta-theoretic notions, the calculi of type theory are such that one can prove theorems to the effect that term \(N\) is of type \(\tau\). Now Curry’s work in (1934) and more fully with Feys in (1958) had shown a certain correspondence between provable formulae in the theory of the conditional and the types of basic combinators in type theory. In particular, with \(\rightarrow\) as the conditional and \(\alpha \Rightarrow \beta\) representing function types, that is types (construed non-syntactically) whose inputs are type \(\alpha\) functions and outputs type \(\beta\) functions, we have, (here \(\vdash_{T\rightarrow}\) means provability in the positive (non-relevantist) theory of the conditional and \(\vdash_{CL}\) means provability in a suitable combinatory logic): where \(N\) is a term built from basic combinators and \(\alpha\) is structurally isomorphic to A (likewise \(\beta\) to B). That is, one can generate A \(\Rightarrow\) B from A \(\rightarrow\) B by replacing each occurrence of \(\rightarrow\) by \(\Rightarrow\), given a uniform substitution (perhaps the trivial identity one) of sentential letters in the formulae of the propositional language by names for basic types. Curry and Feys (1958) extended the correspondence idea to one between type theory and Gentzen’s sequent calculus. In the paper already cited, circulated in 1969, but only published in a volume in a Festschrift for Curry in 1980, W.A. Howard (1969) deepened the CH correspondence by demonstrating a correspondence between intuitionistic sequent form natural deduction and type theory in \(\lambda\)-calculus format, generalising to encompass intuitionist arithmetic- ‘Heyting arithmetic’ (HA)- (thus requiring an extension from all of propositional to predicate logic), all as part of a project of investigation of the constructivist notion of a construction. Howard deepened the results by making clear not only a correspondence between provable formulae in the sequent calculus and type ascriptions, but also between the terms in the type ascriptions and proofs of the corresponding  formulae.[2]  For example, (to the horror of relevantists) A \(\rightarrow\) (B \(\rightarrow\) A) is provable in T\(_{\rightarrow}\). The corresponding type is \(\alpha \Rightarrow(\beta \Rightarrow \alpha)\), the type of the basic operator K, whose action is and whose \(\lambda\) representation is \((\lambda x.(\lambda y.x))\) (usually abbreviated \(\lambda xy.x)\), as can be seen by the \(\beta\)-reduction  chain:[3] The simplest proof of A \(\rightarrow\) (B \(\rightarrow\) A) in T\(_{\rightarrow}\) is: Figure 1 in which the second step, to the intermediate conclusion B \(\rightarrow\) A, is an instance of \(\rightarrow\)I(ntroduction) with vacuous discharge of the unassumed antecedent B (in a sequent calculus version, the rule of thinning, adding extra assumptions in the sequent antecedent, would be used). The type theoretic proof in type theory  TT[4]  of the construction of a term “inhabiting” the type \(\alpha  \Rightarrow(\beta \Rightarrow \alpha)\) takes the form: Figure 2 Here \(\lambda\) abstraction, the introduction of \(\lambda\) terms, corresponds to \(\rightarrow\)I, so the \(\lambda\) term \(\lambda xy.x\) which is shown to have type \(\alpha \Rightarrow  (\beta \Rightarrow \alpha)\) ‘codes’ two steps of the type correlate of \(\rightarrow\)I, namely the rule \(\Rightarrow\)I introducing function types, and we can recover the above proof of the propositional theorem. Moreover given the tight connection between type theoretical calculi and programs in certain types of programming languages, we can also see the TT proof as a program of steps in the construction of a certain type of computational object. In natural deduction systems, normalisation is the procedure by which redundant inferential loops are eliminated. In certain logics (such as intuitionistic logic), a normalisation metatheorem holds and tells us that any proof can be stripped of its redundancy and reduced to a normal form. A further level of correspondence, brought out by Howard, links normalisation with the ‘evaluation’ of programs in which complex terms are reduced to their simplest forms (this is not always possible in the more expressively powerful type systems). It seems to be Kreisel who introduced the slogan ‘formulae as types’, with Martin-Löf responsible for the more widespread ‘propositions as types’ slogan (See again, Wadler, 2015). In the philosophical context, ‘proposition’ is often used to mean something like the meaning of a sentence, i.e. of a formula of a certain sort. Using this terminology, a widespread intuitionist position is that that the proposition expressed by a formula is the set (or species, for the intuitionist) of all proofs of the formula. Given that different provable formulae will correspond to different types, the CH correspondence allows us to rephrase this ‘syntactico-semantics’ position as: the proposition expressed by a formula of HA is the type of its proofs, where ‘type’ is not a straightforward synonym for ‘set’ or ‘species’ but the notion from \(\lambda\)-calculus. As noted, this calculus is a formal system with rich interconnections with programming and computer science and readings in which the instances of types are purely syntactic, for example proof-theoretic entities. Hence the meaning of a formula, the proposition expressed, on such readings, does not represent a reality distinct from the linguistic system in which the formula occurs. The connection with intuitionism, then, is clear: but what is the relevance of the CH correspondence to formalism? There are, in the first place, clear overlaps between some forms of intuitionism and certain formalist positions. Not the philosophical intuitionism of the founding father Brouwer, of course, with its ontology of mathematical objects as mental constructions and an epistemology in which mathematical knowledge is based on internal reflection on the succession of ideas; this is a mathematical metaphysics far removed from formalism. But many constructivists have embraced, without accepting his metaphysics, the Brouwerian identification, or close linkage, of mathematical correctness (truth, if one is prepared to speak of mathematical truth) with provability. This sort of identification is more than congenial to a certain brand of formalism, one which rejects the idea that mathematical theses represent a mind-independent reality and which also divides the sheep from the goats on the basis of those which are provable, in some formal system, versus those which are disprovable. But there are also substantial differences between the intuitionist and the formalist. For one thing, not only Brouwer but also many later constructivists refuse to identify provability with provability in some formal system. For another, formalists have generally felt free to help themselves to classical logic, and have emphasised the free creativity of the mathematician: she should be free to generate whatever mathematical theories she wishes, subject only to withdrawing them if they turn out to be inconsistent (in the chosen background logic). On the first point the formalist will, of course, be a formalist! She will link correctness, at least at the most fundamental level, to formal proof. Here, then, the CH correspondence, or better correspondences, are surely very attractive to the formalist. The linkage between propositions and computations, algorithmic reductions of terms coding proofs to irreducible normal forms in particular, fits very snugly with those versions of formalism which take mathematics to be, at heart, shuffling of symbols with no external reference. On the second point, further work on the CH correspondences generalised the results from intuitionistic logic to a wide variety of other logics, in particular to classical logic (Griffin, 1990), as well as to other logical frameworks such as modal logic and linear logic. There is no burdensome logical restriction imposed by ‘Formulae-as-Types’ then, no need for the formalist to fight with one hand tied behind her back. What of the free creativity the formalist cherishes? Constructivist type theory has, of course, been extended well beyond Heyting arithmetic, particularly ambitious extensions are to be found in the univalent foundations project based on homotopy type theory (Awodey, 2014). This, then, is an avenue a formalism based on Formulae-as-Types might pursue. But for a formalist who wishes to be non-revisionist about non-constructivist mathematics the prospects are perhaps less clear. It is not enough just to add in the extra axioms or inference rules which yield the particular theory, in a standard framework, e.g. of a first-order or higher-order language. For one needs to do the further work needed to show that an extension of the CH correspondence obtains in this system. Moreover there is also an issue with primeness in the sense of the proof-theoretic property (which intuitionist logic satisfies) that when \(\vdash\) A \(\vee\) B then either \(\vdash\) A or \(\vdash\) B. Classical theories typically do not have this property and this will pose problems for generalising the CH correspondence and for justifying excluded middle (assuming the formalist does not simply take all non-trivial calculi as legitimate without need of justification). If correctness of a mathematical claim, relative to a particular framework, is identified with provability and if a disjunction can be correct where neither disjunct is provable then the formalist would seem to require some fancy footwork—supervaluationalism is not obviously appropriate here—to justify using classical logic. There is also the problem of applicability, which Frege thought an insuperable one for formalists. What can the meaning be of applied mathematical notions, such as «the number of \(\phi\)s», where mathematical and non-mathematical discourse is mixed together? Unless the formalist wishes to go down the Dummettian anti-realist route and generalise the notion of proof to a notion of verification appropriate for empirical language, she will have to find a way of combining, without too much ad hocness, a proof-theoretic semantics for pure mathematics with a different, perhaps a realist, truth-conditional semantics, for empirical language. Finally it should be noted that CH formalism, if we can call it such, will be unacceptable to the formalist who is motivated by anti-platonist concerns and wishes to exclude abstract objects from all mathematics, including metamathematics. For the meanings of concrete utterances of mathematical formulae, according to CH formalism, are sets/species/types of proofs, and the latter are abstract objects, infinitely many of them, of arbitrarily long finite length. The problem of the metatheory, in other words, has not been met. The anti-platonist cannot straightforwardly lift the ideas of syntactico-semantics and apply the CH correspondence in support of anti-platonism; a great deal more philosophical work is required.