 In all versions of externalism (semantic, natural kind, and social) discussed earlier, the mental contents of a subject depend in part on aspects of the environment which are clearly external to the subject’s cognitive processes. For example, the twin-water in Putnam’s thought-experiment or the relevant linguistic community in Burge’s are not part of the subjects’ ongoing mental processes. In contrast, active externalism asserts that the environment can play an active role in constituting and driving cognitive processes. Hutchins (1995) argues that the successful completion of a typical commercial flight requires complex interaction between the pilots and the instruments in the cockpit. He claims that an adequate analysis of the task would need to treat the whole distributed system as a cognitive system with memories, representations, and cognitive processes that extend outside the pilots’ heads. Clark and Chalmers (1998) is a widely-discussed defense of active externalism. In one argument, they introduce a thought experiment where someone with Alzheimer’s disease has to rely on a notebook to retain information and find his way about. Clark and Chalmers argue that because the notebook plays an active role in the cognitive life of the patient, its contents actually constitute some of that person’s non-occurrent beliefs, and so these belief contents are “not in the head”;. See also Hurley (1998), Wilson (1994), Haugeland (1995) and Noë (2005), and the entry on  embodied cognition. Whether we should regard the notebook as an extended part of that person’s belief system is a controversial matter. The issue concerns the conditions under which representational objects or states are regarded as part of a cognitive system. Adams and Aizawa (2001) claim that cognitive processes involve only representations with intrinsic content, and so the notebook should not be regarded as part of the subject’s cognitive process, because the notebook contains only symbols with non-intrinsic contents derived from our linguistic intentions. But Clark (2010) argues that this requirement is too strong. Cognition might involve mental imagery using diagrams with derived content, or biological routines that store bitmap images of printed texts. For further discussion of related issues, see the papers collected in Menary (2010). In considering whether a process constitutes a mental process external to a cognitive subject, an important background question is how the subject is to be individuated. In particular, where lies the physical boundary of the subject? One view is that perception marks the boundary where the world and the body meet. In the case of the Alzheimer’s patient, since the patient has to flip through the pages of the notebook and read the entries, this shows that the notebook as the object of perception and action should be regarded as external to the mind. Chalmers himself expresses some sympathy to this response in his preface to Clark (2008). On the other hand, suppose we agree that the notebook is part of the patient’s belief system, and so mental contents can extend beyond the brain. However, it might then be argued that in so doing we are in effect extending the physical boundary of that person beyond his brain. The notebook has now become a spatially scattered part of his extended self. If this is right, then it has not been shown that the patient’s mental contents are determined in part by factors external to the subject. But it might still show that the physical boundary of a subject can be extended through the use of artefacts in cognition. Enhancing our cognitive abilities with additional hardware might become commonplace with the development of computer technology and increasingly sophisticated brain-computer interfaces. For example, we might implant micro-processors and radio transmitters into our brains in order to access external databases, or to offload computationally-intensive processing. Complicated issues are involved in determining whether the external hardware is or is not part of the extended mind. Imagine a scenario where our memory is connected to an external computer database. When we ponder whether a factual proposition P is true, and the information is not in our brain, a remote search might then be triggered, and the result returns as an occurrent belief. In such a scenario, we would all be accessing the same database. So do our minds overlap because we share the same cognitive resource? But if the database servers are actually owned by a commercial company, legal considerations might mitigate against the idea that the servers are part of our bodies or our minds. On the other hand, if a user owns a database server and has exclusive access, we might then be more inclined to say that the server is part of his extended mind. So the exact boundary of the mind might turn out to involve normative and legal considerations. This raises the question of whether there is a coherent and unitary psychological conception of what a mind really is.