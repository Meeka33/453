 Here is a schematic summary of current theories about the nature of the representations and computations that explain how the mind works. Formal logic  provides some powerful tools for looking at the nature of representation and computation. Propositional and predicate calculus serve to express many complex kinds of knowledge, and many inferences can be understood in terms of logical deduction with inferences rules such as modus ponens. The explanation schema for the logical approach is: It is not certain, however, that logic provides the core ideas about representation and computation needed for cognitive science, since more efficient and psychologically natural methods of computation may be needed to explain human thinking. Much of human knowledge is naturally described in terms of rules of the form IF … THEN …, and many kinds of thinking such as planning can be modeled by rule-based systems. The explanation schema used is: Computational models based on rules have provided detailed simulations of a wide range of psychological experiments, from cryptarithmetic problem solving to skill acquisition to language use. Rule-based systems have also been of practical importance in suggesting how to improve learning and how to develop intelligent machine systems. Concepts, which partly correspond to the words in spoken and written language, are an important kind of mental representation. There are computational and psychological reasons for abandoning the classical view that concepts have strict definitions. Instead, concepts can be viewed as sets of typical features. Concept application is then a matter of getting an approximate match between concepts and the world. Schemas and scripts are more complex than concepts that correspond to words, but they are similar in that they consist of bundles of features that can be matched and applied to new situations. The explanatory schema used in concept-based systems is: Analogies play an important role in human thinking, in areas as diverse as problem solving, decision making, explanation, and linguistic communication. Computational models simulate how people retrieve and map source analogs in order to apply them to target situations. The explanation schema for analogies is: The constraints of similarity, structure, and purpose overcome the difficult problem of how previous experiences can be found and used to help with new problems. Not all thinking is analogical, and using inappropriate analogies can hinder thinking, but analogies can be very effective in applications such as education and design. Visual and other kinds of images play an important role in human thinking. Pictorial representations capture visual and spatial information in a much more usable form than lengthy verbal descriptions. Computational procedures well suited to visual representations include inspecting, finding, zooming, rotating, and transforming. Such operations can be very useful for generating plans and explanations in domains to which pictorial representations apply. The explanatory schema for visual representation is: Imagery can aid learning, and some metaphorical aspects of language may have their roots in imagery. Psychological experiments suggest that visual procedures such as scanning and rotating employ imagery, and neurophysiological results confirm a close physical link between reasoning with mental imagery and perception.  Imagery is not just visual, but can also operate with other sensory experiences such as hearing, touch, smell, taste, pain, balance, nausea, fullness, and emotion. Connectionist networks consisting of simple nodes and links are very useful for understanding psychological processes that involve parallel constraint satisfaction. Such processes include aspects of vision, decision making, explanation selection, and meaning making in language comprehension. Connectionist models can simulate learning by methods that include Hebbian learning and backpropagation. The explanatory schema for the connectionist approach is: Simulations of various psychological experiments have shown the psychological relevance of the connectionist models, which are, however, only very rough approximations to actual neural networks. Theoretical neuroscience is the attempt to develop mathematical and computational theories and models of the structures and processes of the brains of humans and other animals.  It differs from connectionism in trying to be more biologically accurate by modeling the behavior of large numbers of realistic neurons organized into functionally significant brain areas.  Computational models of the brain have become biologically richer, both with respect to employing more realistic neurons such as ones that spike and have chemical pathways, and with respect to simulating the interactions among different areas of the brain such as the hippocampus and the cortex. These models are not strictly an alternative to computational accounts in terms of logic, rules, concepts, analogies, images, and connections, but should mesh with them and show how mental functioning can be performed at the neural level. The explanatory schema for theoretical neuroscience is: From the perspective of theoretical neuroscience, mental representations are patterns of neural activity, and inference is transformation of such patterns. Bayesian models are prominent in cognitive science, with applications to such psychological phenomena as learning, vision, motor control, language, and social cognition.  They have also had effective applications in robotics.  The Bayesian approach assumes that cognition is approximately optimal in accord with probability theory, especially Bayes’ theorem, which says that the probability of a hypothesis given evidence is equal to the result of multiplying the prior probability of the hypothesis by the conditional probability of the evidence given the hypothesis, all divided by the probability of the evidence.  The explanatory schema for Bayesian cognition is: Although Bayesian methods have had impressive applications to a wide range of phenomena, their psychological plausibility is debatable because of assumptions about optimality and computations based on probability theory. Artificial intelligence has been a central part of cognitive since the 1950s, and the most dramatic recent advances in AI have come from the approach of deep learning, which has produced major breakthroughs in fields that include game playing, object recognition, and translation. Deep learning builds on ideas from connectionism and theoretical neuroscience, but uses neural networks with more layers and improved algorithms, benefitting from faster computers and large data bases of examples. Another important innovation is combining learning from examples with reinforcement learning, resulting by 2016 in the world’s leading Go player, AlphaGo. Ideas from deep learning are spreading back into neuroscience and also beginning to influence research in cognitive psychology. The explanatory schema for deep learning is: Although deep learning has produced dramatic improvements in some AI systems, it is not clear how it can be applied to aspects of human thought that include imagery, emotion, and analogy.