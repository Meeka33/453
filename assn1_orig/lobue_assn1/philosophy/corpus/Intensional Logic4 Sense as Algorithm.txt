 Following Frege, the mathematical expressions “\(1+4\)” and “\(2+3\)” have the same denotation but different senses. Frege did not actually say what a sense was, though it was clear that, somehow, sense determined denotation. Earlier we talked of computations associated with “\(1+4\)” and “\(2+3\)”, but what we presented was quite simple-minded. Tichý introduced the idea of a construction with these two expressions prescribing different constructions. A much more formal version of this appears in a series of papers, (Moschovakis 1994; Moschovakis 2006; Kalyvianaki and Moschovakis 2008), all of which trace back to (Moschovakis 1989). In these is a very sophisticated formalism in which the sense or intension of an expression is an algorithm, and algorithm execution determines denotation. In what follows we sketch the ideas, skimping on most technical details. To keep things relatively simple we confine our discussion to sentences of a formal language for which, again following Frege, denotation is simply a truth value. Both “there are infinitely many primes” and “there are infinitely many even numbers” agree on denotation—both are true—but clearly have different senses. All the basic ideas of Moschovakis are already present at the sentence level, though the ideas extend broadly. We quote from (Moschovakis 1994), on which our presentation is based. The mathematical results of the paper are about formal languages, but they are meant to apply also to those fragments of natural language which can be formalized, much as the results of denotational semantics for formal languages are often applied to fragments of natural language. In addition to the language of predicate logic whose sense semantics are fairly simple, the theory also covers languages with description operators, arbitrary connectives and modal operators, generalized quantifiers, indirect reference and the ability to define their own truth predicate. If sense is to be identified with algorithm, perhaps the most basic question is: what is an algorithm. For Moschovakis, as for many working mathematicians, an algorithm is an abstract mathematical object, in the same way that a number is. Of course one uses special notation to work with a number or an algorithm, but notation is syntactic while mathematical objects are semantic (even ideal). Algorithmic subject matter may vary: an algorithm for baking a cake does not operate in the same space as an algorithm for solving quadratic equations. Some formalism is needed so that algorithms can be specified, and this machinery should be suitable for all subjects, yet as simple as possible. There are several general, but equivalent, approaches to algorithmic specification across a range of subject matters. Moschovakis (1994) introduces a very simple, direct mechanism which he calls the Lower Predicate Calculus with Reflection, where reflection essentially means self-reference. Of course not all algorithms terminate, and consequently the underlying truth value space needs some consideration, but a solution along Kripke’s lines in his Theory of Truth works well. We lead up to a general definition via some (for the time being) informal examples. Suppose we have a structure with a given domain and some given relations of various arities, say \(\langle \bD, \bR_1, \ldots, \bR_n\rangle\). And suppose we have a first-order language formed in the usual way, with relation symbols, \(R_1\), …, \(R_n\) whose arities match those of the given relations. We will generally use the typographical convention that \(\bR\) is a relation and \(R\) is the associated formal symbol interpreted by that relation. In the usual way we can build up a first-order language that talks about the structure, where atomic formulas involve \(R_1\), …, \(R_n\) and \(=\). Constants can be simulated by the use of unary relations that are true of single things. For example, in arithmetic we can have a relation \(\bZ\) such that \(\bZ(x)\) holds only when \(x=0\). In the interests of readability, in such a case we would act as if we had a constant symbol in our language that was interpreted by 0. Such informal simplifications make formula reading a bit easier, while nothing significant is lost. What is added to the usual first-order machinery is a \(\textsf{where}\) construction. We will give a proper definition shortly but first, here is a concrete example. Let us assume we have a structure for arithmetic, \(\langle \{0,1,2,\ldots\}, \bS, \bZ\rangle\). Here \(\bS\) is the two-place successor relation on the domain, that is, we have \(\bS(0,1)\), \(\bS(1,2)\), …. We also assume \(\bZ\) is true uniquely of 0 and, in accord with what we said above about relations and individual constants, we act as if we had a constant symbol 0 in the formal language. Consider the following formula, where \(S\) is a two-place relation symbol interpreted by \(\bS\), and \(E\) and \(O\) are auxiliary one-place relation symbols. For the time being think of \(\simeq\) as something like “is defined to be”. This will be discussed further later. Think of \(E(x)\) as representing the ‘output’ relation. It is defined in terms \(O\), where \(O\) is defined in terms of \(E\). Mutual recursion is involved. Even at this informal stage it is not hard to see that \(\even\) defines the set of even numbers, in the sense that \(\even(x)\) evaluates to true for even \(x\) and to false for odd \(x\). Here is an informal calculation showing that \(\even(2)\) evaluates to true. In it we use \(\Leftarrow\) for reverse implication. Also we write members of the domain (numbers) directly into formulas, rather than using the machinery of valuations assigning numbers to free variables. We used the clause three times, replacing \(E(2)\), \(O(1)\), and \(E(0)\). The final line is true because \(S(1,2)\), \(S(0,1)\), and \(0=0\) are true. This example is a start, but it is misleadingly simple. The machinery is rich enough to allow formulation of the liar sentence. In the following, \(P\) is an auxiliary relation symbol of arity 0, that is, a propositional letter. We have written just \(P\) instead of \(P()\). Clearly an evaluation attempt of the sort shown above will not terminate. A solution to non-termination is familiar from classical recursion theory, and also from work on the theory of truth: allow the relations defined by our formal machinery to be partial. Not all instances of a relation have to receive a truth value. But these are semantic issues and before getting to them we need to give a proper syntactic definition of the language within which our formulas will be written. Above we spoke of a first-order language appropriate for a structure \(\langle\bD, \bR_1, \ldots, \bR_n\rangle\), enhanced with clauses, but these clauses were only shown via examples. Here is a proper definition. The Lower Predicate Calculus with Reflection (LPCR) for \(\langle\bD, \bR_1, \ldots, \bR_n\rangle\) is the language built up using the machinery of ordinary first-order logic with equality, together with the following formation clause. If \(\phi_0\), \(\phi_1\), …, \(\phi_k\) are formulas and \(P_1\), …, \(P_k\) are (new) auxiliary relation variables, the following is a formula. In this each \(\bx_i\) is a sequence of variables whose length is the arity of \(P_i\). The \(P_i\) may appear in the formulas \(\phi_0\), …, \(\phi_k\) themselves, and so we have a self-referential set of defining equations, with \(\phi_0\) as ‘output’. Note that with \eqref{whereformula} added to the definition of formula, \(\textsf{ where }\) conditions can appear in some of the \(\phi_i\), and so means of preventing inappropriate interaction between nested conditions is needed. This is done through the familiar machinery of free and bound variables. The symbols \(P_1\), …, \(P_k\) are taken to be relation variables, and are considered to be bound in \eqref{whereformula}. Likewise the occurrences of individual variables in \(\bx_i\) are understood to be bound in \(P_i(\bx_i) \simeq \phi_i\). In effect, these are local variables. Now the language LPCR has been defined, and we turn to notions of sense and reference. We have been discussing sentences and more generally formulas with free variables. The familiar Tarskian semantics provides a basis for understanding here, but we need modifications and extensions to deal with the construct. A partial function on a space \(S\) is a function that assigns values to some, but not necessarily to all, members of \(S\). Said otherwise, it is a function whose domain is a subset of \(S\). For a partial function \(f\), \(f(x)\simeq y\) means \(x\) is in the domain of \(f\) and \(f(x) = y\). (Finally we have a proper accounting of our use of \(\simeq\) in the examples earlier.) Partial relations are partial functions from \(k\)-tuples to \(\{{\textsf{t}}, {\textsf{f}}\}\). The given relations of our structures are relations in the usual sense, but it is partial relations that we may find ourselves defining. Assume we have a structure \(\langle\bD, \bR_1, \ldots, \bR_n\rangle\), and suppose we have an LPCR language associated with it. A valuation \(v\) in this structure is a mapping from individual variables to members of \(\bD\) and from auxiliary relation symbols to partial relations on \(\bD\). We would like to associate with each valuation \(v\) a mapping \(T_v\) from formulas of LPCR to truth values but since things like the liar sentence are formulable, \(T_v\) must be a partial function, and so we must be careful even about familiar things like propositional connectives. Various three valued logics have been developed; perhaps the most common is Kleene’s strong three-valued logic, motivated by recursion theory and familiar from much work on the Theory of Truth. The following table says how connectives and quantifiers behave. Cases that are not explicitly covered are understood to be those for which a truth valuation is left undefined. (For instance, if the truth value of \(X\) is undefined, the same is the case for \(\lnot X\).) This still leaves formulas to deal with. Suppose we have the following. We make two simplifying assumptions to keep our discussion from being too intricate. We assume no \(\phi_i\) contains a nested \(\textsf{ where }\) clause. The basic ideas are amply illustrated with this condition imposed, but everything extends to the general case without too much difficulty. It is a general requirement that the variables in \(\bx_i\) are ‘local’ to \(P_i(\bx_i) \simeq \phi_i\), that is, they are considered to be bound in this formula. To this we add another simplifying assumption: the variables in \(\bx_i\) are the only variables that may occur free in \(\phi_i\). Roughly this means that we have no parameters, only local variables. This serves to allow us to discuss things with less clutter. Again, everything extends to the more general case with no fundamental changes. Continuing with \eqref{Eexample}, consider the following associated set \(E\) of equations. The difficulty, of course, is that each \(P_i\) is allowed to occur in one or more \(\phi_j\), possibly even in \(\phi_i\), and so \(E\) is self-referential. In many computer programming languages one sees things like \(x = x+1\). It is explained to beginning programmers that this takes the current value of \(x\), adds 1, and calls the result \(x\) again. Occurrences of \(x\) on the right have ‘before’ values, occurrences on the left have ‘after’ values. Analogously, let us think of the members of \(E\) as (simultaneous) assignment statements. Occurrences of \(P_i\) on the right of \(\simeq\) are current values, occurrences on the left are next values. Taking all of \(P_1\), …, \(P_k\) into account, we can think of \(E\) as defining a functional that maps \(k\)-tuples of partial relations (‘before’ values of these relation symbols) to \(k\)-tuples of partial relations (‘after’ values of these relation symbols). Now here are the details a bit more formally. Suppose we have a \(k\)-tuple \(\langle\bP_1, \ldots, \bP_k\rangle\) of partial relations, where for each \(i\) the arity of \(\bP_i\) matches that of the partial relation variable \(P_i\). This is our input (‘before’ values). For each \(i\) we want to define an output partial relation which we call \(\bP'_i\), of the same arity as \(\bP_i\), so that \(\langle\bP'_1, \ldots, \bP'_k\rangle\) serves as our overall output (‘after’ values). To do this we must say when \(\bP'_i(\bd)\) maps to \({\textsf{t}}\), when it maps to \({\textsf{f}}\), and when it is undefined, for each \(\bd\) with components from \(\bD\). Well, take \(v\) to be a valuation assigning to each auxiliary relation symbol \(P_i\) the corresponding partial relation \(\bP_i\) (this is how ‘before’ values for our partial relation symbols come in), and assigning to the variables in \(\bx_i\) the corresponding members of \(\bd\). Now, simply let \(\bP'_i(\bd)\simeq T_v(\phi_i)\). In this way a new partial relation \(\bP'_i\) is specified, and more generally a vector of them, \(\langle\bP'_1, \ldots, \bP'_k\rangle\). The set of equations \(E\) can be thought of as specifying a functional transforming \(k\)-tuple \(\langle\bP_1, \ldots, \bP_k\rangle\) into \(\langle\bP'_1, \ldots, \bP'_k\rangle\). Let us call this functional \([E]\), and write \([E](\langle\bP_1, \ldots, \bP_k\rangle) = \langle\bP'_1, \ldots, \bP'_k\rangle\). If we are to have equations \(E\) behave well in a logic setting, each \(P_i\) should have the same valuation no matter where we see it—there should be no distinction between what we have been calling left and right sides; \(\bP_i\) and \(\bP'_i\) should be the same. In other words, we would like to have partial relations \(\bP_1\), …, \(\bP_k\) to interpret \(P_1\), …, \(P_k\) so that \([E](\langle\bP_1, \ldots, \bP_k\rangle) = \langle\bP_1, \ldots, \bP_k\rangle\)—‘before’ and ‘after’ values agree. This is called a fixed point of \([E]\). So, we need to know that \([E]\) has a fixed point, and if it has more than one then there is a plausible candidate we can choose as the best one. If \(f\) and \(g\) are two partial functions from a space \(S\) to \(R\), one writes \(f\subseteq g\) to mean that whenever \(f(x)\simeq w\) then also \(g(x)\simeq w\). Then for two partial relations \(\bP\) and \(\bQ\) of the same arity, \(\bP\subseteq\bQ\) means that whenever \(\bP(\bd)\) is defined, so is \(\bQ(\bd)\), and both have the same truth value. We can extend this to \(k\)-tuples by setting \(\langle\bP_1, \ldots, \bP_k\rangle\subseteq\langle\bQ_1, \ldots, \bQ_k\rangle\) if \(\bP_i\subseteq\bQ_i\) for each \(i\). It is not terribly difficult to show that the functional \([E]\) defined above, and based on \eqref{Eexample}, has the monotonicity property: if \(\langle\bP_1, \ldots, \bP_k\rangle\subseteq\langle\bQ_1, \ldots, \bQ_k\rangle\) then \([E](\langle\bP_1, \ldots, \bP_k\rangle)\subseteq[E](\langle\bQ_1, \ldots, \bQ_k\rangle)\). There is a very general theory of monotone mappings like this, from which it follows that \([E]\) does have a fixed point. Moreover, if there are more than one then there is a unique one that is least, in the sense that it is in the \(\subseteq\) relation to any other. This least fixed point is precisely the best candidate we mentioned above. It contains the information that any fixed point must have. Now we finish saying how to evaluate the formula \eqref{Eexample}. First, construct the associated set of equations, \(E\). Next, construct the functional \([E]\). There is a least fixed point for \([E]\), let us say it is \(\langle\bF_1, \ldots, \bF_k\rangle\). Finally, evaluate \(\phi_0\) using \(\bF_i\) to interpret \(P_i\) for each \(i\). The resulting truth value, or undefined, is the value (denotation) associated with \eqref{Eexample}. We have now said how to associate a truth value, or undefined, with every formula of LPCR (under our simplifying assumptions). We have (partial) denotations. Each formula of LPCR specifies an algorithm for its evaluation, that is, for the determination of its truth value (if possible). Moschovakis identifies the sense of a formula with that algorithm. Two formulas that evaluate to the same result, thus having the same denotation, may have different senses because the associated algorithms are different. For example, in \eqref{evenone} we gave a formula that defines the even numbers. Here is another such formula. We leave it to you to verify that \eqref{eventwo} also defines the even numbers. It is intuitively plausible that \eqref{evenone} and \eqref{eventwo} evaluate using algorithms that differ, and so have different senses. But of course this must be made precise. What is needed is a uniform method of comparison between algorithms. Here we just briefly sketch the ideas. There is very general machinery, from Moschovakis 1989, called the Formal Language of Recursion, FLR. Using it a thorough exploration of recursive definitions and fixpoints is possible. The language that concerns us here, LPCR, embeds into FLR, even allowing nested clauses and parameters, something we ignored in our discussion of denotation. In FLR there is a method for converting recursive definitions into a normal form, which cannot be further reduced. That normal form has a very simple structure, consisting of a set of self-referential equations with no nesting present at all. Normal forms reveal essential evaluation structure most clearly. When working with a single structure, \(\langle\bD, \bR_1, \ldots, \bR_n\rangle\), all normal forms will be built from a common set of functionals. This makes it easy to compare normal forms. The idea is that if two formulas of LPCR, when embedded into FLR, have differing normal forms, the two formulas have different senses. Of course this must be taken with some reasonable flexibility. For instance, two sets of equations that differ only by renaming variables or switching order of equations do not differ in any fundamental way. With this understood, if two LPCR formulas, when embedded into FLR, have truly distinct normal forms, the two LPCR formulas are defined to have different senses. This meets all the informal conditions one wants a notion of sense to have. Moschovakis even proves the important theorem that equality of sense, as just defined, is decidable under natural conditions. The word “algorithm” suggests something effective, but here it is being used in a more general sense, as a set of instructions that, for reasons of our finitistic limitations, we may not be able to actually carry out. Consider again the paradigm formula, \eqref{whereformula}. If one of the \(\phi_i\) contains an existential quantifier in a positive position (or a universal quantifier in a negative position) it can be thought of as invoking a systematic search through the domain \(\bD\) for a verifying witness. This is plausible for reasonable domains. But if \(\phi_i\) should contain a universal quantifier in a positive position or an existential quantifier in a negative position, something must be verified for every member of the domain and unless the domain is finite, this is not a human task. Nonetheless, we generally believe we understand quantification. What we are dealing with is algorithms relative to that understanding. The problem with quantifiers is inescapable for much that we routinely discuss using sense and reference. Consider Russell’s treatment of definite descriptions. In this “the \(A\) has property \(B\)” is replaced by “exactly one thing has property \(A\) and it has property \(B\)”. To say that only one thing has property \(A\) one says that something has property \(A\) and everything else does not. The first part of this involves an existential quantifier and the second part a universal one. Then if the definite description occurs in a positive location we have a positive occurrence of a universal quantifier, and if it occurs in a negative location we have a negative occurrence of an existential quantifier. Essential problems arise either way. Moschovakis is not claiming to turn sense and reference into something computable, but simply to provide mathematical machinery that can plausibly formalize the ideas involved using a generalized notion of algorithm. There is a second, related problem where lack of effectiveness comes in. In our discussion of denotation we considered a set \(E\) of equations \eqref{equationsE} and a functional \([E]\) associated with them. Recall that \([E]\) mapped \(k\)-tuples of partial relations to \(k\)-tuples of partial relations. We noted that \([E]\) would be monotone, and by very general results such functionals always have least fixed points. There is more than one way of showing this. One well-known argument has a decidedly algorithmic flavor to it. It goes as follows. Start with the smallest \(k\)-tuple of partial relations—this is the one where every partial relation is always undefined. Call this \(T_0\). Apply the functional \([E]\) to \(T_0\), getting \(T_1\). Apply the functional \([E]\) to \(T_1\) getting \(T_2\), and so on. It is easy to show that \(T_0\subseteq T_1\subseteq T_2\subseteq\ldots\). We have that \(T_0\subseteq T_1\) because \(T_0\) is in the \(\subseteq\) relation to every \(k\)-tuple. By monotonicity we then have \([E](T_0)\subseteq [E](T_1)\), but this says \(T_1 \subseteq T_2\). And so on. Continue with this increasing sequence and eventually the least fixed point of \([E]\) will be reached. But this is very misleading. What does “continue” mean? We have \(T_0\), \(T_1\), \(T_2\), …. None of these may be a fixed point. For instance, suppose we carry out this construction with the functional arising from \eqref{evenone} for \(\even(x)\). Then \(T_0\) will be \(\langle E_0, O_0\rangle\), where both \(E_0\) and \(O_0\) are the everywhere undefined 1-place relation. We leave it to you to check that we get successive \(T_i=\langle E_i, O_i\rangle\) where we have the following, with cases not displayed being undefined. None of \(T_0\), \(T_1\), \(T_2\), …is a fixed point, but there is a clear notion of a limit, called \(T_\omega\), that accumulates the results produced along the way. It is the least fixed point in this example. But iterating and taking a limit may not be sufficient. Consider the following elaboration of \eqref{evenone}. The set of equations arising from \eqref{evenmore} has the two members of \eqref{evenone}, and one more for \(A\). Using these equations, in order to conclude \(A(1)\) we must already have one of \(E(y)\) or \(O(y)\) evaluating to \({\textsf{t}}\) for every number \(y\). If we carry out the construction outlined above, we won’t have this for \(E\) and \(O\) until stage \(\omega\), and so we must go one more step, to what is called \(T_{\omega+1}\), before we reach a fixed point. More and more extreme examples can be given. The fixed point construction may have to be continued to larger and larger transfinite ordinals. This is a well-known phenomenon, especially in areas like the Theory of Truth. It cannot be avoided. Incidentally, it should be noted that the machinery introduced by Kripke in his treatment of truth has a natural embedding into LPCR, but we do not discuss this here.