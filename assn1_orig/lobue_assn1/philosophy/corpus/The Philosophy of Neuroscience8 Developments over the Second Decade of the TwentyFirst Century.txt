 Mechanism, first introduced in section 7 above, came to dominate the philosophy of neuroscience throughout the second decade of the twenty-first century. One much-discussed example is Gualtiero Piccinini and Carl Craver (2011). The authors employ two popular mechanistic notions. Their first is the multi-level, nested hierarchies of mechanisms-within-mechanisms perspective, discussed in section 7 above, that traces back to Craver and Darden (2001). Their second is that of “mechanism sketch”, suggested initially in Machamer, Darden, and Craver (2000) and developed in detail in Craver (2007). Piccinini and Craver’s goal is to “seamlessly” situate psychology as part of an “integrated framework” alongside neuroscience. They interpret psychology’s familiar functional analyses of cognitive capacities as relatively incomplete mechanism-sketches, which leave out many components of the mechanisms that ultimately will fully explain the system’s behavior. Neuroscience in turn fills in these missing components, dynamics, and organizations, at least ones found in nervous systems. This filling-in thereby turns psychology’s mechanism-sketches into full-blown mechanistic explanations. So even though psychology proceeds via functional analyses, so interpreted it is nonetheless mechanistic. Piccinini and Craver realize that their “integrated” account clashes with classical “autonomy” claims for psychology vis-à-vis neuroscience. Nevertheless, they insist that their challenge to classical “autonomy” does not commit them to “reductionism”, in either its classical or more recent varieties. Their commitment to nested hierarchy of mechanisms-within-mechanisms to account for a system’s behavior acknowledges the importance of mechanisms and intralevel causation at all levels constituting the system, not just at lower (i.e., cellular, molecular) levels. David Kaplan and Craver (2011) focus the mechanist perspective critically on dynamical systems mathematical models popular in recent systems and computational neuroscience. They argue that such models are explanatory only if there exists a “plausible mapping” between elements in the model and elements in the modeled system. At bottom is their Model-to-Mechanism-Mapping (3M) Constraint on explanation. The variables in a genuinely explanatory model correspond to components, activities, or organizational features of the system being explained. And the dependencies posited among variables in the model, typically expressed mathematically in systems and computational neuroscience, correspond to causal relations among the system’s components. Kaplan and Craver justify the 3M Constraint on grounds of explanatory norms, common to both science and common sense. All other things being equal, they insist, explanations that provide more relevant details about a system’s components, activities, and organization, more likely will answer more questions about how the system will behave in a variety of circumstances, than will an explanation that provides fewer (mechanistic) details. “Relevant” here pertains to the functioning of the specific mechanism. Models from systems and computational neuroscience that violate the 3M Constraint are thus more reasonably thought of as mathematical descriptions of phenomena, not explanations of some “non-mechanistic” variety. Kaplan and Craver challenge their own view with one of the more popular dynamical/mathematical models in all of computational neuroscience, the Haken-Kelso-Bunz (1985) model of human bimanual finger-movement coordination. They point to passages in these modelers’ publications that suggest that the modelers only intended for their dynamical systems model to be a mathematically compact description of the temporal evolution of a “purely behavioral dependent variable”. The modelers interpreted none of the model’s variables or parameters as mapping onto components or operations of any hypothetical mechanism generating the behavioral data. Nor did they intend for any of the model’s mathematical relations or dependencies among variables to map onto hypothesized causal interactions among components or activities of any mechanism. As Kaplan and Craver further point out, after publishing their dynamicist model, these modelers themselves then began to investigate how the behavioral regularities their model described might be produced by neural motor system components, activities, and organization. Their own follow-up research suggests that these modelers saw their dynamicist model as a heuristic, to help neuroscientists move toward “how-possibly”, and ultimately to a “how-actually” mechanistic explanation. At bottom, Kaplan and Craver’s 3M constraint on explanation presents a dilemma for dynamicists. To the extent that dynamical systems modelers intend to model hypothesized neural mechanisms for the phenomenon under investigation, their explanations will need to cohere with the 3M Constraint (and other canons of mechanistic explanation). To the extent that this is not a goal of dynamicist modelers, their models do not seem genuinely explanatory, at least not in one sense of “explanation” prominent in the history of science. Furthermore, when dynamicist models are judged to be successful, they often prompt subsequent searches for underlying mechanisms, just as the 3M Constraint and the general mechanist account of the move from “how-possibly” to “how actually” mechanisms recommends. Either horn gores dynamicists who claim that their models constitute a necessary additional kind of explanation in neuroscience to mechanistic explanation, beyond any heuristic value such models might offer toward discovering mechanisms. Kaplan and Craver’s radical conclusion, that dynamicist “explanations” are genuine explanations only to the degree that they respect the (mechanist’s) 3M Constraint, needs more defense. The burden of proof always lies on those whose conclusions strike at popular assumptions. More than the discussion of a couple of landmark dynamicist models in neuroscience is needed (in their 2011, Kaplan and Craver also discuss the difference-of-Gaussians model of receptive field properties of mammalian visual neurons). Expectedly, dynamicists have taken up this challenge. Michael Silberstein and Anthony Chemero (2013), for example, argue that localization and decomposition strategies characterize mechanistic explanation, and that some explanations in systems neuroscience violate one of these assumptions, or both. Such violations in turn create a dilemma for mechanists. Either they must “stretch” their account of explanation, beyond decomposition and localization, to capture these recalcitrant cases, or they must accept “counterexamples” to the generality of mechanistic explanation, in both systems neuroscience and systems biology more generally. Lauren Ross (2015) and Mazviita Chirimuuta (2014) independently appeal to Robert Batterman’s account of minimal model explanation as an important kind of non-mechanistic explanation in neuroscience. Minimal models were developed initially to characterize a kind of explanation in the physical sciences (see, e.g., Batterman and Rice 2014). Batterman’s account distinguishes between two different kinds of scientific “why-questions”: why a phenomenon manifests in particular circumstances; and why a phenomenon manifests generally, or in a number of different circumstances. Mechanistic explanations answer the first type of why-question. Here a “more details the better” (MDB) assumption (Chirimuuta 2014), akin to Kaplan and Craver’s “all things being equal” assumption about better explanations (mentioned above), holds force. Minimal models, however, which minimize over the presented implantation details and hence violate MDB, are better able to answer the second type of scientific why-questions. Ross (2015), quoting from computational neuroscientists Rinzel and Ermentrout, insists that models containing more details than necessary can obscure identification of critical elements by leaving too many open possibilities, especially when one is trying to answer Batterman’s second kind of why-questions about a system’s behavior. Chirimuuta and Ross each appeal to related resources from computational neuroscience to illustrate the applicability of Batterman’s minimal model explanation strategy. Ross appeals to “canonical models”, which represent “shared qualitative features of a number of distinct neural systems” (2015: 39). Her central example is the derivation of the Ermentrout-Kopell model of class I neuron excitability, which uses “mathematical abstraction techniques” to “reduce models of molecularly distinct neural systems to a single … canonical model”. Such a model “explains why molecularly diverse neural systems all exhibit the same qualitative behavior”, (2015: 41) clearly a Batterman second-type why-question. Chirimuuta’s resource is “canonical neural computations” (CNCs): computational modules that apply the same fundamental operations in a variety of contexts … a toolbox of computational operations that the brain applies in a number of different sense modalities and anatomic regions and which can be described at higher levels of abstraction from their biophysical implementation. (Chirimuuta 2014: 138) Examples include shunting inhibition, linear filtering, recurrent amplification, and thresholding. Rather than being mechanism-sketches, awaiting further mechanistic details to be turned into full-blown how-actually mechanisms, CNCs are invoked in a different explanatory context, namely, ones posing Batterman’s second type of why-questions. Ross concurs concerning canonical models: Understanding the approach dynamical systems neuroscientists take in explaining [system] behavior requires attending to their explanandum of interest and the unique modeling tools [e.g., canonical models] common in their field. (2015: 52) In short, both Chirimuuta’s and Ross’s replies to Kaplan and Craver’s challenge is a common one in philosophy: save a particular form of explanation from collapsing into another by splitting the explanandum. Finally, to wrap up this discussion of mechanism ascendant, an analogue of Craver’s (2007) problem of accounting for “constitutive mechanistic relevance”, that is, for determining which active components of a system are actually part of the mechanism for a given system phenomenon, has also re-emerged in recent discussions. Robert Rupert (2009) suggests that “integration” is a key criterion for determining which set of causally contributing mechanisms constitute the system for a task, based on the relative frequency with which sets of mechanisms co-contribute to causing task occurrences. He cashes frequency of co-contribution as the probability of the set for causing the cognitive task, conditional to every other co-occurring causal set. Felipe De Brigard (2017) challenges Rupert’s criterion, arguing that it cannot account for cognitive systems displaying two features, “diachronic dynamicity” along with “functional stability”. The frequency with which a given mechanism causally contributes to the same cognitive task (functional stability) can change over time (diachronic dynamicity). Although De Brigard emphasizes the critical importance of these features for Rupert’s integration criterion via a fanciful thought experiment, he also argues that they are a widespread phenomenon in human brains. Both features are found, for example, in evidence pertaining to the “Hemispheric Asymmetry Reduction in Older Adults”, in which tasks that recruit hemispherically localized regions of prefrontal cortex in younger adults show a reduction in hemispheric asymmetry in older adults. And both are found in “Posterior-Anterior Shift with Aging”, where a task increases activity in anterior brain regions while decreasing activity in posterior regions in older adults, relative to activity invoked by the same task in younger adults. To replace Rupert’s notion of integration as a criterion for determining which sets of mechanisms constitute a cognitive system, De Brigard points to two promising recent developments in network neuroscience which potentially allow for parametrized time. “Scaled inclusivity” is a method for examining each node in a network and identifying its membership in “community structures” across different iterations of the network. “Temporal-dynamic network analyses” is a way to quantify changes in community structures or modules between networks at different time points. Both methods thereby identify “modular alliances”, which convey both co-activation and dynamic change information in a single model. De Brigard suggests that these are thus the candidates with which cognitive systems could be identified. Clearly, much remains to be discussed regarding the impact mechanism has come to wield in philosophy of neuroscience over the last decade. But while mechanism has become the most dominant general perspective in the field, work in other areas continues. Michael Anderson defends the relevance of cognitive neuroscience for determining psychology’s taxonomy, independent of any commitment to mechanism. The most detailed development of his approach is in his (2014) book, After Phrenology, based on his influential “neural reuse” hypothesis. Each region of the brain, as recognized by the standard techniques of cognitive neuroscience (especially fMRI), engages in cognitive functions that are highly various, and form different “neural partnerships” with one another under different circumstances. Psychological categories are then to be reconceived along lines suggested by the wide-ranging empirical data in support of neural reuse. A genuine “post-phrenological” science of the mind must jettison the assumption that each brain region performs its own fundamental computation. In this fashion Anderson’s work explicitly continues philosophy of neuroscience’s ongoing interest in localizations of cognitive functions. In shorter compass, Anderson (2015) investigates the relevance of cognitive neuroscience for reconceiving psychology’s basic categories, starting from a consequence of his neural reuse hypothesis. Attempts to map cognitive processes onto specific neural processes and brain regions reveal “many-to-many” relations. Not only do these relations show that combined anatomical-functional labels for brain regions (e.g., “fusiform face area”) are deceptive; they also call into question the possibility of deciding between alternative psychological taxonomies by appealing to cognitive neuroscientific data. For all but the strongest proponents of psychology’s autonomy from neuroscience, these many-to-many mappings will suggest that the psychological taxonomy we bring to this mapping project needs revision. One need not be committed to any strong sense of psychoneural reduction, or the epistemological superiority of cognitive neuroscience to psychology, to draw this conclusion. The mere relevance of cognitive neuroscience for psychology’s categories is enough. This debate is thus “about the requirements for a unified science of the mind, and the proper role of neurobiological evidence in the construction of such an ontology” (2015: 70), not about the legitimacy of either. Anderson divides revisionary projects for psychology into three kinds, based on the degree of revision each kind recommends for psychology, and the extent of one-to-one function-to-structure mappings the proposed revisions predicts will be available. “Conservatives” foresee little need for extensive revisions of psychology’s basic taxonomy, even as more neuroscientific evidence is taken into account than current standard practices pursue. “Moderates” insist that our knowledge of brain function “can (and should) act as one arbiter of the psychologically real” (2015: 70), principally by “splitting” or “merging” psychological concepts that currently are in use. “Radicals” project even more drastic revisions, even to the most primitive concepts of psychology, and even after such revisions they still do not expect that many one-to-one mappings between brain regions and the new psychological primitives will be found. Although Anderson does not stress this connection (eliminative materialism has not been a prominent concern in philosophy of mind or neuroscience for two decades), readers will notice similar themes discussed in  section 2  above, only now with scientific, not folk psychology the target of the radical revisionists. A key criterion for any satisfactory reformulation of a cognitive ontology is the degree to which it supports two kinds of inferences: “forward inferences”, from the engagement of a specific cognitive function to the prediction of brain activity; and “reverse inferences”, from the observation that a specific brain region or pattern occurs to the prediction that a specific cognitive operation is engaged. In light of this explicit criterion, Anderson usefully surveys the work of a number of prominent psychologists and cognitive neuroscientists in each of his revisionist groups. Given his broader commitment to neural reuse, and the trek it invites into “evolutionarily-inspired, ecological, and enactive terms”, Anderson’s own sentiments lie with the “radicals”: language and mathematics, for instance, are best understood as extensions of our basic affordance processing capacities augmented with public symbol systems … The psychological science that results from this reappraisal may well look very different from the one we practice today. (2015: 75) Landmark neuroscientific hypotheses remain a popular focus in recent philosophy of neuroscience. Berit Brogaard (2012), for example, argues for a reinterpretation of the standard “dissociation” understanding of Melvin Goodale and David Milner’s (1992) celebrated “two visual processing streams”, a landmark, now “textbook” result from late-twentieth century neuroscience. Two components of the standard dissociation are key. The first is that distinct brain regions compute information relevant for visually guided “on-the-fly” actions, and for object recognition, respectively, the dorsal stream (which runs from primary visual cortex through the medial temporal region into the superior and inferior parietal lobules) and the ventral stream (which runs from primary visual cortex through V4 and into inferior temporal cortex). And second, that only information relevant for visual object recognition, processed in the ventral stream, contributes to the character of conscious visual experiences. Brogaard’s concern is that this standard understanding challenges psychofunctionalism, our currently most plausible “naturalistic” account of mental states. Psychofunctionalism draws its account of mind directly from our best cognitive psychology. If φ is some mental state type that has inherited the content of a visual experience, then according to cognitive psychology a wide range of visually guided beliefs and desires, different kinds of visual memories, and so on, satisfy φ’s description. But by the standard “dissociation” account of Goodale and Milner’s two visual streams, only dorsal-stream states, and not ventral-stream states, represent truly egocentric visual properties, namely “relational properties which objects instantiate from the point of view of believers or perceivers”, (Brogaard 2012: 572). But according to cognitive psychology, dorsal-stream states do not play this wide-ranging φ-role. So according to psychofunctionalism “φ-mental states cannot represent egocentric properties” (2012: 572). But it seems “enormously plausible” that some of our perceptual beliefs and visual memories represent egocentric properties. So either we reject psychofunctionalism, and so our most plausible naturalization project for determining whether a given mental state is instantiated, or we reject the standard dissociation interpretation of Goodale and Milner’s two visual streams hypothesis, despite the wealth of empirical evidence supporting it. Neither horn of this dilemma looks comfortably graspable, although the first horn might be thought to be more so, since psychofunctionalism as a general theory of mind lacks the kind of strong empirical backing that the standard interpretation of Goodale and Milner’s hypothesis enjoys. Nevertheless, Brogaard recommends retaining psychofunctionalism, and instead rejecting “a particular formulation” of Goodale and Milner’s two visual stream hypothesis. The interpretation to reject insists that “dorsal-stream information cannot contribute to the potentially conscious representations computed by the ventral stream” (2012: 586–587). Egocentric representations of visual information computed by the dorsal stream contribute to conscious visual stream representations “via feedback connections” from dorsal- to ventral-stream neurons (2012: 586). This isn’t to deny dissociation: Information about the egocentric properties of objects is processed by the dorsal stream, and information about allocentric properties of objects is processed by the ventral stream. (2012: 586) But this dissociation hypothesis “has no bearing on what information is passed on to parts of the brain that process information which correlated with visual awareness” (2012: 586). With this re-interpretation, psychofunctionalism is rendered consistent with Goodale and Milner’s two stream, dorsal and ventral, “what” and “where/how” hypothesis and the wealth of empirical evidence that supports it. According to Brogaard, psychofunctionalism can thereby “correctly treat perceptual and cognitive states that carry information processed in the ventral visual stream as capable of representing egocentric properties” (2012: 586). Despite philosophy of neuroscience’s continuing focus on cognitive/systems/computational-neuroscience (see the discussion in  section 7 above),  interest in neurobiology’s cellular/molecular mainstream appears to be increasing. One notable paper is Ann-Sophie Barwich and Karim Bschir’s (2017) historical-cum-philosophical study of G-protein coupled receptors (GPCRs). Work on the structure and functional significance of these proteins has dominated molecular neuroscience for the past forty years; their role in the mechanisms of a variety of cognitive functions is now empirically documented beyond question. And yet one finds little interest in, or even notice of this shift in mainstream neuroscience among philosophers. Barwich and Bschir’s yeoman history research on the discovery and development of these objects pays off philosophically. The role of manipulability as a criterion for entity realism in the science-in-practice of wet-lab research becomes meaningful “only once scientists have decided how to conceptually coordinate measurable effects distinctly to a scientific object” (2017: 1317). Scientific objects like GPCRs get assigned varying degrees of reality throughout different stages of the discovery process. Such an object’s role in evaluating the reality of “neighboring elements of enquiry” becomes a part of the criteria of its reality as well. The impact of science-in-practice on philosophy of science generally has been felt acutely in the philosophy of neuroscience, most notably in increased philosophical interest in neuroscientific experimentation. In itself this should not surprise. Neuroscience relies heavily on laboratory experimentation, especially within its cellular and molecular, “Society for Neuroscience” mainstream. So the call to understand experiment should beckon any philosopher who ventures into neuroscience’s cellular/molecular foundations. Two papers by Jacqueline Sullivan (2009, 2010) have been important in this new emphasis. In her (2009) Sullivan acknowledges both Bickle’s (2003) and Craver’s (2007) focus on cellular and molecular mechanisms of long-term potentiation, and experience-driven form of synaptic plasticity. But she insists that broader philosophical commitments, which lead Bickle to ruthless reductionist and Craver to mosaic unity “global” accounts, obscure important aspects of real laboratory neuroscience practice. She emphasizes the role of “subprotocols”, which specify how data are to be gathered, in her model of “the experimental process”, and illustrates these notions with a number of examples. Her analysis reveals an important underappreciated tension among a pair of widely-accepted experiment norms. Pursuing “reliability” drives experimenters more deeply into extensive laboratory controls. Pursuing “external validity” drives them toward enriched experimental environments that more closely represent the messy natural environment beyond the laboratory. These two norms commonly conflict: in order to get more of one, scientists introduce conditions that give them less of the other. In her (2010) Sullivan offers a detailed history of the Morris water maze task, tracing her account back to Morris’s original publications. Philosophers of neuroscience have uncritically assumed that the water maze is a widely-accepted neuroscience protocol for rodent spatial learning and memory, but the detailed scientific history is not so clear on this interpretation. Scientific commentary over time on what this task measures, including some from Morris himself, reveals no clear consensus. Sullivan traces the source of this scientific inconsistency back to the impact of 1980s-era cellular-molecular reductionism driving experimental behavioral neurobiology protocols like the Morris water maze. A different motivation drives neurobiologist Alcino Silva, neuroinformaticist Anthony Landreth, and philosopher of neuroscience John Bickle’s (2014) focus on experimentation. All contemporary sciences are growing at a vertiginous pace; but perhaps none more so than neuroscience. It is no longer possible for any single scientist to keep up with all the relevant published literature in even his or her narrow research field, or fully to comprehend its implications. An overall lack of clarity and consensus about what is known, what remains doubtful, and what has been disproven creates special problems for experiment planning. There is a recognized and urgent need to develop strategies and tools to address these problems. Toward this explicit end, Silva, Landreth, and Bickle’s book describes a framework and a set of principles for organizing the published record. They derive their framework and principles directly from landmark case studies from the influential neuroscientific field of molecular and cellular cognition (MCC), and describe how their framework can be used to generate maps of experimental findings. Scientists armed with these research maps can then determine more efficiently what has been accomplished in their fields, and where the knowledge gaps still reside. The technology needed to automate the generation of these maps already exists. Silva, Landreth, and Bickle sketch the transformative, revolutionary impact these maps can have on current science. Three goals motivate Silva, Landreth, and Bickle’s approach. First, they derive their framework from the cellular and molecular neurobiology of learning and memory. This choice was due strictly to familiarity with the science. Silva was instrumental in bringing gene targeting techniques applied to mammals into behavioral neuroscience, and Bickle’s focus on ruthlessly reductive neuroscience was built on these and other experimental results. And while each of their framework’s different kinds of experiments and evidence have been recognized by others, theirs purports to be the first to systematize this information explicitly toward the goal of facilitating experimental planning by practicing scientists. Silva, Landreth and Bickle insist that important new experiments can be identified and planned by methodically filling in the different forms of evidence recognized by their framework, and applying the different forms of experiments to the gaps in the experimental record revealed by this process. Second, Silva, Landreth, and Bickle take head-on the problem of the growing amount, complexity and integration of the published literature for experiment planning. They show how graphic weighted representations of research findings can be used to guide research decisions; and how to construct these. The principles for constructing these maps are the principles for integrating experimental results, derived directly from landmark published MCC research. Using a case study from recent molecular neuroscience, they show how to generate small maps that reflect a series of experiments, and how to combine these small maps to illustrate an entire field of neuroscience research. Finally, Silva, Landreth and Bickle begin to develop a science of experiment planning. They envision the causal graphs that compose their research maps to play a role similar to that played by statistics in the already-developed science of data analysis. Such a resource could have profound implications for further developing citation indices and other impact measures for evaluating contributions to a field, from those of individual scientists to those of entire institutions. More recently Bickle and Kostko (2018) have extended Silva, Landreth and Bickle’s framework beyond the neurobiology of learning and memory. Their case study comes from developmental and social neuroscience, Michael Meaney and Moshe Szyf’s work on the epigenetics of rodent maternal nursing behaviors on offspring stress responses. Using the details of this case study they elaborate on a notion that Silva, Landreth and Bickle leave underdeveloped, that of experiments designed explicitly for their results, if successful, to be integrated directly into an already-existing background of established results. And they argue that such experiments “integratable by design” with others are aimed not at establishing evidence for individual causal relations among neuroscientific kinds, but rather at formulating entire causal pathways connecting multiple phenomena. Their emphasis on causal paths relates to that of Lauren Ross (forthcoming). Ross’s work is especially interesting in this context because she uses her causal pathway concept to address “causal selection”, which has to do with distinguishing between background conditions and “true” (triggering) causes of some outcome of interest. For Silva, Landreth, and Bickle (2014), accounting for this distinction is likewise crucial, and they rely on a specific kind of connection experiment, “positive manipulations”, to draw it. Bickle and Kostko’s appeal to causal paths in a detailed case study from recent developmental neurobiology might help bridge Silva, Landreth and Bickle’s broader work on neurobiological experimentation with Ross’s work drawn from biology more generally.