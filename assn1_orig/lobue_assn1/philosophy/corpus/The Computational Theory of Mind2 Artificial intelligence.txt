 Rapid progress in computer science prompted many, including Turing, to contemplate whether we could build a computer capable of thought.  Artificial Intelligence (AI) aims to construct “thinking machinery”. More precisely, it aims to construct computing machines that execute core mental tasks such as reasoning, decision-making, problem solving, and so on. During the 1950s and 1960s, this goal came to seem increasingly realistic (Haugeland 1985). Early AI research emphasized logic. Researchers sought to “mechanize” deductive reasoning. A famous example was the Logic Theorist computer program (Newell and Simon 1956), which proved 38 of the first 52 theorems from Principia Mathematica (Whitehead and Russell 1925). In one case, it discovered a simpler proof than Principia’s. Early success of this kind stimulated enormous interest inside and outside the academy. Many researchers predicted that intelligent machines were only a few years away. Obviously, these predictions have not been fulfilled. Intelligent robots do not yet walk among us. Even relatively low-level mental processes such as perception vastly exceed the capacities of current computer programs. When confident predictions of thinking machines proved too optimistic, many observers lost interest or concluded that AI was a fool’s errand. Nevertheless, the decades have witnessed gradual progress. One striking success was IBM’s Deep Blue, which defeated chess champion Gary Kasparov in 1997. Another major success was the driverless car Stanley (Thrun, Montemerlo, Dahlkamp, et al. 2006), which completed a 132-mile course in the Mojave Desert, winning the 2005 Defense Advanced Research Projects Agency (DARPA) Grand Challenge. A less flashy success story is the vast improvement in speech recognition algorithms. One problem that dogged early work in AI is uncertainty. Nearly all reasoning and decision-making operates under conditions of uncertainty. For example, you may need to decide whether to go on a picnic while being uncertain whether it will rain. Bayesian decision theory is the standard mathematical model of inference and decision-making under uncertainty. Uncertainty is codified through probability. Precise rules dictate how to update probabilities in light of new evidence and how to select actions in light of probabilities and utilities. (See the entries Bayes’s theorem and normative theories of rational choice: expected utility  for details.)  In the 1980s and 1990s, technological and conceptual developments enabled efficient computer programs that implement or approximate Bayesian inference in realistic scenarios. An explosion of Bayesian AI ensued (Thrun, Burgard, and Fox 2006), including the aforementioned advances in speech recognition and driverless vehicles. Tractable algorithms that handle uncertainty are a major achievement of contemporary AI (Murphy 2012), and possibly a harbinger of more impressive future progress. Some philosophers insist that computers, no matter how sophisticated they become, will at best mimic rather than replicate thought. A computer simulation of the weather does not really rain. A computer simulation of flight does not really fly. Even if a computing system could simulate mental activity, why suspect that it would constitute the genuine article? Turing (1950) anticipated these worries and tried to defuse them. He proposed a scenario, now called the Turing Test, where one evaluates whether an unseen interlocutor is a computer or a human. A computer passes the Turing test if one cannot determine that it is a computer. Turing proposed that we abandon the question “Could a computer think?” as hopelessly vague, replacing it with the question “Could a computer pass the Turing test?”.  Turing’s discussion has received considerable attention, proving especially influential within AI. Ned Block (1981) offers an influential critique. He argues that certain possible machines pass the Turing test even though these machines do not come close to genuine thought or intelligence. See the entry the Turing test for discussion of Block’s objection and other issues surrounding the Turing Test. For more on AI, see the entry  logic and artificial intelligence.  For much more detail, see Russell and Norvig (2010).