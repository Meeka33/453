 Just as thoughts are composed of concepts, many concepts are themselves complex entities that are composed of other concepts or more basic representational components. In this section, we look at different proposals about the structure of what are often called lexical concepts. Roughly speaking, these are concepts that tend to be associated with individual words in natural language—concepts like BIRD and WALK as opposed to manifestly complex concepts like NOCTURNAL ANIMALS THAT LIVE IN TREES or TO WALK AIMLESSLY ON A NEWLY PAVED ROAD. With BIRD and WALK and similar concepts, it isn’t obvious what type of internal structure (if any) they have, and this has led to a great deal of controversy (Margolis & Laurence 1999, Murphy 2002). Accounts of the structure of lexical concepts have focused on concepts for categories of objects, actions, and events rather than concepts for individuals. Our discussion will share this focus (see, e.g., Blok et al. 2005 and Levine 2010 for discussion of concepts of individuals). In one way or another, all theories regarding the structure of concepts are developments of, or reactions to, the classical theory of concepts. According to the classical theory, a lexical concept C has definitional structure in that it is composed of simpler concepts that express necessary and sufficient conditions for falling under C. The stock example is the concept BACHELOR, which is traditionally said to have the constituents UNMARRIED and MAN. If the example is taken at face value, the idea is that something falls under BACHELOR if it is an unmarried man and only if it is an unmarried man. According to the classical theory, lexical concepts generally will exhibit this same sort of definitional structure. This includes such philosophically interesting concepts as TRUTH, GOODNESS, FREEDOM, and JUSTICE. Before turning to other theories of conceptual structure, it’s worth pausing to see what’s so appealing about classical or definitional structure. Much of its appeal comes from the way it offers unified treatments of concept acquisition, categorization, and reference determination. In each case, the crucial work is being done by the very same components. Concept acquisition can be understood as a process in which new complex concepts are created by assembling their definitional constituents. Categorization can be understood as a psychological process in which a complex concept is matched to a target item by checking to see if each and every one of its definitional constituents applies to the target. And reference determination, we’ve already seen, is a matter of whether the definitional constituents do apply to the target. These considerations alone would be enough to show why the classical theory has been held in such high regard. But the classical theory receives further motivation through its connection with a philosophical method that goes back to antiquity and that continues to exert its influence over contemporary thought. This is the method of conceptual analysis. Paradigmatic conceptual analyses offer definitions of concepts that are to be tested against potential counterexamples that are identified via thought experiments. Conceptual analysis is supposed to be a distinctively a priori activity that many take to be the essence of philosophy. To the extent that paradigmatic conceptual analyses are available and successful, this will convey support for the classical theory. Conversely, if the definitions aren’t there to be discovered, this would seem to put in jeopardy a venerable view of what philosophy is and how philosophical investigations ought to proceed (see  section 5  below). The classical theory has come under considerable pressure in the last forty years or so, not just in philosophy but in psychology and other fields as well. For psychologists, the main problem has been that the classical theory has difficulty explaining a robust set of empirical findings. At the center of this work is the discovery that certain categories are taken to be more representative or typical and that typicality scores correlate with a wide variety of psychological data (for reviews, see Smith & Medin 1981, Murphy 2002). For instance, apples are judged to be more typical than plums with respect to the category of fruit, and correspondingly apples are judged to have more features in common with fruit. There are many other findings of this kind. One other is that more typical items are categorized more efficiently. For example, subjects are quicker to judge that apples are a kind of fruit than to judge that plums are. The problem isn’t that the classical theory is inconsistent with results like these but that it does nothing to explain them. In philosophy, the classical theory has been subjected to a number of criticisms but perhaps the most fundamental is that attempts to specify definitions for concepts have a poor track record. Quite simply, there are too few examples of successful definitional analyses, and certainly none that are uncontroversial (Wittgenstein 1953/1958, Fodor 1981). The huge literature on the analysis of knowledge is representative of the state of things. Since Edmund Gettier (1963) first challenged the traditional definition of KNOWLEDGE (as JUSTIFIED TRUE BELIEF), there has been widespread agreement among philosophers that the traditional definition is incorrect or at least incomplete (see the entry  the analysis of knowledge)).  But no one can seem to agree on what the correct definition is. Despite the enormous amount of effort that has gone into the matter, and the dozens of papers written on the issue, we are still lacking a satisfactory and complete definition. It could be that the problem is that definitions are hard to come by. But another possibility—one that many philosophers are now taking seriously—is that our concepts lack definitional structure. What other type of structure could they have? A non-classical alternative that emerged in the second half of the twentieth century is the prototype theory (e.g., Hampton 2006). According to this theory, a lexical concept C doesn’t have definitional structure but has probabilistic structure in that something falls under C just in case it satisfies a sufficient number of properties encoded by C’s constituents. The prototype theory has its philosophical roots in Wittgenstein’s (1953/1958) famous remark that the things covered by a term often share a family resemblance, and it has its psychological roots in Eleanor Rosch’s groundbreaking experimental treatment of much the same idea (Rosch & Mervis 1975, Rosch 1978). The prototype theory is especially at home in dealing with the typicality effects that were left unexplained by the classical theory. One standard strategy is to maintain that, on the prototype theory, categorization is to be understood as a similarity comparison process, where similarity is computed as a function of the number of constituents that two concepts hold in common. On this model, the reason apples are judged to be more typical than plums is that the concept APPLE shares more of its constituents with FRUIT. Likewise, this is why apples are judged to be a kind of fruit faster than plums are. The prototype theory does well in accounting for a variety of psychological phenomena and it helps to explain why definitions may be so hard to produce. But the prototype theory has its own problems and limitations. One is that its treatment of categorization works best for quick and unreflective judgments. Yet when it comes to more reflective judgments, people go beyond the outcome of a similarity comparison. If asked whether a dog that is surgically altered to look like a raccoon is a dog or a raccoon, the answer for most of us, and even for children, is that it is remains a dog (see Keil 1989, Gelman 2003 for discussion). Another criticism that has been raised against taking concepts to have prototype structure concerns compositionality. When a patently complex concept has a prototype structure, it often has emergent properties, ones that don’t derive from the prototypes of its constituents (e.g., PET FISH encodes properties such as brightly colored, which have no basis in the prototype structure for either PET or FISH). Further, many patently complex concepts don’t even have a prototype structure (e.g., CHAIRS THAT WERE PURCHASED ON A WEDNESDAY) (Fodor & Lepore 1996, Fodor 1998; for responses to the arguments from compositionality, see Prinz 2002, Robbins 2002, Hampton & Jönsson 2012, and Del Pinal 2016). One general solution that addresses all of these problems is to hold that a prototype constitutes just part of the structure of a concept. In addition, concepts have conceptual cores, which specify the information relevant to more considered judgments and which underwrite compositional processes. Of course, this just raises the question of what sort of structure conceptual cores have. One suggestion is that conceptual cores have classical structure (Osherson & Smith 1981, Landau 1982). This won’t do, however, since it just raises once again most of the problems associated with the classical theory (Laurence & Margolis 1999). Another and currently more popular suggestion is that cores are best understood in terms of the theory theory of concepts. This is the view that concepts stand in relation to one another in the same way as the terms of a scientific theory and that categorization is a process that strongly resembles scientific theorizing (see, e.g., Carey 1985, 2009, Gopnik & Meltzoff 1997, Keil 1989). It’s generally assumed, as well, that the terms of a scientific theory are interdefined so that a theoretical term’s content is determined by its unique role in the theory in which it occurs. The theory theory is especially well-suited to explaining the sorts of reflective categorization judgments that proved to be difficult for the prototype theory. For example, theory theorists maintain that children override perceptual similarity in assessing the situation where the dog is made to look like a raccoon, claiming that even children are in possession of a rudimentary biological theory. This theory tells them that being a dog isn’t just a matter of looking like a dog. More important is having the appropriate hidden properties of dogs—the dog essence (see Atran & Medin 2008 on folkbiology). Another advantage of the theory theory is that it is supposed to help to explain important aspects of conceptual development. Conceptual change in childhood is said to follow the same pattern as theory change in science. One problem that has been raised against the theory theory is that it has difficulty in allowing for different people to possess the same concepts (or even for the same person to have the same concept over time). The reason is that the theory theory is holistic. A concept’s content is determined by its role in a theory, not by its being composed of just a handful of constituents. Since beliefs that enter people’s mental theories are likely to be different from one another (and are likely to change), there may be no principled basis for comparison (Fodor & Lepore 1992). Another problem with the theory theory concerns the analogy to theory change in science. The analogy suggests that children undergo radical conceptual reorganization in the course of cognitive development, but many of the central case studies have proved to be controversial on empirical grounds, with evidence that the relevant concepts are implicated in core knowledge systems that are enriched in development but not fundamentally altered (see Spelke & Kinzler 2007 on core knowledge). However, there are certain specific examples where radical conceptual reorganization is plausible, for instance, when children eventually develop a theory of matter that allows them to differentiate weight from density, and air from nothing (Carey 2009). A radical alternative to all of the theories we’ve mentioned so far is conceptual atomism, the view that lexical concepts have no semantic structure (Fodor 1998, Millikan 2000). According to conceptual atomism, the content of a concept isn’t determined by its relation to other concepts but by its relation to the world. Conceptual atomism follows in the anti-descriptivist tradition that traces back to Saul Kripke, Hilary Putnam, and others working in the philosophy of language (see Kripke 1972/80, Putnam 1975, Devitt 1981). Kripke, for example, argues that proper names function like mere tags in that they have no descriptive content (Kripke 1972/80). On a description theory one might suppose that “Gödel” means something like the discoverer of the incompleteness of arithmetic. But Kripke points out we could discover that Schmitt really discovered the incompleteness of arithmetic and that Gödel could have killed Schmitt and passed the work off as his own. The point is that if the description theory were correct, we would be referring to Schmitt when we say “Gödel”. But intuitively that’s not the case at all. In the imagined scenario, the sentence “Gödel discovered the incompleteness of arithmetic” is saying something false about Gödel, not something trivially true about the discoverer of the incompleteness of arithmetic, whoever that might be (though see Machery et al. 2004 on whether this intuition is universal and Genone 2012 for discussion of the role of intuitions in theories of reference). Kripke’s alternative account of names is that they achieve their reference by standing in a causal relation to their referents. Conceptual atomism employs a similar strategy while extending the model to all sorts of concepts, not just ones for proper names. At present, the nature of conceptual structure remains unsettled. Perhaps part of the problem is that more attention needs to be given to the question of what explanatory work conceptual structure is supposed to do and the possibility that there are different types of structure associated with different explanatory functions. We’ve seen that conceptual structure is invoked to explain, among other things, typicality effects, reflective categorization, cognitive development, reference determination, and compositionality. But there is no reason to assume that a single type of structure can explain all of these things. As a result, there is no reason why philosophers shouldn’t maintain that concepts have different types of structure. For example, notice that atomism is largely motivated by anti-descriptivism. In effect, the atomist maintains that considerable psychological variability is consistent with concepts entering into the same mind-world causal relations, and that it’s the latter that determines a concept’s reference. But just because the mechanisms of reference determination permit considerable psychological variability doesn’t mean that there aren’t, in fact, significant patterns for psychologists to uncover. On the contrary, the evidence for typicality effects is impressive by any measure. For this reason, it isn’t unreasonable to claim that concepts do have prototype structure even if that structure has nothing to do with the determination of a concept’s referent. Similar considerations suggest that concepts may have theory-structure and perhaps other types of structure as well (see Laurence & Margolis 1999 on different types of conceptual structure). One way of responding to the plurality of conceptual structures is to suppose that concepts have multiple types of structure. This is the central idea behind conceptual pluralism. According to one version of conceptual pluralism, suggested by Laurence & Margolis (1999), a given concept will have a variety of different types of structure associated with it as components of the concept in question. For example, concepts may have atomic cores that are linked to prototypes, internalized theories, and so on. On this approach, the different types of structure that are components of a given concept play different explanatory roles. Reference determination and compositionality have more to do with the atomic cores themselves and how they are causally related to things outside of the mind, while rapid categorization and certain inferences depend on prototype structure, and more considered inferences and reasoning depend upon theory structure. Many variants on this general proposal are possible, but the basic idea is that, while concepts have a plurality of different types of structure with different explanatory roles, this differing structure remains unified through the links to an atomic representation that provides a concept’s reference. One challenge for this type of account is to delineate which of the cognitive resources that are associated with a concept should be counted as part of its structure and which should not. As a general framework, the account is neutral regarding this question, but as the framework is filled in, clarification will be needed regarding the status of potential types of structure. A different form of pluralism about conceptual structure doesn’t employ atomic cores but simply says that the prototype, theory, etc. are all themselves concepts (Weiskopf 2009). Rather than holding that a single concept (e.g., the concept CAT) has multiple types of structure as components, as in the first form of pluralism, this form takes each type of structure to be a concept on its own, resulting in a plurality of concepts (CAT1, CAT2, CAT3, etc). On this view, it is wrong to suppose that there is such a thing as the concept CAT. Instead, there are many cat-concepts, each with a different type of structure, where each is involved in just a subset of the high-level psychological processes associated with cats. CAT1, for example, might explain some instances of categorization and some inferences, while CAT2, CAT3, etc. explain others. What’s more, on this form of pluralism, people might also differ with respect to which kinds of cat-concepts they possess. And even if two people have a cat-concept with the same general type of structure (e.g., prototype structure), the concepts might still be rather different (treating prototypical cats as having rather different sorts of properties). In response to this second form of pluralism, some philosophers have argued that CAT1, CAT2, etc. may be better understood as different senses of a single CAT concept, on analogy with the different senses of a polysemous linguistic expression (e.g. the physical object sense and the content sense of “book”)(Vicente & Manrique 2016). Regardless of whether one accepts this point about polysemy, an important challenge facing this second (“multiple concepts”) version of pluralism is to explain why all of the different cat-concepts count as cat-concepts—that is, to explain what unifies the plurality of cat-concepts. A natural answer to this challenge is that what unifies them is that they all refer to the same category, the category of cats. But it is not so clear that they can all refer to the same category given the differences between the different cat-concepts and the way that they function in cognition. For example, a standard prototype structure would capture prototypical cats and exclude the highly unusual, atypical cats that a theory structure would cover, and consequently the two concepts would refer to distinct (though related) categories. In all of its forms, pluralism about conceptual structure recognizes that concepts have diverse functions and that a corresponding variety of types of representations are needed to fulfill these functions. These same considerations have led some theorists to advocate concept eliminativism—the view that there are no concepts (Machery 2009). The reasoning behind concept eliminativism is that concept should be understood to be a natural kind if concepts exist at all, and that natural kinds ought to have significant commonalities that can be discovered using empirical methods, including commonalities that go well beyond the criteria that are initially used to characterize them. But according to concept eliminativists, there are no such commonalities that hold among the types of representations that pluralists embrace. Perhaps we need prototypes and theories and other types of representations for distinct higher-level cognitive processes, but they are too diverse to warrant the claim that they constitute a single kind. On this view, then, we should simply abandon the theoretical construct of a concept and refer only to more fine-grained types of representations, such as prototypes and theories. Opponents of concept eliminativism have responded to the eliminativist’s challenge in a number of ways. Some have argued that Machery’s criteria for elimination are simply too strong and that concept, understood as a higher-level kind or perhaps a functional kind, has great utility in psychological models of cognitive processes (e.g., Hampton 2010, Lalumera 2010, Strohminger & Moore 2010). Others have argued that Machery’s criteria for something’s being a natural kind are too restrictive and that his view would have the consequence of ruling out clear cases of legitimate higher-level kinds in science generally (e.g., Gonnerman & Weinberg 2010, Margolis & Laurence 2010). And others have argued that even if we grant Machery’s stringent criteria for being a natural kind, elimination wouldn’t follow, as concepts are natural kinds according to his criteria (Samuels & Ferreira 2010, Weiskopf 2010). (For further critical discussion of eliminativism, see the peer commentary that appears with Machery 2010 and the author’s response.)