 In his 1933 paper Tarski went on to show that many fully interpreted formal languages do have a truth definition that satisfies his conditions. He gave four examples in that paper. One was a trivial definition for a finite language; it simply listed the finitely many true sentences. One was a definition by quantifier elimination; see Section 2.2 below. The remaining two, for different classes of language, were examples of what people today think of as the standard Tarski truth definition; they are forerunners of the 1956 model-theoretic definition. The two standard truth definitions are at first glance not definitions of truth at all, but definitions of a more complicated relation involving assignments \(a\) of objects to variables: (where the symbol ‘\(F\)’ is a placeholder for a name of a particular formula of the object language). In fact satisfaction reduces to truth in this sense: \(a\) satisfies the formula \(F\) if and only if taking each free variable in \(F\) as a name of the object assigned to it by \(a\) makes the formula \(F\) into a true sentence. So it follows that our intuitions about when a sentence is true can guide our intuitions about when an assignment satisfies a formula. But none of this can enter into the formal definition of truth, because ‘taking a variable as a name of an object’ is a semantic notion, and Tarski’s truth definition has to be built only on notions from syntax and set theory (together with those in the object language); recall Section 1.1. In fact Tarski’s reduction goes in the other direction: if the formula \(F\) has no free variables, then to say that \(F\) is true is to say that every assignment satisfies it. The reason why Tarski defines satisfaction directly, and then deduces a definition of truth, is that satisfaction obeys recursive conditions in the following sense: if \(F\) is a compound formula, then to know which assignments satisfy \(F\), it’s enough to know which assignments satisfy the immediate constituents of \(F\). Here are two typical examples: We have to use a different approach for atomic formulas. But for these, at least assuming for simplicity that \(L\) has no function symbols, we can use the metalanguage copies \(\#(R)\) of the predicate symbols \(R\) of the object language. Thus: (Warning: the expression \(\#\) is in the metametalanguage, not in the metalanguage \(M\). We may or may not be able to find a formula of \(M\) that expresses \(\#\) for predicate symbols; it depends on exactly what the language \(L\) is.) Subject to the mild reservation in the next paragraph, Tarski’s definition of satisfaction is compositional, meaning that the class of assignments which satisfy a compound formula \(F\) is determined solely by (1) the syntactic rule used to construct \(F\) from its immediate constituents and (2) the classes of assignments that satisfy these immediate constituents. (This is sometimes phrased loosely as: satisfaction is defined recursively. But this formulation misses the central point, that (1) and (2) don’t contain any syntactic information about the immediate constituents.) Compositionality explains why Tarski switched from truth to satisfaction. You can’t define whether ‘For all \(x, G\)’ is true in terms of whether \(G\) is true, because in general \(G\) has a free variable \(x\) and so it isn’t either true or false. The reservation is that Tarski’s definition of satisfaction in the 1933 paper doesn’t in fact mention the class of assignments that satisfy a formula \(F\). Instead, as we saw, he defines the relation ‘\(a\) satisfies \(F\)’, which determines what that class is. This is probably the main reason why some people (including Tarski himself in conversation, as reported by Barbara Partee) have preferred not to describe the 1933 definition as compositional. But the class format, which is compositional on any reckoning, does appear in an early variant of the truth definition in Tarski’s paper of 1931 on definable sets of real numbers. Tarski had a good reason for preferring the format ‘\(a\) satisfies \(F\)’ in his 1933 paper, namely that it allowed him to reduce the set-theoretic requirements of the truth definition. In sections 4 and 5 of the 1933 paper he spelled out these requirements carefully. The name ‘compositional(ity)’ first appears in papers of Putnam in 1960 (published 1975) and Katz and Fodor in 1963 on natural language semantics. In talking about compositionality, we have moved to thinking of Tarski’s definition as a semantics, i.e. a way of assigning ‘meanings’ to formulas. (Here we take the meaning of a sentence to be its truth value.) Compositionality means essentially that the meanings assigned to formulas give at least enough information to determine the truth values of sentences containing them. One can ask conversely whether Tarski’s semantics provides only as much information as we need about each formula, in order to reach the truth values of sentences. If the answer is yes, we say that the semantics is fully abstract (for truth). One can show fairly easily, for any of the standard languages of logic, that Tarski’s definition of satisfaction is in fact fully abstract. As it stands, Tarski’s definition of satisfaction is not an explicit definition, because satisfaction for one formula is defined in terms of satisfaction for other formulas. So to show that it is formally correct, we need a way of converting it to an explicit definition. One way to do this is as follows, using either higher order logic or set theory. Suppose we write \(S\) for a binary relation between assignments and formulas. We say that \(S\) is a satisfaction relation if for every formula \(G, S\) meets the conditions put for satisfaction of \(G\) by Tarski’s definition. For example, if \(G\) is ‘\(G_1\) and \(G_2\)’, \(S\) should satisfy the following condition for every assignment \(a\): We can define ‘satisfaction relation’ formally, using the recursive clauses and the conditions for atomic formulas in Tarski’s recursive definition. Now we prove, by induction on the complexity of formulas, that there is exactly one satisfaction relation \(S\). (There are some technical subtleties, but it can be done.) Finally we define \(a\) satisfies \(F\) if and only if: there is a satisfaction relation \(S\) such that \(S(a,F)\). It is then a technical exercise to show that this definition of satisfaction is materially adequate. Actually one must first write out the counterpart of Convention \(T\) for satisfaction of formulas, but I leave this to the reader. The remaining truth definition in Tarski’s 1933 paper – the third as they appear in the paper – is really a bundle of related truth definitions, all for the same object language \(L\) but in different interpretations. The quantifiers of \(L\) are assumed to range over a particular class, call it \(A\); in fact they are second order quantifiers, so that really they range over the collection of subclasses of \(A\). The class \(A\) is not named explicitly in the object language, and thus one can give separate truth definitions for different values of \(A\), as Tarski proceeds to do. So for this section of the paper, Tarski allows one and the same sentence to be given different interpretations; this is the exception to the general claim that his object language sentences are fully interpreted. But Tarski stays on the straight and narrow: he talks about ‘truth’ only in the special case where \(A\) is the class of all individuals. For other values of \(A\), he speaks not of ‘truth’ but of ‘correctness in the domain \(A\)’. These truth or correctness definitions don’t fall out of a definition of satisfaction. In fact they go by a much less direct route, which Tarski describes as a ‘purely accidental’ possibility that relies on the ‘specific peculiarities’ of the particular object language. It may be helpful to give a few more of the technical details than Tarski does, in a more familiar notation than Tarski’s, in order to show what is involved. Tarski refers his readers to a paper of Thoralf Skolem in 1919 for the technicalities. One can think of the language \(L\) as the first-order language with predicate symbols \(\subseteq\) and =. The language is interpreted as talking about the subclasses of the class \(A\). In this language we can define: Now we aim to prove: Lemma. Every formula \(F\) of \(L\) is equivalent to (i.e. is satisfied by exactly the same assignments as) some boolean combination of sentences of the form ‘There are exactly \(k\) elements in \(A\)’ and formulas of the form ‘There are exactly \(k\) elements that are in \(v_1\), not in \(v_2\), not in \(v_3\) and in \(v_4\)’ (or any other combination of this type, using only variables free in \(F)\). The proof is by induction on the complexity of formulas. For atomic formulas it is easy. For boolean combinations of formulas it is easy, since a boolean combination of boolean combinations is again a boolean combination. For formulas beginning with \(\forall\), we take the negation. This leaves just one case that involves any work, namely the case of a formula beginning with an existential quantifier. By induction hypothesis we can replace the part after the quantifier by a boolean combination of formulas of the kinds stated. So a typical case might be: \(\exists z\) (there are exactly two elements that are in \(z\) and \(x\) and not in \(y)\). This holds if and only if there are at least two elements that are in \(x\) and not in \(y\). We can write this in turn as: The number of elements in \(x\) and not in \(y\) is not 0 and is not 1; which is a boolean combination of allowed formulas. The general proof is very similar but more complicated. When the lemma has been proved, we look at what it says about a sentence. Since the sentence has no free variables, the lemma tells us that it is equivalent to a boolean combination of statements saying that \(A\) has a given finite number of elements. So if we know how many elements \(A\) has, we can immediately calculate whether the sentence is ‘correct in the domain \(A\)’. One more step and we are home. As we prove the lemma, we should gather up any facts that can be stated in \(L\), are true in every domain, and are needed for proving the lemma. For example we shall almost certainly need the sentence saying that \(\subseteq\) is transitive. Write \(T\) for the set of all these sentences. (In Tarski’s presentation \(T\) vanishes, since he is using higher order logic and the required statements about classes become theorems of logic.) Thus we reach, for example: Theorem. If the domain \(A\) is infinite, then a sentence \(S\) of the language \(L\) is correct in \(A\) if and only if \(S\) is deducible from \(T\) and the sentences saying that the number of elements of \(A\) is not any finite number. The class of all individuals is infinite (Tarski asserts), so the theorem applies when \(A\) is this class. And in this case Tarski has no inhibitions about saying not just ‘correct in \(A\)’ but ‘true’; so we have our truth definition. The method we have described revolves almost entirely around removing existential quantifiers from the beginnings of formulas; so it is known as the method of quantifier elimination. It is not as far as you might think from the two standard definitions. In all cases Tarski assigns to each formula, by induction on the complexity of formulas, a description of the class of assignments that satisfy the formula. In the two previous truth definitions this class is described directly; in the quantifier elimination case it is described in terms of a boolean combination of formulas of a simple kind. At around the same time as he was writing the 1933 paper, Tarski gave a truth definition by quantifier elimination for the first-order language of the field of real numbers. In his 1931 paper it appears only as an interesting way of characterising the set of relations definable by formulas. Later he gave a fuller account, emphasising that his method provided not just a truth definition but an algorithm for determining which sentences about the real numbers are true and which are false.