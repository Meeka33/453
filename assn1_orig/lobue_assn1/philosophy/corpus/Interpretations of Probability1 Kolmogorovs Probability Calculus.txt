 Probability theory was a relative latecomer in intellectual history. To be sure, proto-probabilistic ideas concerning evidence and inference date back to antiquity (see Franklin 2001). However, probability’s mathematical treatment had to wait until the Fermat-Pascal correspondence, and their analysis of games of chance in 17th century France. Its axiomatization had to wait still longer, in Kolmogorov’s classic Foundations of the Theory of Probability (1933). Roughly, probabilities lie between 0 and 1 inclusive, and they are additive. More formally, let \(\Omega\) be a non-empty set (‘the universal set’). A field (or algebra) on \(\Omega\) is a set \(\mathbf{F}\) of subsets of \(\Omega\) that has \(\Omega\) as a member, and that is closed under complementation (with respect to \(\Omega)\) and union. Let \(P\) be a function from \(\mathbf{F}\) to the real numbers obeying: Call \(P\) a probability function, and \((\Omega , \mathbf{F}, P)\) a probability space. This is Kolmogorov’s “elementary theory of probability”. The assumption that \(P\) is defined on a field guarantees that these axioms are non-vacuously instantiated, as are the various theorems that follow from them. The non-negativity and normalization axioms are largely matters of convention, although it is non-trivial that probability functions take at least the two values 0 and 1, and that they have a maximal value (unlike various other measures, such as length, volume, and so on, which are unbounded). We will return to finite additivity at a number of points below. We may now apply the theory to various familiar cases. For example, we may represent the results of tossing a single die once by the set \(\Omega = \{1, 2, 3, 4, 5, 6\}\), and we could let \(\mathbf{F}\) be the set of all subsets of \(\Omega\). Under the natural assignment of probabilities to members of \(\mathbf{F}\), we obtain such welcome results as the following: and so on. We could instead attach probabilities to members of a collection \(\mathbf{S}\) of sentences of a formal language, closed under (countable) truth-functional combinations, with the following counterpart axiomatization: The bearers of probabilities are sometimes also called “events”, “outcomes”, or “propositions”, but the underlying formalism remains the same. More attention has been given to interpreting ‘\(P\)’ than to interpreting its bearers; we will be concerned with the former. Now let us strengthen our closure assumptions regarding \(\mathbf{F}\), requiring it to be closed under complementation and countable union; it is then called a sigma field (or sigma algebra) on \(\Omega\). It is controversial whether we should strengthen finite additivity, as Kolmogorov does: Kolmogorov comments that infinite probability spaces are idealized models of real random processes, and that he limits himself arbitrarily to only those models that satisfy countable additivity. This axiom is the cornerstone of the assimilation of probability theory to measure theory. The conditional probability of A given B is then given by the ratio of unconditional probabilities: This is often taken to be the definition of conditional probability, although it should be emphasized that this is a technical usage of the term that may not align perfectly with a pretheoretical concept that we might have (see Hájek, 2003). We recognize it in locutions such as “the probability that the die lands 1, given that it lands odd, is 1/3”, or “the probability that it will rain tomorrow, given that there are dark clouds in the sky tomorrow morning, is high”. It is the concept of the probability of something given or in the light of some piece of evidence or information. Indeed, some authors take conditional probability to be the primitive notion, and axiomatize it directly (e.g. Popper 1959b, Rényi 1970, van Fraassen 1976, Spohn 1986, and Roeper and Leblanc 1999). There are other formalizations that give up normalization; that give up countable additivity, and even additivity; that allow probabilities to take infinitesimal values (positive, but smaller than every positive real number); that allow probabilities to be imprecise — interval-valued, or more generally represented with sets of precise probability functions; and that treat probabilities comparatively rather than quantitatively. (See Fine 1974, Halpern 2003, Cozman 2016, Fine 2016, Hawthorne 2016, Lyon 2016.) For now, however, when we speak of ‘the probability calculus’, we will mean Kolmogorov’s approach, as is standard. See Hájek and Hitchcock (2016b) for a relatively non-technical introduction to it, intended for philosophers. Given certain probabilities as inputs, the axioms and theorems allow us to compute various further probabilities. However, apart from the assignment of 1 to the universal set and 0 to the empty set, they are silent regarding the initial assignment of  probabilities.[1]  For guidance with that, we need to turn to the interpretations of probability. First, however, let us list some criteria of adequacy for such interpretations.